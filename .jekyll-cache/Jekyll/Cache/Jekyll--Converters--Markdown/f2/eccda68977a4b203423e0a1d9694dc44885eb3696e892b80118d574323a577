I"	
<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="err">짧은</span> <span class="err">요약</span> <span class="p">:</span>

<span class="err">어느</span> <span class="err">정도가</span> <span class="err">베이직한</span> <span class="err">것인</span> <span class="err">지는</span> <span class="err">모르겠지만</span>  
<span class="err">복습</span> <span class="err">겸</span> <span class="err">정리가</span> <span class="err">좀</span> <span class="err">필요할</span> <span class="err">것</span> <span class="err">같아</span> <span class="err">적어봅니다</span><span class="o">.</span>  </code></pre></figure>

<h1 id="분류-알고리즘">분류 알고리즘</h1>

<p>*Linear Regression<br />
-선형식/로지스틱식 파라미터 학습하여 분류<br />
**장: 학습속도/예측속도 빠름, 예측을 수식을 통해 파악 가능<br />
**단: 선형 또는 로지스틱 함수로 국한됨</p>

<p>*Deep Neural Network<br />
-다층 모델의 파라미터 학습하여 분류<br />
**장: 비선형 관계 학습, 데이터의 잠재적 feature 파악가능<br />
**단: 많은 데이터 필요, 높은 컴퓨팅 파워 요구, 예측이 블랙박스</p>

<p>*Support Vector Machine<br />
-하이퍼플레인(데이터 가르는 척도)과 서포트벡터(하이퍼플레인과 마진만큼 거리가짐)를 척도로 분류<br />
**장: 많은 feature 처리 가능<br />
**단: 분류가 많아지면 각 분류마다 SVM 계산해줘야해서 계산량 등 많아짐</p>

<p>*K-Nearest Neighbor<br />
-거리 기반으로 분류<br />
**장: 이해하가 쉬움, 튜닝 적어도 성능 괜춘<br />
**단: 데이터가 커지면 예측 속도 느려짐, 많은 특성(feature) 처리 능력은 부족</p>

:ET