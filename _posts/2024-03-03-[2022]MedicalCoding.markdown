---
layout: post
title:  "[2022]Medical Coding with Biomedical Transformer Ensembles and Zero/Few-shot Learning"  
date:   2024-03-03 18:55:11 -0400
categories: study
---

{% highlight ruby %}


짧은 요약(Abstract) :    

* 의료 코딩은 신뢰할 수 있는 데이터 검색 및 보고를 위한 필수 전제 조건임
* 주어진 자유 텍스트 보고 용어(예: "오른쪽 허벅지의 무릎까지의 통증")에 대해, 매우 크고 지속적으로 성장하는 표준화된 의료 용어 저장소에서 해당하는 가장 낮은 수준의 용어(LLT)를 식별하는 작업임 –이 경우에는 "일측성 다리 통증"
* 그러나 이 작업을 자동화하는 것은 LLT 코드의 대규모 수(작성 시 80,000개 이상), 긴 꼬리/신생 클래스에 대한 훈련 데이터의 제한된 가용성, 그리고 의료 분야의 일반적으로 높은 정확도 요구 사항 때문에 도전적임
* 이 논문에서는 MC 작업을 소개하고, 그 과제를 논의하며, 전통적인 BERT 기반 분류와 최근의 제로/퓨샷 학습 접근 방식(TARS)을 결합한 새로운 접근 방식인 XTARS를 제시함
* XTARS를 사용한 광범위한 실험을 통해, 특히 퓨샷 체제에서 강력한 기준선을 능가하는 것을 보여줌


* Medical coding is a prerequisite for reliable data retrieval and reporting in the medical field
* Identifying the lowest level term (LLT) in a vast and growing standardized medical terminology repository for a given free text report term  
** For example "pain from knee to right thigh" to "unilateral leg pain"  
* Automating this task is challenging due to the large number of LLT codes (over 80,000 at the time of writing), limited availability of training data for long-tail/emerging classes, and the typically high accuracy requirements in the medical field
This paper introduces the MC task, discusses its challenges, and presents a new approach, XTARS, combining traditional BERT-based classification with recent zero/few-shot learning methods (TARS)
* Extensive experiments with XTARS, especially in a few-shot regime, demonstrate its superiority over strong baselines



Useful sentences :  


{% endhighlight %}  

<br/>

[Paper link](https://drive.google.com/drive/folders/1870mgj6jrTdl2H-UWHWk6CmV8tVj6EiA?usp=sharing)  
[~~Lecture link~~]()  

<br/>

# 단어정리  
* unilateral: 단독의, 일방적인. 의학적 맥락에서는 주로 한쪽에만 영향을 미치는 증상이나 상태를 지칭할 때 사용  
* regime: 체제, 제도. 일반적으로 어떤 분야의 관리나 운영 방식을 의미. 의학이나 건강 관련 분야에서는 특정 치료나 운동, 식단 등을 일정한 방식으로 시행하는 것 의미    
* alphanumerical: 알파벳과 숫자의 조합. 문자와 숫자를 모두 포함하는 문자열을 의미  
* thigh: 허벅지. 인체의 다리 부분 중, 골반에서 무릎까지의 부위를 지칭  
* non-canonical: 비정규적인, 비전통적인. 일반적이거나 널리 받아들여지는 규범, 기준, 형식에서 벗어난 것을 의미  
* abbreviations: 약어. 긴 단어나 구문을 짧게 줄인 형태  
* be phrased: 표현되다. 어떤 말이나 문장이 특정한 방식으로 구성되거나 말해지는 것을 의미   
* proprietary: 전용의, 소유의. 일반적으로 특정 회사나 개인이 소유하고 있는 것을 의미  
* verbatim: 말 그대로의, 직접 인용한. 텍스트나 발언이 원본에서 정확히 그대로 복사되었음을 나타냄  
* btm-25%? btm-50%?: bottom, 전체 데이터 세트 중 예측에 있어 가장 불확실성이 높은 하위 25%의 부분집합, 하위 50% 부분집합  
* one PT?, the PT is then obtained direcly from MedDRA: Preferred Term: 하나의 PT는 특정 의료 조건을 나타내며, 여러 "Lowest Level Terms(LLT)"에 연결될 수 있음  
* topological: 위상학적인. 주로 수학 및 네트워크 이론에서 사용되며, 공간, 지형, 연결성의 특성을 다룸. 이 문맥에서는 MedDRA의 위상학적 변경, 즉 계층 구조나 분류 체계의 변화를 의미  
* deploying a single model: 단일 모델 배치. 머신러닝 또는 딥러닝에서 하나의 모델만을 사용하여 실제 환경에 적용하는 과정을 의미  
* underspecification problem: 불완전 명세 문제. 모델이 학습 과정에서 충분한 정보를 받지 못해, 새로운 데이터나 상황에 대한 예측에서 불확실성이나 오류가 증가하는 문제  
* instabilities: 불안정성. 여기서는 모델 예측의 불안정성을 의미하며, 모델이 다양한 입력에 대해 일관되지 않거나 예측력이 낮은 결과를 내는 현상  
* cardinality: 기수성, 카디널리티. 집합의 원소의 수를 의미하는 용어로, 이 경우 데이터셋 내의 클래스나 라벨의 개수를 나타내는 데 사용  
* perturbation: 교란, 변동. 모델의 입력이나 매개변수에 작은 변화를 주어 모델의 견고성이나 성능 변화를 측정하는 데 사용  
* plausible: 그럴듯한. 여기서는 'plausible negatives'라는 용어로 사용되어 각 라벨링된 데이터 포인트마다 그럴듯한 부정적인 샘플을 추출하는 것을 의미  
* proportional: 비례하는. 어떤 값이 다른 값에 비례하여 변화하는 성질을 나타냅니다. 예를 들어, TARS에서는 코사인 유사도에 비례하여 부정 샘플을 샘플링  
* temperature T(in softmax): 소프트맥스 함수에서의 온도 매개변수(T). T 값을 조정함으로써 소프트맥스 함수의 출력 분포를 더 날카롭게(낮은 T) 하거나 부드럽게(높은 T) 할 수 있음. 이는 예측 확률 분포의 엔트로피를 조절하고, 결과적으로 모델이 더 확실하거나 덜 확실한 예측을 하도록 만듬  
* attained: 달성된, 얻어진. 어떤 목표나 수준에 도달했음을 의미    
* on-par: 동등한, 비슷한 수준의. 어떤 것이 다른 것과 동일하거나 비슷한 수준에 있음   
* deviation: 편차. 기준이나 평균으로부터의 이탈 또는 차이를 의미  
* standard deviation: 표준편차. 데이터 집합의 분산 정도를 나타내는 통계적 수치로, 데이터가 평균으로부터 얼마나 멀리 떨어져 있는지를 나타냄  
* snippet: 작은 조각, 일부분. 문서, 코드, 정보 등의 작은 부분이나 일부를 가리킴  
<br/>

# 1 Introduction  
* 의료 코딩(Medical Coding, MC)은 의료 이벤트의 텍스트 설명을 표준화된 알파벳-숫자 용어 및 코드로 분류하는 과정  
** 예를 들어, "오른쪽 허벅지에서 무릎까지의 통증"이라는 텍스트 설명은 MedDRA (MSSO Retrieved Jun 24 2021) 온톨로지에서 "단측 다리 통증"으로 분류  
* MC는 임상 시험 분석을 용이하게 하며, 예를 들어 안전성 데이터 검색이나 부작용 감지를 가능케 함  
* 의료 코드는 건강 계획 의료 청구 및 의료 제공자가 예를 들어 사전 승인 요청 및 클레임에 대한 결정을 내리는 데 사용되며, 일부 국가에서는 환자가 의료 서비스에 지불해야 하는 금액에 영향을 줌  
* Bayer에서는 월간 약 55,000개의 용어를 전문 의료 코더가 수동으로 코딩해야 하며, 이는 비용이 많이 드는 과정  
** 이 과정을 부분적으로 자동화하는 것이 목표   
<br/>

# 2 Task and Data Sources
* 의료 코딩(MC) 입력은 의료 이벤트의 텍스트 설명으로, 보고된 용어(Reported Term, RT)  
* MC의 목표는 주어진 RT를 주어진 온톨로지에서 가장 적절한 용어와 연결하는 것  

## 2.1 MedDRA as target ontology  
* MedDRA(MSSO Retrieved Jun 24 2021) 온톨로지를 활용  
** 이는 거친(granular) 클래스와 세밀한 클래스로 구성된 다단계 계층 구조로 조직  
** 계층 구조에서 더 세밀한 단계는 약 80,000개의 고유 클래스가 존재하는 최저 수준 용어(Lowest Level Term, LLT)  
** 더 거친 단계는 MedDRA에서 현재 약 26,000개가 존재하는 선호 용어(Preferred Term, PT)
* MedDRA는 클래스의 수 변경이나 그 정의 변경을 포함한 빈번한 릴리스를 겪음  
** 모델은 항상 MedDRA의 가장 최신 버전을 사용해야 하므로 접근 방식은 이러한 변경에 대해 강인해야  


## 2.2 Training data  
* 제안된 접근 방식을 훈련하고 평가하기 위해 여러 독점 데이터 소스를 사용  
* 첫 번째는 인간 전문가가 LLT에 수동으로 연결한 RT가 포함된 코딩된 데이터  
* 두 번째는 간단한 규칙 기반 시스템이 RT를 LLT와 자동으로 연결한 자동코딩된 데이터  
* 이 시스템은 높은 정밀도를 가지지만 대부분의 샘플(약 55%)이 자동 코더 범위를 벗어나 사람에 의한 수동 코딩으로 전달  
* 또한, 회사 동의어 데이터 세트를 사용  
* 이는 의료 텍스트 설명과 해당 LLT의 쌍으로 구성되며, 이러한 동의어는 회사 MC 부서에서 생성 및 유지 관리  
* 이 동의어는 LLT보다 더 구체적인 개념을 정의합니다.
* 전체 훈련 데이터 세트에서는 26,893개의 클래스만이 관찰되었음을 알 수 있고 이는 MedDRA LLT 코드의 상당 부분에 대한 훈련 데이터가 전혀 없음을 의미  
* 또한 눈에 띄는 데이터 불균형을 확인할 수 있음: 관찰된 클래스 중 21,187개(78%)가 10개 미만의 샘플을 가지고 있으며, 모든 샘플 중 약 21%가 이러한 클래스에서 나옴 

# 3 Method  
* 의료 코딩(MC) 작업을 각각의 낮은 수준 용어(Lowest Level Term, LLT) 이름을 고유한 클래스로 취급하는 다중 클래스 분류 작업으로 설정  
** 따라서 각 LLT는 정확히 하나의 선호 용어(Preferred Term, PT)에 속하므로 PT는 MedDRA에서 직접 얻어짐  
** 이는 더 간단한 모델을 훈련하고 배포하며, 기본적인 MedDRA 온톨로지의 구조적 변화에 대한 모델의 의존성을 줄이는 결과를 가져옴  

* 방법론 개요에서 접근 방식은 기존의 두 가지 접근 방식, 즉 (1) BERT 기반의 기본 대규모 다중 클래스 예측 접근 방식과 (2) 최근의 제로/퓨샷 학습 접근 방식(TARS)을 기반으로 하고 이를 결합  
* 이 섹션에서는 먼저 이 두 가지 기본 접근 방식과 그 장단점을 논의한 다음, 제안하는 XTARS 접근 방식을 소개  

## 3.1 Baseline 1: Multiclass Classification with BERT Ensembles  
* 첫 번째 기본 접근 방식은 BERT 기반의 표준 다중 클래스 분류 접근 방식을 따름  
* 사전 훈련된 BERT 모델의 CLS-토큰에서 검색된 텍스트 임베딩 위에 단일 소프트맥스 분류기를 "예측 헤드"로 추가  
* 언어 모델과 예측 헤드는 표준 매개변수를 사용하여 공동으로 미세 조정되며, 단일 입력 텍스트에 대해 모든 클래스에 대한 예측 점수 분포를 출력  
* 이러한 접근 방식은 생물의학 데이터에 대한 대규모 다중 레이블 텍스트 분류에 적용되었으며, 더 복잡하고 맞춤화된 접근 방식과 비교할 수 있는 결과를 보여줌  

* 딥 앙상블: 단일 모델을 프로덕션 설정에 배포하는 것은 권장되지 않음  
* 이는 데이터 세트 변화에 따라 배포 도메인에서 널리 다른 결과를 생성할 수 있기 때문에 실제 설정에서 모델을 배포할 때 문제가 될 수 있음  
* 이러한 문제를 완화하기 위해 깊은 앙상블을 사용  
* 주요 아이디어는 임의의 섭동(일반적으로 무작위 시드)만 다른 여러 모델을 훈련시키고 이 모델들에 대해 평균을 내어 예측 안정성을 높이고 성능을 향상시키는 것  
* 추가적으로 깊은 앙상블은 베이지안 딥 러닝 접근 방식과 동등한 신뢰할 수 있는 불확실성 추정치를 생성하는 것으로도 나타남  

## 3.2 Baseline 2: TARS Few-Shot Classification  
* 전통적인 기계 학습 알고리즘은 라벨의 자연어 정의에 접근할 수 없으며, 대신 인코딩(예: 원-핫 인코딩)이라고 알려진 이산 표현에만 접근할 수 있음   
* 이 표현은 자연어 정의에 존재하는 의미 정보를 보존하지 않음  
* 결과적으로 모델은 학습 중에 주어진 라벨에 연결된 샘플을 통해서만 간접적으로 클래스 의미를 학습할 수 있음  
* 소수샷 설정에서는 라벨 의미의 부족이 분명한 단점  
* 자연어 추론에서 영감을 받은 Task-Aware Representation of Sentences(TARS Halder et al. (2020))는 입력 텍스트(예: RT)와 라벨(예: LLT 이름)을 연결하고 라벨이 정확한 것이면 True, 그렇지 않으면 False(부정 클래스 또는 샘플)를 예측함으로써 라벨 의미를 포함    
* TARS는  소수샷 및 제로샷 설정에서 강력한 결과에 도달하는 것으로 나타났으나, 비교적 작은 라벨 세트로만 평가  

* 의료 코딩과 관련하여 TARS는 MedDRA에서 매우 큰 클래스 수로 인해 심각한 확장성 문제에 직면:   
** 예측 중에 각 라벨 후보를 별도로 평가하기 위해 모델을 통해 별도의 포워드 패스가 필요  
** 이 절차는 K가 가능한 라벨 수일 때 K 예측이 필요  
** K가 매우 클 때(예: MC의 MedDRA에서 K ≈ 80,000) 예측 계산은 계산적으로 금지  
** 또한 대규모 분류 시나리오는 훈련 절차를 복잡하게 만듬   
* TARS는 각 라벨 데이터 포인트에 대해 neg개의 타당한 부정을 샘플링하기 위해 하드-네거티브 샘플링 기술을 사용하며, 이는 주어진 라벨과 정확한 라벨 사이의 코사인 유사도에 비례하는 확률로 샘플링  
* 유사도가 대규모 분류(예: MC에서)에서 부정 라벨을 추출하기 위한 추출 확률로 사용될 때, 모델은 종종 "너무 쉬운" 부정 라벨을 자주 봄  
* 이는 초미세 라벨과의 학습을 방해    

## 3.3 Proposed Approach: xTARS  
* 훈련 중에 어려운 부정 샘플링을 개선하고 예측 중에 복잡성 문제를 해결하는 TARS 알고리즘에 변경을 도입하여 XTARS를 제안  
* 접근 방식은 먼저 MC를 위해 별도로 훈련되어야 하는 기본 BERT 다중 클래스 분류 모델을 활용  

* 대규모 라벨 세트에서 어려운 부정 샘플링: 매우 큰 라벨 세트에서 어려운 부정 샘플을 샘플링하는 위에 언급된 문제를 해결하기 위해, 두 가지 샘플링 기술을 함께 사용   
* 첫 번째는 훈련된 BERT 분류 모델의 예측을 활용하는 것  
* 상위 5개 예측(또는 올바른 클래스가 상위 5개에 있는 경우 상위 4개)을 부정 샘플로 사용  
** 왜냐하면 이것들은 완전히 훈련된 표준 모델의 관점에서 어렵기 때문  

* 두 번째는 TARS의 코사인 유사도 기반 샘플링을 상위-k와 소프트맥스 재조정을 사용하여 수정하는 것  
* 라벨 유사도를 계산한 후에 올바른 라벨에 가장 유사한 상위-k 클래스만 추출하고 나머지는 모두 0으로 설정   
* 부정 샘플의 수의 세 배가 되는 k를 선택  
* 마지막으로, 우리는 온도-스케일 소프트맥스를 사용하여 상위-k 유사도를 재조정  
* 낮은(높은) T는 더 뾰족한(넓은) 분포를 결과로 함   
* 이 절차는 부정 샘플의 품질을 개선하고(TARS (neg=10) 대비 xTARS (neg=10) 참조) 더 빠름(k 대 K 차원의 샘플링 확률 벡터를 사용하기 때문에 k << K)  

* 예측 중 후보 라벨 제한: 우리는 먼저 기본 BERT 모델(또는 딥 앙상블)로 다중 클래스 분포를 예측하여 예측 중의 확장성 문제를 해결  
* 그런 다음 TARS를 위한 라벨 후보로 사용할 n 상위 점수 예측을 선택  
* 실험을 통해 n의 좋은 값이 5라는 것을 발견  
* 이것은 계산 비용을 4자리 숫자(5 대 80,000)로 줄이지만, 올바른 라벨이 BERT 후보의 상위 5개에 없는 경우 XTARS가 올바르게 예측할 수 없다는 작은 단점이 있음  
* 그러나 목표 누적 정확도에 도달하도록 후보 수를 증가시킬 수 있음  


# 4 Evaluation  
* 단일 모델 및 앙상블 모델 구성 모두에 대해 산업 응용 프로그램에 흔한 강력한 BERT 및 TARS 기준선과 비교하여 제안된 XTARS 접근 방식을 평가  
* 평가는 모든 접근 방식을 MC의 대규모 다중 클래스 분류 시나리오에서 테스트하고 제안된 부정 샘플링 기술의 영향을 평가  
* 특정(상위 80%) 및 불확실한 샘플(하위 50% 및 하위 25%)에 대한 성능을 구체적으로 평가  
* 불확실한 분할은 몇 샷 제도(Table 2)에서의 성능을 평가하는 것을 목표로 함  

## 4.1 Experimental setup  
* 언어 모델 및 앙상블: BLURB 리더보드(Gu et al. 2020)에서 생물 의학 작업에 대한 점수가 가장 높은 사전 훈련된 언어 모델, 즉 bioBERT(Lee et al. 2019), PubMedBERT(Gu et al. 2020), sciBERT(Beltagy et al. 2019)를 선택  
* 각 훈련 실행에 대해 임의 시드 초기화만 다른 여러 모델을 훈련시킨 다음 분류 확률을 평균하여 모델 앙상블을 수행  


### Estimation of uncertainty.  
* 불확실성을 추정하기 위해 예측 엔트로피 개념을 활용  
* 이는 예측 분포에서 포함된 평균 정보량을 포착  
* 예측 엔트로피가 크면(작으면) 예측이 더 불확실(확실)  
* 예측 확률이 모두 같을 때 예측 엔트로피가 최대에 도달하고, 하나의 확률이 1이고 나머지가 0일 때 0이 됨  

## 4.2 Experimental results  
* LLT와 PT 모두에 대한 결과는 예상대로 PT에 대한 정확도가 LLT보다 모든 실험에서 더 높으며, 덜 확실한 예측에 대해서는 낮음  
* 자세히 살펴보면 다음과 같은 관찰 결과:  
** XTARS는 강력한 단일 모델 성능을 보여줌  
** 상위 10개 행에서, 세 가지 BERT 모델(PubMedBERT, BioBERT, sciBERT)은 대략 비슷한 성능을 보여줌  
** 모든 샘플을 고려했을 때, 특히 LLT에 대해, TARS는 BERT보다 성능이 떨어짐  
** 매우 불확실한 샘플(btm-25%)에서도 이득은 미미  
** 더 많은 부정 샘플을 포함시키는 것은 결과를 개선하지 않음  
** XTARS는 다른 모든 단일 모델 기준을 대부분 상당히 능가하며 LLT 정확도에서 최고 단일 모델 BERT보다 3.6포인트, PT 정확도에서 1.1포인트 높은 성능을 보임  
** 부정 샘플링 기법의 영향을 분석한 결과, XTARS의 top-k와 softmax 재조정 샘플링은 TARS보다 성능이 약간 향상되었지만 크게 향상되지는 않음  
** 대조적으로, 훈련된 BERT 분류 모델에서 부정 샘플을 포함시키면 성능이 크게 향상(LLT 정확도에서 11.3포인트 증가), 단일 모델 설정에서 XTARS가 모든 BERT 모델을 능가하게 만듬  
** 이는 큰 라벨 세트로 효과적으로 학습하기 위해 어려운 부정이 필요함을 시사  
** 이 두 샘플링 전략을 결합하면 성능이 더욱 향상  
** 모델 불확실성의 영향을 분석한 결과, XTARS는 전반적으로 BERT 성능을 향상시키며, 특히 불확실한 샘플(btm-25%)에서 더 큰 향상을 보임  (9.7포인트 증가).   
** 이는 또한 랜덤 시드 초기화에 대한 안정성이 증가함을 나타냄    
** 앙상블 결과는 모든 모델에 대해 성능 향상을 가져오며, BERT가 XTARS보다 더 큰 이득을 얻음  

<br/>
# 5 Discussion and practical deployment  
* 실험 평가에서 XTARS는 단일 모델 설정에서 모든 다른 접근법을 크게 능가하고 앙상블 설정에서도 약간 능가하는 것으로 나타남    
* 그러나 모델 배치 시 전체적인 정확도만큼이나 다른 실제 고려 사항을 고려해야 함  
* XTARS의 한 가지 단점은 모델을 훈련시키기 전에 완전히 훈련된 다중 클래스 분류 BERT 모델이 필요하다는 것  
* 본 시스템은 지속적으로 운영되는 시스템이며 MedDRA와 훈련 데이터가 지속적으로 확장되기 때문에, 정기적인 간격으로 모델을 재훈련하는 자동화된 시스템을 구현  
* 여기서는 높은 정확도와 상대적으로 낮은 복잡성 때문에 BERT 앙상블 설정(3 × 5)을 선택  

* 실제 시스템에서의 인간 검증. 배포 후 실제 성능을 추정하기 위해 백 테스팅을 수행:   
** 예측을 인간 코더가 부여한 라벨과 비교  
** 실제 시스템에서 총 2,452개의 예측에 대해 LLT 정확도가 90.9%이며 커버리지가 80.3%임을 발견  
** 산업 관점에서 이 정확도는 코딩 효율성을 크게 향상  
** 인간 코더는 시스템 제안을 많은 경우 단순히 수락할 수 있으므로, 코더가 수동으로 가장 적합한 LLT 코드를 검색해야 하는 데이터 포인트의 작은 부분만 남김  
** 가장 확실한 상위 80% 샘플의 경우 거의 모든 모델이 MC에 대한 95% PT 정확도의 규제 요건을 충족  

# 6 Related work  
## 대규모 텍스트 분류  
* 문헌은 전자 건강 기록(환자 메모 또는 서술)의 비정형 부분에 여러 의료 코드를 할당하는 데 중점(Baumel 등, 2018; Mullenbach 등, 2018; Rios 및 Kavuluru, 2018; Shi 등, 2017; Xie 및 Xing, 2018; Kim 및 Ganapathi, 2021)  
* 그러나 이 경우에는 임상 시험 데이터 수집 과정에서 코딩 과정에 관련된 텍스트 스니펫(RT)만 수집됨    
* 각 텍스트 스니펫은 단일 코드에 할당되어야 함  

## 제로/퓨샷 학습
* NLP에서 퓨샷 학습은 주로 메타 학습(Finn 등, 2017)을 통해 수행  
* 메타 학습은 예를 들어 기계 번역(Gu 등, 2018), 감정 분석(Yu 등, 2018), 대화 의도 분류(Geng 등, 2019) 등에 적용  
** 본 논문에서는 입력 텍스트(reported term)과 라벨(lowest level term)이 주어지고 올바른 것인지 이진 분류하는 식으로 퓨샷 적용  
** 제로샷의 경우 직접 예시를 보지 않은 버트 기반 후보군을 입력으로 줌  
* 그러나 이러한 접근 방식은 제로샷 예측을 수행할 수 없음   
* Yin 등(2019)은 제로/퓨샷 텍스트 분류를 텍스트 함축 문제로 취급하도록 제안  
* 입력 텍스트는 전제로 작용하고 라벨은 가설로 사용  
* Halder 등(2020)도 비슷한 아이디어를 채택  
* 생물 의학 데이터를 위한 대규모 텍스트 분류에서 제로/퓨샷 학습에 대한 문헌은 드뭅(Chalkidis 등, 2020; Song 등, 2020)    

## 의료 코딩을 위한 배치된 시스템
* Magi-Coder는 약물감시 보고서에서 의료 코드를 얻기 위한 규칙 기반 시스템(Zorzi 등, 2017; Combi 등, 2019)으로, 입력 텍스트를 스캔하여 온톨로지와 일치하는 용어를 찾고 최상의 일치를 투표  
* 그들은 소셜 미디어에서 스크랩한 약물 부작용 데이터 세트에서 평균 정밀도(재현율) 69%(70%)를 달성(Yang 등, 2012)  

# 7 Conclusion  
* 이 논문에서는 의료 코딩(MC) 작업을 소개하고 그 과제들을 논의  
* 저자들은 생산 환경에 배포된 생물의학 변환기 기반 MC 시스템을 개요하고 앙상블이 성능을 향상시킨다는 것을 보여줌  
* 저자들은 매우 큰 라벨 세트와 데이터 포인트의 라벨에 대한 긴 꼬리 분포에 적합한 제로/퓨샷 학습 접근법인 XTARS를 소개  
* XTARS의 주요 제한 사항은 (성능이 좋은) BERT 모델이 필요하다는 것으로, 이는 모델의 복잡성을 증가  
* 저자들은 MC에서 XTARS의 유망한 결과를 보고하고 다른 작업에 적용할 수 있도록 코드를 연구 커뮤니티에 공개   


