---
layout: post
title:  "[2023]Evaluating the Zero shot Robustness of Instruction tuned Language Models"  
date:   2024-04-28 16:29:29 -0400
categories: study
---

{% highlight ruby %}


한줄 요약: 


짧은 요약(Abstract) :    
* 최근 지시문 미세조정이 새로운 작업에 대한 대규모 언어 모델(LLMs)의 제로샷 능력을 향상시키는 유망한 접근 방식으로 부상  
* 이 기술은 특히 중간 크기의 LLMs의 성능을 향상시키는 데 강점을 보여, 때로는 훨씬 더 큰 모델 변형과 경쟁할 수 있는 성능을 유도  
* 이 논문에서는 두 가지 질문을 던집니다:   
** (1) 지시어 조정된 모델들은 지시문의 특정 표현에 얼마나 민감한가?   
** (2) 우리는 어떻게 이러한 자연 언어 변형에 대해 그들을 더 강건하게 만들 수 있을까?  
* 전자에 대한 답을 위해, 우리는 NLP 실무자들이 수동으로 작성한 319개의 지시문을 수집하고, 널리 사용되는 벤치마크에 포함된 80개 이상의 고유 작업에 대해 이러한 지시문의 변동성과 평균 성능을 평가하여 지시문 미세조정 중 관찰된 지시문 표현과 비교  
* 저자들은 새로운(관찰되지 않은) 하지만 적절한 지시문 표현을 사용하는 것이 일관되게 모델 성능을 저하시킴을 찾음  
* 더 나아가, 이러한 자연스러운 지시문은 의미적 동등성에도 불구하고 하류 성능에서 넓은 변동성을 나타냄    
* 다시 말해, 지시어 조정된 모델들은 지시문 재구성에 특별히 강건하지 않음   
* 저자들은 이 문제를 완화하기 위한 간단한 방법을 제안하며, 의미적으로 동등한 지시문의 표현 간 유사성을 극대화하기 위해 '소프트 프롬프트' 임베딩 파라미터를 도입하고 최적화하는 것을 포함  
* 저자들은 이 방법이 일관되게 지시어 조정된 모델의 강건성을 향상시킨다는 것을 보여줌  


* Useful sentences :  
*   


{% endhighlight %}  

<br/>

[Paper link](https://drive.google.com/drive/folders/1tP3X1VCpp-Q5QNN8NXIXlD_VgzB8Xa_P?usp=drive_link)  
[~~Lecture link~~]()  

<br/>

# 단어정리  
*  
 
<br/>
# Methodology    
* 논문 "Evaluating the Zero-shot Robustness of Instruction-tuned Language Models"에서 제안된 방법론은 크게 다음과 같은 절차를 따름:
** 새로운 지시문 수집: 연구자들은 NLP 분야의 대학원생들로부터 319개의 새로운 작업 지시문을 수집합니다. 이들 지시문은 훈련 과정에서 사용된 것들과는 다르게 구성되어 있으며, 이를 통해 모델이 훈련되지 않은 새로운 지시문에 대한 반응을 평가합니다 . 
** 모델 평가: 수집된 새로운 지시문을 사용하여, 다양한 지시어 조정 모델(예: Flan-T5, Alpaca, T0)의 강건성을 두 가지 벤치마크(MMLU와 BBL)를 통해 평가합니다. 이 과정에서 모델이 새로운 지시문에 어떻게 반응하는지, 성능이 어떻게 달라지는지 관찰합니다 .  
** 강건성 향상 방법 제안: 연구자들은 '소프트 프롬프트' 임베딩 파라미터를 도입하여 모델이 의미적으로 동등한 지시문 사이에서 유사한 표현을 유도하도록 합니다. 이는 크로스 엔트로피 손실과 함께 최적화되며, 새로운 지시문을 사용할 때 모델의 성능 저하를 완화하는 데 도움이 됩니다 .  
* 이 방법론은 지시어 조정된 모델들이 다양한 지시문 표현의 변화에 강건하도록 만드는 데 중점을 두고 있으며, 이는 특히 지시문의 재구성에 취약한 현상을 개선하려는 시도입니다.


<br/>  
# Results  
* 논문 "Evaluating the Zero-shot Robustness of Instruction-tuned Language Models"에서 얻은 결과들은 다음과 같음:  

* 성능 저하: 새롭고 관찰되지 않은 지시문을 사용할 경우, 모델의 성능이 크게 저하되는 경향이 있습니다. 특히, 훈련 시 본 적 없는 의미론적으로 동등한 지시문을 사용했을 때 평균적으로 6.9%의 절대 성능 하락을 관찰했습니다 .  
* 강건성 향상: '소프트 프롬프트' 임베딩 파라미터를 도입하고 최적화함으로써, 의미적으로 동등한 지시문 간의 표현을 유사하게 유도하려는 새로운 방법을 제안했습니다. 이 방법은 일관되게 새로운 지시문을 사용할 때 모델의 성능을 향상시켰으며, 특히 BBL-QA에서 큰 강건성 향상을 보여주었습니다 . 
* 임베딩 거리 감소: 소프트 프롬프트 정렬 전후로 관찰된 지시문과 관찰되지 않은 지시문 사이의 임베딩 거리가 줄어들었습니다. 이는 소프트 프롬프트 정렬이 의미적으로 동등한 지시문 사이의 유사성을 증가시키는 효과적인 메커니즘이라는 것을 시사합니다 .  
* 이러한 결과는 지시어 조정 모델들이 지시문의 표현 변화에 강건하지 않음을 보여주며, 제안된 방법이 이러한 취약점을 개선할 수 있는 유효한 접근 방식임을 입증합니다.  









<br/>  
# 요약  
* 이것은 OOD를 다룬 이전 것들 중 하나와 비슷, 대신 Robustness를 늘리기 위해 소프트 프롬프트 임베딩 파라미터를 제안-> 동등한 지시문 사이에서 유사한 표현을 유도하는 것(학습시키는 것)  