---
layout: post
title:  "[2023]Adversarial Machine Learning: Attack Surfaces, Defence Mechanisms, Learning Theories in Artificial Intelligence: Chapter1: Adversarial Machine Learning"  
date:   2024-04-02 10:03:29 -0400
categories: study
---

{% highlight ruby %}


한줄 요약: 

짧은 요약(Abstract) :    
적대적 학습 알고리즘은 주어진 기계 학습 알고리즘의 취약점을 이용하도록 특별히 설계됨  
다양한 공격 시나리오와 정책 하에 학습 알고리즘을 훈련시켜 이러한 취약점을 모의함  
공격 시나리오는 지능적인 적에 의해 가정되며 최적의 공격 정책은 하나 또는 여러 최적화 문제를 해결함으로써 얻어짐  
따라서 공격에 대응하도록 설계된 학습 알고리즘은 해당 공격에 강해지며 취약점이 더 이상 취약하지 않게 됨  
따라서 적대적 학습의 목표는 공격 시나리오에 대항하여 검색 및 최적화 알고리즘의 목적 함수에 대한 해결책을 찾는 것으로 생각할 수 있음  

게임 이론적 적대적 학습에서 적대적 예제는 다양한 공격 시나리오에서 기계 학습 알고리즘을 설계함으로써 생성됨  
적대적 조작을 위한 최적의 공격 전략은 종종 비선형 및 비볼록 최적화 문제로 공식화되는 해결책으로 구성됨  
적대적 예제는 제한된 데이터로 훈련된 기계 학습 모델이 모든 가능한 입력에 대해 예상 출력을 생성해야 하기 때문에 감지하기 어려움  
강화 학습 에이전트도 인간에게 미묘하게 인식되지 않는 섭동의 존재 하에 성능이 저하될 수 있음  

저자들은 기존의 적대적 기계 학습 알고리즘을 각각 공격 시나리오와 방어 메커니즘 측면에서 검토하여 신뢰할 수 있는 데이터 분석 시스템과 견고한 패턴 인식 시스템을 배포하는 기술을 요약함  
또한 저자들은 게임 이론적 적대적 학습 및 적대적 강화 학습에서 최첨단 기술을 요약함  

저자들의 알고리즘은 공격 시나리오의 강도와 관련성에 따라 평가됨  
공격 시나리오가 가장 나쁜 경우에는 균형 해결책이 지역 최적해이고 가장 좋은 경우에는 전역 최적해임  
따라서 새로운 CNNsecure는 다수의 적에 의해 생성된 적대적 데이터에 성공적으로 적응한 반면 기존의 CNNoriginal는 각 적 Li가 주어진 훈련/테스트 데이터 분포에서 게임 i를 플레이하여 생성한 각 적대적 조작에 취약함  
저자들의 알고리즘은 CNN의 성능에 영향을 미치는 데이터 샘플을 찾을 수 있음  
저자들의 적대적 공격에서 회복할 수 있는 CNN은 기저 데이터 분포의 예기치 않은 변화에 더 잘 대처할 수 있음  
적과 학습자 사이의 게임은 기저 데이터 분포에서 훈련된 CNN을 위한 적대적 데이터 조작을 생성할 수 있게 함

Useful sentences :  
*   


{% endhighlight %}  

<br/>

[Paper link](https://drive.google.com/drive/folders/1p1MrsOhGYsfzcphgMb3DdRDPq2tQpOSm?usp=sharing)  
[~~Lecture link~~]()  

<br/>

# 단어정리  
* 

<br/>
# 1.1 Adversarial Learning Frameworks     
전통적인 기계 학습 모델들은 훈련 데이터 샘플, 테스트 데이터 샘플, 그리고 검증 데이터 샘플이 동일한 독립 동일 분포의 데이터 분포를 따른다고 가정함  
이러한 가정은 악의적 의도를 가진 지능적인 적에 의한 공격으로부터 기계 학습 모델의 보안 취약성을 만들어냄  
주어진 훈련 데이터 샘플을 가지고 이러한 적들은 모델 오류를 증가시키는 적대적 예제를 설계함  
이러한 적대적 예제로부터 학습 시스템을 보호하는 것은 인공 지능 보안 진단, 생성 학습, 딥러닝, 정보 보안, 자율 시스템, 지능형 시스템, 그리고 데이터 분석 등의 연구 분야에서 활발히 연구되고 있음  

적대적 예제는 적의 공격이 학습 모델의 훈련을 완료한 후에 계획되어 학습 모델이 새로운 샘플에 반응할 수 없는 한 학습 모델을 오도할 수 있음  
이러한 관찰로부터 적대적 알고리즘은 적을 학습 모델의 훈련 과정에 포함시킴  
따라서 적대적 알고리즘은 적대적 기계 학습을 학습 모델과 하나 이상의 지능적인 적들 간의 상호작용으로 모델링함  

게임 이론은 학습 모델과 지능적인 적 사이의 상호작용을 학습자와 적 간의 진화하는 전략들의 상호작용 측면에서 연구할 수 있는 틀을 제공함  
게임 이론 상호작용은 처음에 생명 과학에서 생물 시스템의 집단 간의 상호작용을 연구하는 비선형 미분 방정식으로 공식화됨  

기계 학습에서 손실 함수는 분석 예측의 분포에 대한 정보 불확실성의 영향을 정량화함  
적대적 알고리즘은 학습 환경에 적대적 예제로 진화하는 변화를 시뮬레이션하는 합리적인 적응적 적들의 존재에서 훈련 데이터에 대한 모델 과적합을 방지하는 훈련 과정을 위한 기계 학습 손실 함수를 공식화함  

게임 이론적 적대적 학습에서 적대적 예제는 적의 전략 공간에서 다양한 공격 시나리오 하에 기계 학습 알고리즘을 설계함으로써 생성됨  
적대적 조작을 위한 최적의 공격 전략은 종종 비선형이고 비볼록 최적화 문제의 해결책으로 공식화됨  

적대적 예제는 제한된 데이터로 훈련된 기계 학습 모델이 모든 가능한 입력에 대해 예상된 출력을 생성해야 하기 때문에 감지하기 어려움  
강화 학습 에이전트도 인간에게 미묘하게 인지될 수 없는 섭동의 존재 하에서 적대적 예제에 의해 조작될 수 있어 성능이 저하될 수 있음  

이어지는 문헌 검토에서는 공격 시나리오와 방어 메커니즘 측면에서 각기 다른 기존의 적대적 기계 학습 알고리즘에 대한 개요를 제공함  
또한 신뢰할 수 있는 데이터 분석 시스템과 견고한 패턴 인식 시스템을 배포하기 위한 기술을 요약함  
게임 이론적 적대적 학습과 적대적 강화 학습에서의 최첨단 기술도 요약함

<br/>
# 1.1.1 Adversarial Algorithms Comparisons     
이 섹션에서는 문헌 검토와 적대적 학습 알고리즘의 공격 분류를 제시함  
적대적 알고리즘들은 알고리즘 설계와 알고리즘 적용 측면에서 표 1.1과 1.2에 요약되어 있음  
알고리즘들은 주로 적대적 비용 함수 즉, 적의 존재 하에서 학습 알고리즘의 예상 성능을 측정하는 비용 함수를 기준으로 비교됨  
이 비용 함수는 다양한 적대적 학습 알고리즘마다 다르게 공식화됨  
표의 열은 적대적 학습 알고리즘을 비교하기 위한 다양한 특징들을 나열하고 있음  
저자들의 알고리즘은 "게임 이론 : 딥러닝"으로 명명됨  
표의 행은 비교 대상인 다양한 알고리즘들을 나열함  
행을 가로질러 적대적 데이터에 취약한 계산 모델인 특징 추출을 위한 딥러닝, 서포트 벡터 머신, 그리고 분류기 앙상블이 나열됨  
시뮬레이션된 적대적 공격을 위한 입력 데이터는 텍스트 스팸, 이미지 스팸, 그리고 생체 인식 스팸으로 취함  
알고리즘들은 비용 함수, 검색 알고리즘, 수렴 조건, 공격 전략, 공격 영향, 보안 위반, 적의 지식, 알고리즘 동작, 그리고 학습 게임 측면에서 비교됨  
"비용 함수"는 적대적 데이터에 대한 해결책을 찾기 위한 목적 함수임  
"검색 알고리즘"은 최적의 해결책을 찾기 위해 사용되는 알고리즘임  
"수렴 조건"은 적대적 데이터를 생성하기 위한 검색 기준임  
"공격 전략"은 적이 작동하는 공격 시나리오임  
전략의 "공격 영향"은 적이 학습 알고리즘에 대한 훈련 데이터 및 테스트 데이터 입력에 대한 접근을 결정함  
"보안 위반"은 적의 공격 목적임  
"적의 지식"은 적의 의미 정보임  
"알고리즘 동작"은 학습 알고리즘이 적대적 데이터 조작에 적응하기 위해 취하는 조치임  
표에서 볼 수 있듯이 대부분의 기존 연구 작업은 비용 함수에 게임 이론 공식을 추가하지 않음  
따라서 대부분의 기존 학습 알고리즘은 지속적인 적대적 데이터 조작에 적응할 수 없음  
"학습 게임" 열에서 보여지듯이 저자들의 알고리즘은 딥러닝 모델에 입력되는 훈련 및 테스트 데이터 분포의 게임 이론 기반 공식을 가진 유일한 적대적 학습 알고리즘임

<br/>
# 1.2 Adversarial Security Mechanisms  
표 1.1과 1.2 외에도 기존의 적대적 학습 알고리즘과 그 적용 분야는 학습자의 방어 메커니즘과 해당 적의 공격 시나리오로 분류될 수 있음  
학습자의 방어 메커니즘은 보안 학습 알고리즘 설계, 다중 분류기 시스템, 프라이버시 보존 기계 학습, 그리고 적을 오도하기 위한 무작위화 또는 잘못된 정보 사용을 제안함  

빅지오 등은 패턴 분류의 모델 선택 및 성능 평가 단계를 확장하는 경험적 프레임워크 측면에서 학습자의 방어 메커니즘에 대해 논의함  
이 프레임워크는 '보안 설계'를 위한 학습자 교육을 '보안 은폐'보다 권장함  
이 프레임워크는 공격을 받는 생성 학습 모델과 판별 학습 모델의 경우에 제안된 방어 메커니즘을 검증하기 위한 추가 단계를 권장함  

가장 관련성 높은 적대적 공격을 사전에 예측하기 위해 잠재적 공격 시나리오를 시뮬레이션하는 가정 시나리오 분석을 수행함  
공격 시나리오를 적의 목표, 지식, 그리고 능력 측면에서 정의함  
훈련 데이터와 테스트 데이터에 대한 교차 검증 샘플에서 잠재적 공격을 공식적으로 설명할 수 있는 생성 데이터 분포 모델을 제안함  

학습 알고리즘의 보안에 대한 가정이 이루어지며, 그 다음 모델 성능은 빅지오 등이 제안한 프레임워크에 따라 시뮬레이션된 최적의 공격 전략 하에 평가됨

<br/>
# 1.2.1 Adversarial Examples Taxonomies  
파페르노 외는 기계 학습 훈련 과정과 추론 과정에서 발견되는 적대적 조작의 단계를 요약한 기계 학습 위협 모델을 제시함  
기계 학습 훈련 과정에서 적은 온라인 데이터 수집 과정이나 오프라인 데이터 수집 과정을 조작할 수 있음  
이러한 적대적 조작은 적대적 예제를 주입하거나 학습 모델의 결정 경계를 수정할 의도로 훈련 데이터를 수정함  
기계 학습 추론 과정에서 적은 학습 모델의 매개변수에 대해 블랙박스 공격이나 화이트박스 공격을 계획할 수 있음  
이러한 공격 설정은 훈련 데이터와 실행 시간 데이터 분포 사이의 분포 이동을 유발함  

파페르노 외는 기계 학습 보안을 기밀성, 무결성, 그리고 가용성 모델의 프리즘을 통해 바라봄  
여기서 적은 분류기의 매개변수, 라벨, 그리고 특징을 각각 목표로 삼음  
기계 학습 보안과 대비되어 기계 학습 프라이버시는 훈련 및 실행 시간 데이터 분포가 다를 때, 학습 모델이 노출하는 데이터 양이 차등 프라이버시 예산에 의해 제한될 때, 그리고 학습 모델의 방어가 학습 출력에 공정성, 해석 가능성, 그리고 투명성을 제공할 때 모델 성능 측면에서 탐구됨  
적대적 환경은 모델 복잡성, 모델 정확성, 그리고 모델 회복력에 영향을 미치며 적대적 학습을 위한 'no free lunch' 정리 측면에서 공식화됨  
파페르노 외는 아마도 대략적으로 정확한(PAC) 학습 프레임워크 내에서 기계 학습 추론 중에 게임 이론적 적대적 학습을 동기화함


<br/>
# 1.3 Stochastic Game Illustration in Adversarial Deep Learning  
그림 1.2는 연구의 게임 공식을 흐름도로 나타낸 학습 과정을 보여줌  
CNNoriginal은 훈련 데이터 Xtrain에서 훈련되고 테스트 데이터 Xtest에서 평가되어 실험에서 '학습자 성능'을 제공함  
그림 1.2는 두 명의 플레이어 게임을 보여줌  
이 게임은 각 상호 작용 시 적과 학습자가 수행하는 움직임을 가지고 있음  
이 움직임에서 적은 진화 연산자에서 생성된 적대적 샘플로 학습자를 목표로 함  
그 후 학습자는 새로운 교차 검증 샘플에서 CNN을 재훈련함으로써 적대적 데이터에 대한 딥러닝 연산자를 조정함  

적대적 조작을 다룰 수 있도록 더 잘 갖춰진 최종 딥러닝 네트워크 CNNsecure를 생성하는 게임을 두 명의 플레이어가 진행함  
처음의 딥러닝 네트워크 CNNoriginal보다 더 잘 준비된 것임  

여러 적들이 참여하는 다수의 두 명의 플레이어 순차 게임에서 M명의 적들의 집합 L은 이 성능을 목표로 함  
각 두 명의 플레이어 게임에서 원본 및 생성된 데이터 샘플에서 훈련되고 적대적 데이터에서 테스트된 CNN들은 각각 CNNmanipulated-cnn 및 CNNmanipulated-gan으로 주어짐  
이 모든 CNN들은 '조작된 학습자 성능'이라는 용어로 제공됨  
원본 훈련 및 테스트 데이터인 Xtrain 및 Xtest에서 훈련된 원래 CNN인 CNNoriginal보다 CNNmanipulated-cnn 및 CNNmanipulated-gan이 현저히 성능이 떨어짐을 발견함  
따라서 적대적 조작이 학습자를 공격하는 데 성공했다고 결론 내림  
새로운 합성곱 신경망인 CNNsecure는 적대적 조작에 적응하기 위해 다시 훈련됨  
'안전한 학습자 성능'으로 제공됨  
조작된 CNN인 CNNmanipulated-cnn 및 CNNmanipulated-gan보다 더 나음이 발견됨  

따라서 새로운 CNNsecure는 다수의 적에 의해 생성된 적대적 데이터에 성공적으로 적응한 반면 주어진 CNNoriginal은 각 적 Li가 주어진 훈련/테스트 데이터 분포에서 게임 i를 진행하여 생성한 각 적대적 조작에 취약함을 결론 내림  
저자들의 알고리즘은 CNN의 성능에 영향을 미치는 데이터 샘플을 찾을 수 있음  
저자들의 적대적 공격에서 회복할 수 있는 CNN은 기저 데이터 분포의 예상치 못한 변화에 더 잘 대처할 수 있음  
적과 학습자 사이의 게임은 기저 데이터 분포에서 훈련된 CNN을 위한 적대적 데이터 조작을 생성할 수 있게 함

<br/>  
# 요약  
* 