---
layout: post
title:  "[2017]Adversarial Examples for Evaluating Reading Comprehension Systems"  
date:   2024-05-18 15:10:29 -0400
categories: study
---

{% highlight ruby %}


í•œì¤„ ìš”ì•½: 


ì§§ì€ ìš”ì•½(Abstract) :    
### Abstract

í‘œì¤€ ì •í™•ë„ ì§€í‘œëŠ” ë…í•´ ì‹œìŠ¤í…œì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŒì„ ë‚˜íƒ€ë‚´ì§€ë§Œ, ì´ëŸ¬í•œ ì‹œìŠ¤í…œì´ ì§„ì •ìœ¼ë¡œ ì–¸ì–´ë¥¼ ì´í•´í•˜ëŠ” ì •ë„ëŠ” ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤.  

ì‹œìŠ¤í…œì´ ì‹¤ì œ ì–¸ì–´ ì´í•´ ëŠ¥ë ¥ì„ ë³´ìƒí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ìŠ¤íƒ í¬ë“œ ì§ˆë¬¸ ì‘ë‹µ ë°ì´í„°ì…‹(SQuAD)ì— ëŒ€í•œ ì ëŒ€ì  í‰ê°€ ì²´ê³„ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.  

ìš°ë¦¬ì˜ ë°©ë²•ì€ ì‹œìŠ¤í…œì´ ë‹µì„ ë³€ê²½í•˜ì§€ ì•Šê±°ë‚˜ ì‚¬ëŒì„ í˜¼ë™ì‹œí‚¤ì§€ ì•Šê³  ì»´í“¨í„° ì‹œìŠ¤í…œì„ ë°©í•´í•˜ë„ë¡ ìë™ìœ¼ë¡œ ìƒì„±ëœ ë¬¸ì¥ì„ í¬í•¨í•˜ëŠ” ë‹¨ë½ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.  

ì´ëŸ¬í•œ ì ëŒ€ì  ì„¤ì •ì—ì„œëŠ” 16ê°œì˜ ë°œí‘œëœ ëª¨ë¸ì˜ ì •í™•ë„ê°€ í‰ê·  75%ì˜ F1 ì ìˆ˜ì—ì„œ 36%ë¡œ ë–¨ì–´ì§‘ë‹ˆë‹¤. ë¹„ë¬¸ë²•ì  ë‹¨ì–´ ì‹œí€€ìŠ¤ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ê²½ìš°, 4ê°œì˜ ëª¨ë¸ì˜ í‰ê·  ì •í™•ë„ëŠ” 7%ë¡œ ë”ìš± ê°ì†Œí•©ë‹ˆë‹¤.  

ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ í†µì°°ë ¥ì´ ì–¸ì–´ë¥¼ ë³´ë‹¤ ì •í™•í•˜ê²Œ ì´í•´í•˜ëŠ” ìƒˆë¡œìš´ ëª¨ë¸ ê°œë°œì„ ì´‰ì§„í•˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤.  

### Original Abstract

Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear.  

To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD).  

Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans.  

In this adversarial setting, the accuracy of sixteen published models drops from an average of 75% F1 score to 36%; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7%.  

We hope our insights will motivate the development of new models that understand language more precisely.   


* Useful sentences :  
*   


{% endhighlight %}  

<br/>

[Paper link](https://drive.google.com/drive/folders/1s9zUjtwX3LIOeNYAZ4khcSKBCDwEnyKU?usp=sharing)  
[Lecture link](https://aclanthology.org/D17-1215.mp4)   

<br/>

# ë‹¨ì–´ì •ë¦¬  
*  
 
<br/>
# Methodology    
## ì ëŒ€ì  í‰ê°€ì˜ ì¼ë°˜ì ì¸ í”„ë ˆì„ì›Œí¬  

í‘œë©´ì ì¸ ë‹¨ì„œë¥¼ ì˜ì¡´í•˜ë©´ì„œ ì–¸ì–´ë¥¼ ì´í•´í•˜ì§€ ëª»í•˜ëŠ” ëª¨ë¸ì€ ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì˜ˆì¸¡ì— ë„ì›€ì´ ë˜ëŠ” ë‹¨ì„œë¥¼ ì¸ì‹í•¨ìœ¼ë¡œì¨ í‰ê·  F1 ì ìˆ˜ì— ë”°ë¼ ì„±ê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê¸°ì¡´ì˜ ëª¨ë¸ì´ ê°„ë‹¨í•œ íŒ¨í„´ì„ ë„˜ì–´ì„œì„œ ë°°ì› ëŠ”ì§€ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” í…ŒìŠ¤íŠ¸ ì˜ˆì œë¥¼ ë³€ê²½í•˜ì—¬ ë¶€ì¡±í•œ ëª¨ë¸ì„ í˜¼ë™ì‹œí‚¤ëŠ” ì ëŒ€ì  í‰ê°€ ë°©ë²•ì„ ë„ì…í•©ë‹ˆë‹¤.

Figure 1ì˜ ì˜ˆë¥¼ ê³ ë ¤í•´ë³´ë©´: BiDAF ì•™ìƒë¸” ëª¨ë¸ì€ ì›ë˜ ì˜¬ë°”ë¥¸ ë‹µì„ ì œê³µí–ˆì§€ë§Œ, ì ëŒ€ì  ë°©í•´ ë¬¸ì¥ì´ ì¶”ê°€ë˜ë©´ í˜¼ë™ë©ë‹ˆë‹¤.

ìš°ë¦¬ëŠ” ì ëŒ€ìë¥¼ (p, q, a) ì˜ˆì œë¥¼ ë°›ì•„ ìƒˆë¡œìš´ ì˜ˆì œ (p', q', a')ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¡œ ì •ì˜í•©ë‹ˆë‹¤.

ì ëŒ€ì  ì •í™•ë„ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë©ë‹ˆë‹¤: ğ´ğ‘‘ğ‘£(ğ‘“)=(1/âˆ£ğ·ğ‘¡ğ‘’ğ‘ ğ‘¡âˆ£)âˆ‘(ğ‘,ğ‘,ğ‘)âˆˆğ·ğ‘¡ğ‘’ğ‘ ğ‘¡ğ‘£(ğ´(ğ‘,ğ‘,ğ‘,ğ‘“),ğ‘“))

í‘œì¤€ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜ëŠ” ëª¨ë¸ì´ ì˜¬ë°”ë¥¸ ë‹µì„ ì–»ëŠ” í…ŒìŠ¤íŠ¸ ë¶„í¬ì˜ ë¹„ìœ¨ì„ ì¸¡ì •í•˜ì§€ë§Œ, ì ëŒ€ì  ì •í™•ë„ëŠ” ì ëŒ€ì ìœ¼ë¡œ ì„ íƒëœ ë³€ê²½ì—ë„ ë¶ˆêµ¬í•˜ê³  ëª¨ë¸ì´ ê²¬ê³ í•˜ê²Œ ì˜¬ë°”ë¥¸ ë¹„ìœ¨ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

ì´ ì–‘ì´ ì˜ë¯¸ë¥¼ ê°€ì§€ë ¤ë©´, ì ëŒ€ìëŠ” ë‘ ê°€ì§€ ê¸°ë³¸ ìš”êµ¬ ì‚¬í•­ì„ ì¶©ì¡±í•´ì•¼ í•©ë‹ˆë‹¤: ì²«ì§¸, (p', q', a') íŠœí”Œì´ ìœ íš¨í•´ì•¼ í•˜ë©°, ì¸ê°„ì´ (p', q', a')ì„ ë³´ê³  ì˜¬ë°”ë¥¸ ë‹µì´ë¼ê³  íŒë‹¨í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë‘˜ì§¸, (p', q', a')ì€ ì›ë˜ ì˜ˆì œ (p, q, a)ì™€ "ê°€ê¹Œì›Œì•¼" í•©ë‹ˆë‹¤.

## ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ëŠ” ì ëŒ€ì

ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œëŠ” ì ëŒ€ì  ì˜ˆì œê°€ ì…ë ¥ì— ëˆˆì— ë„ì§€ ì•ŠëŠ” ì–‘ì˜ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ì—¬ ìƒì„±ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì„­ë™ì€ ì´ë¯¸ì§€ì˜ ì˜ë¯¸ë¥¼ ë³€ê²½í•˜ì§€ ì•Šì§€ë§Œ, ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ëŠ” ë³€í™”ì— ê³¼ë¯¼í•œ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

ì–¸ì–´ì— ëŒ€í•œ ì§ì ‘ì ì¸ ìœ ì‚¬ì ì€ ì…ë ¥ì˜ íŒ¨ëŸ¬í”„ë ˆì´ì§•ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë†’ì€ ì •ë°€ë„ì˜ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆ ìƒì„±ì€ ì–´ë ¤ìš°ë©°, ëŒ€ë¶€ë¶„ì˜ ë¬¸ì¥ ìˆ˜ì •ì€ ì‹¤ì œë¡œ ì˜ë¯¸ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.  

## ì—°ê²°í˜• ì ëŒ€ì

íŒ¨ëŸ¬í”„ë ˆì´ì§•ì— ì˜ì¡´í•˜ëŠ” ëŒ€ì‹ , ìš°ë¦¬ëŠ” ì˜ë¯¸ë¥¼ ë³€ê²½í•˜ëŠ” ì„­ë™ì„ ì‚¬ìš©í•˜ì—¬ ì—°ê²°í˜• ì ëŒ€ìë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤. ì—°ê²°í˜• ì ëŒ€ìëŠ” (p + s, q, a) í˜•ì‹ì˜ ì˜ˆì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  

ì—°ê²°í˜• ì ëŒ€ìëŠ” ìƒˆ ë¬¸ì¥ì„ ë‹¨ë½ ëì— ì¶”ê°€í•˜ê³  ì§ˆë¬¸ê³¼ ë‹µë³€ì€ ë³€ê²½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìœ íš¨í•œ ì ëŒ€ì  ì˜ˆì œëŠ” sê°€ ì˜¬ë°”ë¥¸ ë‹µê³¼ ëª¨ìˆœë˜ì§€ ì•ŠëŠ” ê²½ìš°ì…ë‹ˆë‹¤.  

ê¸°ì¡´ ëª¨ë¸ì€ ì´ëŸ¬í•œ ë¬¸ì¥ì„ ì‹¤ì œë¡œ ì§ˆë¬¸ì„ ë‹¤ë£¨ëŠ” ë¬¸ì¥ê³¼ êµ¬ë¶„í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìœ¼ë©°, ì´ëŠ” ëª¨ë¸ì´ ì˜ë¯¸ ë³€ê²½ì— ê³¼ë¯¼í•œ ê²ƒì´ ì•„ë‹ˆë¼ ê³¼ì‰ ì•ˆì •ì„±ì„ ê°–ëŠ”ë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  

ì´ì œ ë‘ ê°€ì§€ êµ¬ì²´ì ì¸ ì—°ê²°í˜• ì ëŒ€ìì™€ ë‘ ê°€ì§€ ë³€í˜•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ADDSENTëŠ” ì§ˆë¬¸ê³¼ ìœ ì‚¬í•´ ë³´ì´ëŠ” ë¬¸ë²•ì ì¸ ë¬¸ì¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤. ë°˜ë©´ ADDANYëŠ” ì„ì˜ì˜ ì˜ì–´ ë‹¨ì–´ ì‹œí€€ìŠ¤ë¥¼ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì„ í˜¼ë™ì‹œí‚µë‹ˆë‹¤.  

## ADDSENT  

ADDSENTëŠ” ì§ˆë¬¸ê³¼ ìœ ì‚¬í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ì˜¬ë°”ë¥¸ ë‹µê³¼ ëª¨ìˆœë˜ì§€ ì•ŠëŠ” ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” 4ë‹¨ê³„ ì ˆì°¨ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

1ë‹¨ê³„ì—ì„œ, ìš°ë¦¬ëŠ” ì§ˆë¬¸ì— ì˜ë¯¸ë¥¼ ë³€ê²½í•˜ëŠ” ì„­ë™ì„ ì ìš©í•˜ì—¬ ê²°ê³¼ì ì¸ ì ëŒ€ì  ë¬¸ì¥ì´ í˜¸í™˜ ê°€ëŠ¥í•˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” WordNetì˜ ë™ì˜ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª…ì‚¬ì™€ í˜•ìš©ì‚¬ë¥¼ êµì²´í•˜ê³ , GloVe ë‹¨ì–´ ë²¡í„° ê³µê°„ì˜ ê°€ì¥ ê°€ê¹Œìš´ ë‹¨ì–´ë¡œ ì´ë¦„ìˆëŠ” ì—”í‹°í‹°ì™€ ìˆ«ìë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.

2ë‹¨ê³„ì—ì„œ, ìš°ë¦¬ëŠ” ì›ë˜ ë‹µë³€ê³¼ ê°™ì€ "ìœ í˜•"ì„ ê°€ì§„ ê°€ì§œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

3ë‹¨ê³„ì—ì„œ, ìš°ë¦¬ëŠ” ë³€ê²½ëœ ì§ˆë¬¸ê³¼ ê°€ì§œ ë‹µë³€ì„ ì‚¬ìš©í•˜ì—¬ ì„œìˆ  í˜•íƒœë¡œ ê²°í•©í•©ë‹ˆë‹¤.

4ë‹¨ê³„ì—ì„œ, ìš°ë¦¬ëŠ” êµ°ì¤‘ ì†Œì‹±ì„ í†µí•´ ì´ëŸ¬í•œ ë¬¸ì¥ì˜ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤. ê° ë¬¸ì¥ì€ 5ëª…ì˜ ì‘ì—…ìê°€ ë…ë¦½ì ìœ¼ë¡œ í¸ì§‘í•˜ì—¬, ê° ì›ì‹œ ë¬¸ì¥ì— ëŒ€í•´ ìµœëŒ€ 5ê°œì˜ ë¬¸ì¥ì´ ìƒì„±ë©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ 3ëª…ì˜ ì¶”ê°€ ì‘ì—…ìê°€ ë¹„ë¬¸ë²•ì ì´ê±°ë‚˜ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ë¬¸ì¥ì„ í•„í„°ë§í•˜ì—¬, ë” ì‘ì€ ì§‘í•©ì˜ ì¸ê°„ì´ ìŠ¹ì¸í•œ ë¬¸ì¥ì„ ìƒì„±í•©ë‹ˆë‹¤.

## ADDANY

ADDANYì˜ ëª©í‘œëŠ” ë¬¸ë²•ì ì´ì§€ ì•Šë”ë¼ë„ ë‹¨ì–´ ì‹œí€€ìŠ¤ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì§€ì—­ íƒìƒ‰ì„ ì‚¬ìš©í•˜ì—¬ í˜¼ë€ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ì ëŒ€ì ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.

ìš°ë¦¬ëŠ” ì¼ë°˜ ì˜ì–´ ë‹¨ì–´ ëª©ë¡ì—ì„œ ë‹¨ì–´ë¥¼ ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”í•œ ë‹¤ìŒ, ê° ë‹¨ì–´ì— ëŒ€í•´ ìµœì„ ì˜ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.

ADDANYëŠ” ADDSENTë³´ë‹¤ í›¨ì”¬ ë” ë§ì€ ëª¨ë¸ ì ‘ê·¼ì„ ìš”êµ¬í•©ë‹ˆë‹¤.

ADDANYëŠ” ì›ë˜ ë‹µê³¼ ëª¨ìˆœë˜ì§€ ì•ŠëŠ” ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” ë³´ì¥ì„ í•˜ì§€ ì•Šìœ¼ë©°, ì‹¤ì œë¡œ ìƒì„±ëœ ë¬¸ì¥ì€ ì˜ë¯¸ê°€ ì—†ëŠ” ë¬¸ë²•ì ì´ì§€ ì•Šì€ ë‹¨ì–´ ì‹œí€€ìŠ¤ì…ë‹ˆë‹¤.


## ADDSENTMOD

ADDSENTì˜ ë³€í˜•ì¸ ADDSENTMODëŠ” ë‹¤ë¥¸ ê°€ì§œ ë‹µë³€ì„ ì‚¬ìš©í•˜ê³ , ì ëŒ€ì  ë¬¸ì¥ì„ ë‹¨ë½ì˜ ëì— ì¶”ê°€í•˜ëŠ” ëŒ€ì‹  ì‹œì‘ ë¶€ë¶„ì— ì¶”ê°€í•©ë‹ˆë‹¤.

------  

## General Framework

A model that relies on superficial cues without understanding language can do well according to average F1 score if these cues happen to be predictive most of the time.

To determine whether existing models have learned much beyond such simple patterns, we introduce adversaries that confuse deficient models by altering test examples.

Consider the example in Figure 1: the BiDAF Ensemble model originally gives the right answer but gets confused when an adversarial distracting sentence is added to the paragraph.

We define an adversary to be a function that takes in an example (p, q, a) and returns a new example (pâ€², qâ€², aâ€²).

The adversarial accuracy is defined as: Adv(f)= (1/âˆ£Dtestâˆ£) âˆ‘ (p,q,a)âˆˆD test v(A(p,q,a,f),f)).

While standard test error measures the fraction of the test distribution over which the model gets the correct answer, the adversarial accuracy measures the fraction over which the model is robustly correct, even in the face of adversarially-chosen alterations.

For this quantity to be meaningful, the adversary must satisfy two basic requirements: first, it should always generate (pâ€², qâ€², aâ€²) tuples that are validâ€”a human would judge aâ€² as the correct answer to qâ€² given pâ€². Second, (pâ€², qâ€², aâ€²) should be somehow â€œcloseâ€ to the original example (p, q, a).

## Semantics-preserving Adversaries

In image classification, adversarial examples are commonly generated by adding an imperceptible amount of noise to the input. These perturbations do not change the semantics of the image, but they can change the predictions of models that are oversensitive to semantics-preserving changes.

For language, the direct analogue would be to paraphrase the input. However, high-precision paraphrase generation is challenging, as most edits to a sentence do actually change its meaning.

## Concatenative Adversaries

Instead of relying on paraphrasing, we use perturbations that do alter semantics to build concatenative adversaries. Concatenative adversaries generate examples of the form (p + s, q, a).

Concatenative adversaries add a new sentence to the end of the paragraph and leave the question and answer unchanged. Valid adversarial examples are precisely those for which s does not contradict the correct answer.

Existing models are bad at distinguishing these sentences from sentences that do in fact address the question, indicating that they suffer not from oversensitivity but from overstability to semantics-altering edits.

Now, we describe two concrete concatenative adversaries, as well as two variants. ADDSENT, our main adversary, adds grammatical sentences that look similar to the question. In contrast, ADDANY adds arbitrary sequences of English words, giving it more power to confuse models.

## ADDSENT

ADDSENT uses a four-step procedure to generate sentences that look similar to the question, but do not actually contradict the correct answer.

In Step 1, we apply semantics-altering perturbations to the question, in order to guarantee that the resulting adversarial sentence is compatible. We replace nouns and adjectives with antonyms from WordNet, and change named entities and numbers to the nearest word in GloVe word vector space.

In Step 2, we create a fake answer that has the same â€œtypeâ€ as the original answer.

In Step 3, we combine the altered question and fake answer into declarative form.

In Step 4, we fix errors in these sentences via crowdsourcing. Each sentence is edited independently by five workers on Amazon Mechanical Turk, resulting in up to five sentences for each raw sentence. Three additional crowdworkers then filter out sentences that are ungrammatical or incompatible, resulting in a smaller set of human-approved sentences.

## ADDANY

The goal of ADDANY is to choose any sequence of words, regardless of grammaticality. We use local search to adversarially choose a distracting sentence.

We first initialize words randomly from a list of common English words and then choose the best word for each position.

ADDANY requires significantly more model access than ADDSENT.

ADDANY does not ensure that the sentences generated do not contradict the original answer; in practice, the generated sentences are gibberish sequences of words.

## ADDSENTMOD

ADDSENTMOD, a variant of ADDSENT, uses different fake answers and prepends the adversarial sentence to the beginning of the paragraph instead of appending it to the end.

<br/>  
# Results  
### ê²°ê³¼ (Results)

**ì£¼ìš” ì‹¤í—˜**

Table 2ëŠ” Match-LSTMê³¼ BiDAF ëª¨ë¸ì´ ë„¤ ê°€ì§€ ì ëŒ€ìì— ëŒ€í•´ ì–´ë–»ê²Œ ìˆ˜í–‰í–ˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

ê° ëª¨ë¸ì€ ëª¨ë“  í˜•íƒœì˜ ì ëŒ€ì  í‰ê°€ì—ì„œ ìƒë‹¹í•œ ì •í™•ë„ í•˜ë½ì„ ê²ªì—ˆìŠµë‹ˆë‹¤.

ADDSENTëŠ” ë„¤ ëª¨ë¸ì˜ í‰ê·  F1 ì ìˆ˜ë¥¼ 75.7%ì—ì„œ 31.3%ë¡œ ê°ì†Œì‹œì¼°ìŠµë‹ˆë‹¤.

ADDANYëŠ” ë” íš¨ê³¼ì ì´ì–´ì„œ í‰ê·  F1 ì ìˆ˜ë¥¼ 6.7%ë¡œ ë–¨ì–´ëœ¨ë ¸ìŠµë‹ˆë‹¤.

ADDONESENTëŠ” ëª¨ë¸ ë…ë¦½ì ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  ADDSENTì˜ íš¨ê³¼ë¥¼ ë§ì´ ìœ ì§€í–ˆìŠµë‹ˆë‹¤.

ë§ˆì§€ë§‰ìœ¼ë¡œ, ADDCOMMONì€ ì¼ë°˜ì ì¸ ë‹¨ì–´ë§Œ ì¶”ê°€í–ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  í‰ê·  F1 ì ìˆ˜ë¥¼ 46.1%ë¡œ ë–¨ì–´ëœ¨ë ¸ìŠµë‹ˆë‹¤.

ìš°ë¦¬ëŠ” ë˜í•œ ìš°ë¦¬ì˜ ì ëŒ€ìê°€ ê°œë°œ ì¤‘ì— ì‚¬ìš©ë˜ì§€ ì•Šì€ ëª¨ë¸ì„ í˜¼ë™ì‹œí‚¬ ë§Œí¼ ì¼ë°˜ì ì´ë¼ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

ìš°ë¦¬ëŠ” ê³µê°œëœ í…ŒìŠ¤íŠ¸ ì‹œê°„ ì½”ë“œê°€ ìˆëŠ” ì—´ë‘ ê°œì˜ ëª¨ë¸ì—ì„œ ADDSENTë¥¼ ì‹¤í–‰í–ˆìœ¼ë©°, ëª¨ë“  ëª¨ë¸ì´ ì ëŒ€ì  í‰ê°€ì— ëŒ€í•´ ê°•ê±´í•˜ì§€ ì•ŠìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. 16ê°œì˜ ëª¨ë¸ì— ê±¸ì³ í‰ê·  F1 ì ìˆ˜ëŠ” 75.4%ì—ì„œ 36.4%ë¡œ ë–¨ì–´ì¡ŒìŠµë‹ˆë‹¤.

**ì‚¬ëŒ í‰ê°€**

ìš°ë¦¬ì˜ ê²°ê³¼ê°€ ìœ íš¨í•œì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì‚¬ëŒë“¤ë„ ì ëŒ€ì  ì˜ˆì œì— í˜¼ë™ë˜ì§€ ì•ŠëŠ”ì§€ ê²€ì¦í–ˆìŠµë‹ˆë‹¤.

ADDANYëŠ” ì‚¬ëŒì„ ëŒ€ìƒìœ¼ë¡œ ì‹¤í–‰í•˜ê¸°ì—ëŠ” ëª¨ë¸ ì¿¼ë¦¬ê°€ ë„ˆë¬´ ë§ê¸° ë•Œë¬¸ì— ADDSENTì— ì§‘ì¤‘í–ˆìŠµë‹ˆë‹¤.

ê° ì›ë˜ì™€ ì ëŒ€ì  ë‹¨ë½-ì§ˆë¬¸ ìŒì„ ì„¸ ëª…ì˜ ì‘ì—…ìì—ê²Œ ì œì‹œí•˜ê³ , ë‹¨ë½ì—ì„œ ë³µì‚¬-ë¶™ì—¬ë„£ê¸°ë¡œ ì˜¬ë°”ë¥¸ ë‹µì„ ì„ íƒí•˜ê²Œ í–ˆìŠµë‹ˆë‹¤.

ê·¸ëŸ° ë‹¤ìŒ ì„¸ ê°œì˜ ì‘ë‹µì— ëŒ€í•´ ë‹¤ìˆ˜ê²° íˆ¬í‘œë¥¼ í–ˆìŠµë‹ˆë‹¤(ëª¨ë‘ ë‹¤ë¥¸ ê²½ìš° ë¬´ì‘ìœ„ë¡œ í•˜ë‚˜ë¥¼ ì„ íƒ).

ì´ ê²°ê³¼ëŠ” Table 4ì— ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤.

ì›ë˜ ì˜ˆì œì—ì„œ ìš°ë¦¬ì˜ ì‚¬ëŒë“¤ì€ ì „ì²´ ê°œë°œ ì„¸íŠ¸ì—ì„œ ë³´ê³ ëœ 91.2 F1ë³´ë‹¤ ì•½ê°„ ë” ì˜ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.

ADDSENTì—ì„œëŠ” ì¸ê°„ì˜ ì •í™•ë„ê°€ 13.1 F1 í¬ì¸íŠ¸ ë–¨ì–´ì¡Œì§€ë§Œ, ì»´í“¨í„° ì‹œìŠ¤í…œë³´ë‹¤ í›¨ì”¬ ì ì€ ê°ì†Œë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.

ê²Œë‹¤ê°€, ì´ ê°ì†Œì˜ ëŒ€ë¶€ë¶„ì€ ìš°ë¦¬ì˜ ì ëŒ€ì  ë¬¸ì¥ê³¼ ê´€ë ¨ì´ ì—†ëŠ” ì‹¤ìˆ˜ë¡œ ì„¤ëª…ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ë¶„ì„**

ë‹¤ìŒìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì ëŒ€ì  í‰ê°€ì—ì„œ ìš°ë¦¬ì˜ ë„¤ ê°€ì§€ ì£¼ìš” ëª¨ë¸ì˜ í–‰ë™ì„ ë” ì˜ ì´í•´í•˜ë ¤ê³  í–ˆìŠµë‹ˆë‹¤.

ì ëŒ€ìì— ì˜í•´ ë°œìƒí•œ ì˜¤ë¥˜ë¥¼ ê°•ì¡°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ëª¨ë¸ì´ ì›ë˜ ì •í™•í•œ ë‹µì„ ì˜ˆì¸¡í•œ ì˜ˆì œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.

ìš°ë¦¬ëŠ” ì´ ì§‘í•©ì„ "ëª¨ë¸ ì„±ê³µ"ê³¼ "ëª¨ë¸ ì‹¤íŒ¨"ë¡œ ë‚˜ëˆ„ì—ˆìŠµë‹ˆë‹¤.

**ADDSENT ë¬¸ì¥ì˜ ë²”ì£¼í™”**

ìš°ë¦¬ëŠ” ADDSENTê°€ ìƒì„±í•œ ë¬¸ì¥ì„ ìˆ˜ë™ìœ¼ë¡œ ì¡°ì‚¬í–ˆìŠµë‹ˆë‹¤.

100ê°œì˜ BiDAF Ensemble ì‹¤íŒ¨ ì‚¬ë¡€ ì¤‘, 75ê±´ì€ ì ëŒ€ì  ë¬¸ì¥ì—ì„œ ì—”í‹°í‹° ì´ë¦„ì´ ë³€ê²½ëœ ê²½ìš°ì˜€ê³ , 17ê±´ì€ ìˆ«ìë‚˜ ë‚ ì§œê°€ ë³€ê²½ëœ ê²½ìš°ì˜€ìœ¼ë©°, 33ê±´ì€ ì§ˆë¬¸ ë‹¨ì–´ì˜ ë°˜ì˜ì–´ê°€ ì‚¬ìš©ëœ ê²½ìš°ì˜€ìŠµë‹ˆë‹¤.

ë˜í•œ, êµ°ì¤‘ ì†Œì‹± ì¤‘ì— ì‘ì—…ìë“¤ì´ ê°€í•œ ê¸°íƒ€ ì„­ë™ì´ ìˆëŠ” 7ê°œì˜ ë¬¸ì¥ì´ ìˆì—ˆìŠµë‹ˆë‹¤.

**ëª¨ë¸ ì„±ê³µì˜ ì´ìœ **

ë§ˆì§€ë§‰ìœ¼ë¡œ, íŠ¹ì • ì˜ˆì œì—ì„œ ëª¨ë¸ì´ ì ëŒ€ì  ì„­ë™ì— ê²¬ê³ í•œì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ìš”ì¸ì„ ì´í•´í•˜ë ¤ê³  í–ˆìŠµë‹ˆë‹¤.

ëª¨ë¸ì€ ì§ˆë¬¸ê³¼ ì›ë˜ ë‹¨ë½ì˜ ì •í™•í•œ n-ê·¸ë¨ ì¼ì¹˜ê°€ ìˆëŠ” ê²½ìš° ì˜ ìˆ˜í–‰í•˜ëŠ” ê²½í–¥ì´ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.

ì§ˆë¬¸ì´ ì§§ì„ìˆ˜ë¡ ëª¨ë¸ì´ ì„±ê³µí•  ê°€ëŠ¥ì„±ì´ ë†’ì•˜ìŠµë‹ˆë‹¤.

**ëª¨ë¸ ê°„ ì „ì´ ê°€ëŠ¥ì„±**

ADDONESENTì—ì„œ ìƒì„±ëœ ì˜ˆì œëŠ” ëª…í™•í•˜ê²Œ ëª¨ë¸ ê°„ì— ì „ì´ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ADDSENTì™€ ADDANYì—ì„œ ìƒì„±ëœ ì˜ˆì œë„ ë‹¤ë¥¸ ëª¨ë¸ì„ í˜¼ë™ì‹œí‚¤ëŠ” ê²½í–¥ì´ ìˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

**ì ëŒ€ì  ì˜ˆì œì—ì„œì˜ í›ˆë ¨**

ë§ˆì§€ë§‰ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì ëŒ€ì  ì˜ˆì œì—ì„œ í›ˆë ¨í•˜ì—¬ ê¸°ì¡´ ëª¨ë¸ì´ ë” ê°•ê±´í•´ì§ˆ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

ADDSENTì˜ ê²½ìš°, ì›ì‹œ ì ëŒ€ ë¬¸ì¥ì„ ìƒì„±í•œ ë‹¤ìŒ ì›ë˜ í›ˆë ¨ ë°ì´í„°ì™€ ê²°í•©í•˜ì—¬ BiDAF ëª¨ë¸ì„ í›ˆë ¨ì‹œì¼°ìŠµë‹ˆë‹¤.

ê²°ê³¼ëŠ” Table 6ì— ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤.

ADDSENTì— ëŒ€í•´ ì¬í›ˆë ¨ëœ ëª¨ë¸ì€ ê±°ì˜ ë°©ì–´ì ì´ì—ˆì§€ë§Œ, ADDSENTMODì— ëŒ€í•´ ê±°ì˜ ë™ì¼í•œ ì„±ëŠ¥ ì €í•˜ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.

ì´ëŠ” ëª¨ë¸ì´ ë§ˆì§€ë§‰ ë¬¸ì¥ì„ ë¬´ì‹œí•˜ê³  ADDSENTê°€ ì œì•ˆí•œ ê°€ì§œ ë‹µì„ ê±°ë¶€í•˜ëŠ” ê²ƒì„ í•™ìŠµí–ˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

### Original Results

**Main Experiments**

Table 2 shows the performance of the Match-LSTM and BiDAF models against all four adversaries.

Each model incurred a significant accuracy drop under every form of adversarial evaluation.

ADDSENT made average F1 score across the four models fall from 75.7% to 31.3%.

ADDANY was even more effective, making average F1 score fall to 6.7%.

ADDONESENT retained much of the effectiveness of ADDSENT, despite being model-independent.

Finally, ADDCOMMON caused average F1 score to fall to 46.1%, despite only adding common words.

We also verified that our adversaries were general enough to fool models that we did not use during development.

We ran ADDSENT on twelve published models for which we found publicly available test-time code; all models were not robust to adversarial evaluation. Average F1 score fell from 75.4% to 36.4% across the sixteen total models tested.

**Human Evaluation**

To ensure our results are valid, we verified that humans are not also fooled by our adversarial examples.

As ADDANY requires too many model queries to run against humans, we focused on ADDSENT.

We presented each original and adversarial paragraph-question pair to three crowdworkers and asked them to select the correct answer by copy-and-pasting from the paragraph.

We then took a majority vote over the three responses (if all three responses were different, we picked one at random).

These results are shown in Table 4.

On original examples, our humans are actually slightly better than the reported number of 91.2 F1 on the entire development set.

On ADDSENT, human accuracy drops by 13.1 F1 points, much less than the computer systems.

Moreover, much of this decrease can be explained by mistakes unrelated to our adversarial sentences.

**Error Analysis**

Next, we sought to better understand the behavior of our four main models under adversarial evaluation.

To highlight errors caused by the adversary, we focused on examples where the model originally predicted the (exact) correct answer.

We divided this set into "model successes" and "model failures."

**Categorizing ADDSENT Sentences**

We manually examined sentences generated by ADDSENT.

In 100 BiDAF Ensemble failures, we found 75 cases where an entity name was changed, 17 cases where numbers or dates were changed, and 33 cases where an antonym of a question word was used.

Additionally, there were 7 sentences with other perturbations made by crowdworkers during Step 4 of ADDSENT.

**Reasons for Model Successes**

Finally, we sought to understand the factors that influence whether the model will be robust to adversarial perturbations on a particular example.

We found that models do well when the question has an exact n-gram match with the original paragraph.

Models succeeded more often on short questions.

**Transferability Across Models**

Examples from ADDONESENT clearly transfer across models.

Examples generated by ADDSENT and ADDANY also tended to fool other models.

**Training on Adversarial Examples**

Finally, we tried training on adversarial examples to see if existing models can become more robust.

For ADDSENT, we generated raw adversarial sentences and combined them with the original training data to train the BiDAF model.

The results are shown in Table 6.

The retrained model was nearly robust against ADDSENT but performed poorly on ADDSENTMOD.

This suggests the model learned to ignore the last sentence and reject the fake answers proposed by ADDSENT.


<br/>  
# ìš”ì•½  
ì´ ë…¼ë¬¸ì€ ë…í•´ ì‹œìŠ¤í…œì˜ ì‹¤ì œ ì–¸ì–´ ì´í•´ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì ëŒ€ì  í‰ê°€ ì²´ê³„ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

ì ëŒ€ì  í‰ê°€ì˜ ì£¼ìš” ë°©ë²•ë¡ ìœ¼ë¡œëŠ” ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì¥ì„ ì¶”ê°€í•˜ëŠ” ADDSENTì™€ ì„ì˜ì˜ ë‹¨ì–´ ì‹œí€€ìŠ¤ë¥¼ ì¶”ê°€í•˜ëŠ” ADDANYê°€ ìˆìŠµë‹ˆë‹¤.

ì´ ë°©ë²•ë“¤ì€ ëª¨ë¸ì˜ ì•½ì ì„ ë“œëŸ¬ë‚´ë©°, ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì€ ì´ ì„¤ì •ì—ì„œ ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ë©ë‹ˆë‹¤.

ì—°êµ¬ ê²°ê³¼ëŠ” ADDSENTì™€ ADDANY ëª¨ë‘ì—ì„œ í‰ê·  F1 ì ìˆ˜ê°€ í¬ê²Œ ë–¨ì–´ì§ì„ ë³´ì—¬ì£¼ë©°, ì½”ë“œì™€ ë°ì´í„°ë¥¼ ê³µê°œí•˜ì—¬ í›„ì† ì—°êµ¬ë¥¼ ì´‰ì§„í•©ë‹ˆë‹¤.

---

This paper proposes an adversarial evaluation scheme to assess the true language understanding abilities of reading comprehension systems.

Key methodologies of adversarial evaluation include ADDSENT, which adds sentences similar to the question, and ADDANY, which adds arbitrary sequences of words.

These methods expose weaknesses in the models, with most models showing significant performance drops in this setting.

The research findings show that average F1 scores drop significantly for both ADDSENT and ADDANY, and the code and data are made public to promote further research.

<br/>
# refre format:     
Jia, Robin, and Percy Liang. "Adversarial Examples for Evaluating Reading Comprehension Systems." Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, September 2017.    