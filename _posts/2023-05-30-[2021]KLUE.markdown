---
layout: post
title:  "[2021]Korean Language Understanding Evaluation"
date:   2023-05-30 20:14:33 +0900
categories: study
---






{% highlight ruby %}


짧은 요약(Abstract) :    
* 한국언어이해 평가 벤치마크 소개  
* 8가지 포함(TC, STS, NLI, NER, RE, DP-DependencyParsing, MRC, DST-DialogueStateTracking)  
* PLM 학습(KLUE-BERT, KLUE-RoBERTa(SOTA))  
* 이슈 필터링(편견bias, 유해toxin, 개인정보PII-PersonalInformationIdentifier)  



{% endhighlight %}  

<br/>


[Paper with my notes](https://drive.google.com/drive/folders/1ns7PMLzJp0_FvHeIb1a4M9ET_qjnjuJ0?usp=sharing)  


[~~Lecture link~~]()  

<br/>

# 단어정리  
* pragmatics: 실용주의, 화용론     
** 화용론? 화자와 청자의 관계에 따라 언어 사용이 어떻게 바뀌는지, 화자의 의도와 발화의 의미는 어떻게 다를 수 있는지 등에 대한 연구   
*** '말하는 이, 듣는 이, 시간, 장소 따위로 구성되는 맥락(context)과 관련하여 문장의 의미를 체계적으로 분석하려는 의미론의 한 분야'  
*** 언어행위(speech act), 전제(presupposition 또는 PSP), 함축(implicature), 직시(deixis), 정보구조(information structure 또는 information packaging)등이 화용론에서 주요하게 다루는 주제  
* preemptively: 선제적으로  
* agglutinative nature: 교착 성질  
* agglutinative: 교착, 교착어(한국어-조사 등이 붙음)  








<br/>

# 1 Introduction  
* 버트, GPT3 같은 PLM의 성공이유는 GLUE나 SupserGLUE같은 효율적이고 잘 설계된 벤치마크 덕분    
** syntax, semantics, pragmatics 잘 포함한 NLU 벤치마크인 것이 이유    
** 다양 언어들에서 GLUE의 성공을 보고 GLUE와 유사한 언어별 벤치마크 생성(다국어 포함)  
* 한국어도 그래서 GLUE 유사 벤치마크 시도  
** 새로운 base 코포라부터 구축    
*** 불법/편견/개인정보 문제 피할 수 있음  
** 8KLUE Task  
** PLM & tokenizer  
<br/>

# 2 KLUE Benchmark  
## 2.1 Design Principles  
* 디자인 원칙  
** 다양 task/코포라 커버  
*** 8 task/news, 백과사전, 리뷰, 스마트홈, 한국어스타일 포맷  
*** 모두에게 공개  
** 정확, 모호하지 않은 태깅  
*** 가이드라인 꼼꼼하게 만듬  
* PLM에서 윤리문제 줄임  
** toxin(욕설, 성적인표현, 공격), bias(젠더, 종교, 인종), PII(개인정보) 제거  


## 2.2 Source Corpora  
* CC BY (-SA) 라이센스 기반 또는 상업이용을 허용  


## 2.3 Considerations in Annotation  
* 고려사항  
** 한글 특성 잘 반영: agglutinative nature(교착특성) 잘 반영하게 가이드 in NER, POS, DP  
** 정확태그 획득(가이드 통해..)  
* 나쁜거 제거  
** bias, hate(Moon 정의 따름): 지나친 일반화, 젠더, 인종, 배경, 국적, 종족, 정치견해, 피부색, 종교, 장애, 나이, 외모, 경제력, 직업  
** hate:공격, 모욕, 냉소  
** Privacy PII 인식  
** KISA 가이드 따름  


## 2.4 Tasks  
* 8개 NLU 소개(how to build)  
** hate, bias PII 제외  


### KLUE-TC  
* KLUE 토픽 분류  
** 다른 나라꺼 보고 있으니 추가  
*** 다른 나라에서 뉴스 썼으니 우리나라에서도 사용  
** 정치, 경제, 사회, 문화, 세계, IT/과학, 스포츠  
** 단일문장분류  
** macroF1으로 분류   
* 연합뉴스 헤드라인 태그(사전 클래스와 차이 있었음)  
** 13명 70,000개 태그  
** 각 헤드라인 당 3명  
** invalid와 다수결로 판갈음 안 될 시 제외  


### KLUE-STS  
* STS는 의미적 유사도에 대한 regression task  
** MT, 요약, QA의 기반(NLP의 기반)  
** 비교 테스크  
** 0,1 이진화도 진행  
** F1으로 평가  
** AIRBNB, POLICY(뉴스), RTT(Rount Trip Translation 번역하고 다시 원래 언어로 번역) 사용(레이블 x), PARAKQC(레이블o) 사용, 19명이 레이블링  
*** 13,244 문장쌍  


### KLUE-NLI  
* 전제와 가설 사이 관계 추출(3클래스 분류)  
** 참(포함), 거짓(역설), 판정불가(중립)  
** SNLI, MNLI와 비슷하게 데이터셋 구축  
** 알려진 레이블링요소 피함  
** 저제문장 수집, 사람이 가설 3개 생성  
** 다른 사람이 레이블링(검증)  
** 총 30,998쌍  


### KLUE-NER  
* 사람, 위치, 조직, 시간, 양, 재화 같은 개체명 인식  
** QA, IE 등 NLU에 속함  
** 시간, 장소, 조직, 날짜, 시간, 양 6개 태그 BIO 포맷  	
** 위키트리뉴스, NSMC(Naver? Movie review)를 원천으로 샘플링  
** 한국텔레커뮤니케이션기술연합(TTA) NER가이드 따름  
** 언어학자, NLP연구자 검증  
** 31,009 문장


