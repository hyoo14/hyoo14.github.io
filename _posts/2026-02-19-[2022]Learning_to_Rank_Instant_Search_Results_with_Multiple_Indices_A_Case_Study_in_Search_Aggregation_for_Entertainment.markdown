---
layout: post
title:  "[2022]Learning to Rank Instant Search Results with Multiple Indices: A Case Study in Search Aggregation for Entertainment"
date:   2026-02-19 21:53:23 -0000
categories: study
---

{% highlight ruby %}

í•œì¤„ ìš”ì•½: ì´ ë…¼ë¬¸ì—ì„œëŠ” Xfinityì˜ ì¦‰ê° ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ìœ„í•œ ë‹¤ì¤‘ ì¸ë±ìŠ¤ë¥¼ í™œìš©í•œ ê²°ê³¼ ìˆœìœ„ í•™ìŠµ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.


ì§§ì€ ìš”ì•½(Abstract) :


ì´ ë…¼ë¬¸ì—ì„œëŠ” Xfinityì˜ ì¦‰ê° ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ì‚¬ìš©ìê°€ ì…ë ¥í•˜ëŠ” ê° í‚¤ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì¶œì²˜ì—ì„œ ê²°ê³¼ë¥¼ ì œê³µí•˜ë©°, ê²°ê³¼ì—ëŠ” ì˜í™”, TV ì‹œë¦¬ì¦ˆ, ìŠ¤í¬ì¸  ì´ë²¤íŠ¸, ìŒì•… ë¹„ë””ì˜¤, ë‰´ìŠ¤ í´ë¦½ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” Xfinity ìŒì„± ë¦¬ëª¨ì»¨ì„ í†µí•´ ë” ê¸´ ì¿¼ë¦¬ë¥¼ ì œì¶œí•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŸ¬í•œ ì¿¼ë¦¬ëŠ” ë¶ˆì™„ì „í•œ ë‹¨ì–´, ì£¼ì œ ê²€ìƒ‰, ë˜ëŠ” íŠ¹ì •í•œ ê²€ìƒ‰ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ” ì–´íœ˜ì  ì¼ì¹˜, ì˜ë¯¸ì  ì¼ì¹˜, í•­ëª© ê°„ ìœ ì‚¬ì„± ì¼ì¹˜ ë“± ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ìƒì„±ë˜ë©°, ì´ëŸ¬í•œ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ëª©ë¡ìœ¼ë¡œ ê²°í•©í•˜ëŠ” ê²ƒì´ ì£¼ìš” ë„ì „ ê³¼ì œì…ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ê³ ë ¤í•œ í•™ìŠµ ê¸°ë°˜ ìˆœìœ„ ë§¤ê¸°ê¸°(Learning to Rank, LTR) ì‹ ê²½ë§ ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ê²°í•©ëœ ëª©ë¡ì€ ì‚¬ìš©ìì˜ ê²€ìƒ‰ ê¸°ë¡ê³¼ í”„ë¡œê·¸ë¨ ë©”íƒ€ë°ì´í„°ë¥¼ ë°˜ì˜í•˜ì—¬ ê°œì¸í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰ê° ê²€ìƒ‰ì— ëŒ€í•œ ì—°êµ¬ê°€ ë¶€ì¡±í•œ ìƒí™©ì—ì„œ, ì €ìë“¤ì€ ë‹¤ë¥¸ ì‹¤ë¬´ìë“¤ì—ê²Œ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì—°êµ¬ ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.




This paper addresses the instant search system at Xfinity, which provides a variety of results from different sources for each keystroke entered by the user. The results can include movies, television series, sporting events, music videos, news clips, and more. Users can also submit longer queries using the Xfinity Voice Remote, which may include incomplete words, topical searches, or more specific searches. The results can be generated through various methods such as lexical matches, semantic matches, and item-to-item similarity matches, presenting a key challenge in how to combine these results into a single list. To tackle this, the authors propose a Learning to Rank (LTR) neural model that takes the search query into account. This combined list can be personalized based on the user's search history and metadata of the programs. Given the underrepresentation of instant search in the literature, the authors present their findings to aid other practitioners.


* Useful sentences :


{% endhighlight %}

<br/>

[Paper link]()
[~~Lecture link~~]()

<br/>

# ë‹¨ì–´ì •ë¦¬
*


<br/>
# Methodology



ì´ ë…¼ë¬¸ì—ì„œëŠ” Xfinityì˜ ì¸ìŠ¤í„´íŠ¸ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ìœ„í•œ í•™ìŠµ ê¸°ë°˜ ë­í‚¹ ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ë‹¤ì–‘í•œ ì¶œì²˜ì—ì„œ ì œê³µë˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì œê³µí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ë‘ ê°€ì§€ ì£¼ìš” ë‹¨ê³„ê°€ ìˆìŠµë‹ˆë‹¤: í›„ë³´ ìƒì„±ê³¼ ì¬ë­í‚¹ì…ë‹ˆë‹¤.

1. **í›„ë³´ ìƒì„±**: í›„ë³´ ìƒì„± ë‹¨ê³„ì—ì„œëŠ” ì—¬ëŸ¬ ì¸ë±ìŠ¤ì— ë¹„ë™ê¸° í˜¸ì¶œì„ í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ì— ëŒ€í•œ í›„ë³´ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ì–‘í•œ ë§¤ì¹­ ê¸°ë²•ì´ ì‚¬ìš©ë©ë‹ˆë‹¤:
   - **Lexical Matching (ì–´íœ˜ ë§¤ì¹­)**: ì¿¼ë¦¬ì˜ ì ‘ë‘ì‚¬ê°€ í¬í•¨ëœ ì œëª©ì„ ê°€ì§„ í•­ëª©ì„ í›„ë³´ ëª©ë¡ì— í¬í•¨ì‹œí‚¤ê³ , ê¸€ë¡œë²Œ ì¸ê¸° ì ìˆ˜ë¡œ ì¬ë­í‚¹í•©ë‹ˆë‹¤.
   - **Semantic Search Model (ì˜ë¯¸ ê²€ìƒ‰ ëª¨ë¸)**: ìŒë‘¥ì´ ì‹ ê²½ë§(ì‹œì•” ì‹ ê²½ë§)ì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ì™€ ì½˜í…ì¸ ì˜ ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì‚¬ì „ í›ˆë ¨ëœ ìì—°ì–´ ì²˜ë¦¬(NLP) ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì¿¼ë¦¬ì™€ ì½˜í…ì¸ ì˜ ë²¡í„° í‘œí˜„ì„ ìƒì„±í•©ë‹ˆë‹¤.
   - **Item-to-Item Similarity Candidates (í•­ëª© ê°„ ìœ ì‚¬ì„± í›„ë³´)**: í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬í•œ í•­ëª© ëª©ë¡ì„ ë¯¸ë¦¬ ê³„ì‚°í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
   - **Trending Candidates (íŠ¸ë Œë“œ í›„ë³´)**: ìµœê·¼ í´ë¦­ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŠ¸ë Œë“œ í•­ëª©ì„ ì‹ë³„í•˜ê³  ì´ë¥¼ í›„ë³´ ëª©ë¡ì˜ ìƒìœ„ì— ë°°ì¹˜í•©ë‹ˆë‹¤.

2. **ì¬ë­í‚¹**: í›„ë³´ ëª©ë¡ì´ ìƒì„±ëœ í›„, ë‘ ê°œì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¬ë­í‚¹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
   - **ì²« ë²ˆì§¸ ëª¨ë¸**: ì¿¼ë¦¬ì™€ í•­ëª© IDë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„, ì¿¼ë¦¬ì˜ n-ê·¸ë¨ì„ ì„ë² ë”©í•˜ê³  í‰ê· í™”í•˜ì—¬ í›„ë³´ ëª©ë¡ì„ ê²°í•©í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì¿¼ë¦¬ì™€ í•­ëª©ì˜ ì¸ê¸°ë„ë¥¼ ìº¡ì²˜í•˜ê¸° ìœ„í•´ ìŒë³„ í•™ìŠµì„ í†µí•´ í›ˆë ¨ë©ë‹ˆë‹¤.
   - **ë‘ ë²ˆì§¸ ëª¨ë¸**: ê°œì¸í™”ëœ ê²°ê³¼ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ì ê²€ìƒ‰ í´ë¦­ ì´ë ¥ì„ ê³ ë ¤í•˜ì—¬ ìƒìœ„ Nê°œì˜ ê²°ê³¼ë¥¼ ê°œì¸í™”í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ LSTMì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ì™€ í•­ëª© ì œëª© ê°„ì˜ ìœ ì‚¬ì„±ì„ ì‹ë³„í•©ë‹ˆë‹¤.

ì´ ì‹œìŠ¤í…œì€ ëŒ€ê·œëª¨ ì‚¬ìš©ìì—ê²Œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ë‹¤ì–‘í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì ìš©í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì–´íœ˜ ë§¤ì¹­ì´ ì—†ëŠ” í•­ëª© ê°„ ìœ ì‚¬ì„± ë§¤ì¹­ì€ ì–´íœ˜ ë§¤ì¹­ë³´ë‹¤ ë‚®ì€ ìˆœìœ„ë¡œ ë°°ì¹˜ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ, ì‚¬ìš©ìëŠ” ë” ë‚˜ì€ ê²€ìƒ‰ ê²½í—˜ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.




This paper proposes a learning-based ranking model for Xfinity's instant search system, aimed at integrating search results from various sources and presenting them to users. The process consists of two main stages: candidate generation and reranking.

1. **Candidate Generation**: In the candidate generation stage, asynchronous calls are made to multiple indices to generate candidate results for a search query. Various matching techniques are employed in this stage:
   - **Lexical Matching**: Items whose titles contain the query as a prefix are included in the candidate list, and results are reranked by a global popularity score.
   - **Semantic Search Model**: A twin neural network (Siamese network) is used to evaluate the semantic similarity between the query and the content. This model leverages a pre-trained natural language processing (NLP) model to generate vector representations of the query and content.
   - **Item-to-Item Similarity Candidates**: A collaborative filtering-based approach is used to pre-compute and store lists of similar items.
   - **Trending Candidates**: Trending items are identified based on recent click data and boosted to the top of the candidate list.

2. **Reranking**: After generating the candidate lists, two deep learning models are employed for reranking.
   - **First Model**: This model takes the query and item ID as input, embedding and averaging the n-grams of the query to combine the candidate lists. It is trained using a pairwise learning approach to capture the popularity of items for a given query.
   - **Second Model**: This model personalizes the top N results by considering the user's search click history. It uses LSTM to identify the similarity between the search query and the item title.

The system is designed to serve millions of users at scale and applies various business logic to generate the final results. For instance, item-to-item similarity matches that do not also contain a lexical match are ranked lower than lexical matches. This approach aims to provide users with a better search experience.


<br/>
# Results



ì´ ë…¼ë¬¸ì—ì„œëŠ” Xfinityì˜ ì¸ìŠ¤í„´íŠ¸ ê²€ìƒ‰ ì‹œìŠ¤í…œì—ì„œ ì œì•ˆëœ ë‘ ë‹¨ê³„ì˜ ì¬ìˆœìœ„ ëª¨ë¸ì„ í†µí•´ ì–»ì€ ê²°ê³¼ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì—°êµ¬íŒ€ì€ A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ë‘ ê°€ì§€ ì£¼ìš” ë©”íŠ¸ë¦­ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤: ê²€ìƒ‰ ì„±ê³µë¥ (SSR)ê³¼ í‰ê·  í‚¤ ì…ë ¥ ìˆ˜(ANK). 

1. **ê²½ìŸ ëª¨ë¸**: ì œì•ˆëœ ëª¨ë¸ì€ ê¸°ì¡´ì˜ ê¸€ë¡œë²Œ ì¸ê¸° ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ê³¼ ë¹„êµë˜ì—ˆìŠµë‹ˆë‹¤. A/B í…ŒìŠ¤íŠ¸ëŠ” ì•½ 2ì£¼ ë™ì•ˆ ì§„í–‰ë˜ì—ˆìœ¼ë©°, ì‹¤í—˜êµ°ê³¼ ëŒ€ì¡°êµ°ì€ ë™ì¼í•œ ì–‘ì˜ íŠ¸ë˜í”½ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. 

2. **í…ŒìŠ¤íŠ¸ ë°ì´í„°**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ìµœê·¼ 2ì£¼ê°„ì˜ ì‚¬ìš©ì ê²€ìƒ‰ ì„¸ì…˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì˜€ìœ¼ë©°, ê° ì„¸ì…˜ì€ ìµœì†Œ í•˜ë‚˜ì˜ ê²€ìƒ‰ ê²°ê³¼ í´ë¦­ ì´ë²¤íŠ¸ë¥¼ í¬í•¨í•´ì•¼ í–ˆìŠµë‹ˆë‹¤. ì´ 150ë°±ë§Œ ê°œì˜ ì˜ˆì œê°€ í›ˆë ¨ì— ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.

3. **ë©”íŠ¸ë¦­**: 
   - **ê²€ìƒ‰ ì„±ê³µë¥ (SSR)**: ì‚¬ìš©ìê°€ ê²€ìƒ‰ í›„ í´ë¦­í•œ ê²°ê³¼ê°€ í›„ì† ê²€ìƒ‰ ì—†ì´ ğ‘‡ë¶„ ì´ë‚´ì— ì´ë£¨ì–´ì§„ ë¹„ìœ¨ë¡œ ì •ì˜ë©ë‹ˆë‹¤. 
   - **í‰ê·  í‚¤ ì…ë ¥ ìˆ˜(ANK)**: ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ë¥¼ í´ë¦­í•˜ê¸° ìœ„í•´ ì…ë ¥í•œ í‰ê·  í‚¤ ìˆ˜ì…ë‹ˆë‹¤. 

4. **ë¹„êµ ê²°ê³¼**: 
   - ì œì•ˆëœ ì¬ìˆœìœ„ ëª¨ë¸ì„ ë„ì…í•œ ê²°ê³¼, SSRì€ 0.5-5% í–¥ìƒë˜ì—ˆê³ , ANKëŠ” 10-20% ê°ì†Œí–ˆìŠµë‹ˆë‹¤. 
   - íŠ¹íˆ, ê°œì¸í™” ëª¨ë¸ì´ ì¶”ê°€ë˜ì—ˆì„ ë•Œ ì§§ì€ ì¿¼ë¦¬(ì˜ˆ: "MA")ì—ì„œ ë” í° ê°œì„ ì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. 
   - ì‚¬ìš©ìê°€ ì…ë ¥í•˜ëŠ” ì¿¼ë¦¬ì˜ ê²½ìš°, ê²€ìƒ‰ì´ ì‹¤íŒ¨í•˜ëŠ” ì´ìœ ëŠ” ì‚¬ìš©ìê°€ ì„¸ì…˜ì„ í¬ê¸°í•˜ê±°ë‚˜ ê²€ìƒ‰í•œ í•­ëª©ì´ ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ê¸°ê³„ í•™ìŠµ ê¸°ë°˜ì˜ ìˆœìœ„ ë§¤ê¹€ì´ SSRì— í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šì•˜ì§€ë§Œ, ì†Œí­ì˜ ê°œì„ ì´ ìˆì—ˆìŠµë‹ˆë‹¤. 
   - ë°˜ë©´, ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë¥¼ ë„ì…í•¨ìœ¼ë¡œì¨ SSRì—ì„œ ê°€ì¥ í° í–¥ìƒì´ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë” ë§ì€ ê²€ìƒ‰ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì²˜ë¦¬í•¨ìœ¼ë¡œì¨ ì‚¬ìš©ìê°€ ë” ë§ì€ ì½˜í…ì¸ ë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì—ˆìŠµë‹ˆë‹¤.

ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ì œì•ˆëœ ì¸ìŠ¤í„´íŠ¸ ê²€ìƒ‰ ì‹œìŠ¤í…œì´ ë‹¤ì–‘í•œ ì¿¼ë¦¬ ìœ í˜•ì— ëŒ€í•´ íš¨ê³¼ì ìœ¼ë¡œ ì‘ë™í•˜ë©°, ì‚¬ìš©ì ê²½í—˜ì„ ê°œì„ í•˜ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

---





This paper discusses the results obtained from the proposed two-step reranking model in Xfinity's instant search system. The research team evaluated two main metrics through A/B testing: Search Success Rate (SSR) and Average Number of Keystrokes (ANK).

1. **Competing Model**: The proposed model was compared against a global popularity sorting algorithm. The A/B tests were conducted over approximately two weeks, with both the treatment and control groups receiving equal amounts of traffic.

2. **Test Data**: The test data was based on user search session data from the last two weeks, with each session required to include at least one search result click event. A total of 150 million examples were used for training.

3. **Metrics**: 
   - **Search Success Rate (SSR)**: Defined as the percentage of sessions ending in a search result click without a follow-up search within T minutes.
   - **Average Number of Keystrokes (ANK)**: The average number of keystrokes a user inputs before clicking on the desired search result.

4. **Comparison Results**: 
   - The introduction of the proposed reranking model resulted in a 0.5-5% improvement in SSR and a 10-20% reduction in ANK.
   - Notably, the addition of the personalization model led to greater improvements in shorter queries (e.g., "MA").
   - In cases where users typed queries, search failures were typically due to users abandoning the session or the searched item being unavailable. Therefore, machine learning-based ranking did not significantly impact SSR, but a slight improvement was observed.
   - Conversely, the introduction of new indices resulted in the largest gains in SSR. By handling more search use cases, the system enabled users to find more content.

These results demonstrate that the proposed instant search system operates effectively across various query types and contributes to enhancing the user experience.


<br/>
# ì˜ˆì œ



ì´ ë…¼ë¬¸ì—ì„œëŠ” Xfinityì˜ ì¸ìŠ¤í„´íŠ¸ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ìœ„í•œ í•™ìŠµ ê¸°ë°˜ ë­í‚¹ ëª¨ë¸ì„ ì œì•ˆí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ì‚¬ìš©ìê°€ ì…ë ¥í•˜ëŠ” ì¿¼ë¦¬ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì¶œì²˜ì—ì„œ ê²°ê³¼ë¥¼ ì œê³µí•˜ë©°, ê° í‚¤ ì…ë ¥ë§ˆë‹¤ ìƒˆë¡œìš´ ê²°ê³¼ë¥¼ í™”ë©´ì— ë Œë”ë§í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì˜ ì£¼ìš” ëª©í‘œëŠ” ì—¬ëŸ¬ ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©í•˜ê³ , ì´ë¥¼ ì‚¬ìš©ì ë§ì¶¤í˜•ìœ¼ë¡œ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

#### íŠ¸ë ˆì´ë‹ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°

1. **íŠ¸ë ˆì´ë‹ ë°ì´í„°**:
   - **ì…ë ¥**: ì‚¬ìš©ìì˜ ê²€ìƒ‰ ì¿¼ë¦¬ì™€ í•´ë‹¹ ì¿¼ë¦¬ì— ëŒ€í•œ í´ë¦­ ë°ì´í„°. ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ìê°€ "ì˜í™”"ë¼ëŠ” ì¿¼ë¦¬ë¥¼ ì…ë ¥í–ˆì„ ë•Œ, ì´ ì¿¼ë¦¬ì— ëŒ€í•´ í´ë¦­ëœ ê²°ê³¼ ëª©ë¡ì´ ìˆ˜ì§‘ë©ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” (ì¿¼ë¦¬, ì•„ì´í…œ ID) ìŒìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ê° ìŒì€ ì‚¬ìš©ìê°€ í´ë¦­í•œ íšŸìˆ˜ë¡œ ê°€ì¤‘ì¹˜ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.
   - **ì¶œë ¥**: ê° ì¿¼ë¦¬ì— ëŒ€í•´ ë­í‚¹ëœ ì•„ì´í…œ ëª©ë¡. ì˜ˆë¥¼ ë“¤ì–´, "ì˜í™”"ë¼ëŠ” ì¿¼ë¦¬ì— ëŒ€í•´ "ì–´ë²¤ì ¸ìŠ¤", "íƒ€ì´íƒ€ë‹‰", "ì¸ì…‰ì…˜"ê³¼ ê°™ì€ ì˜í™”ë“¤ì´ ë­í‚¹ë˜ì–´ ì¶œë ¥ë©ë‹ˆë‹¤.

2. **í…ŒìŠ¤íŠ¸ ë°ì´í„°**:
   - **ì…ë ¥**: ìƒˆë¡œìš´ ì‚¬ìš©ìì˜ ê²€ìƒ‰ ì¿¼ë¦¬. ì˜ˆë¥¼ ë“¤ì–´, "ì½”ë¯¸ë”” ì˜í™”"ë¼ëŠ” ì¿¼ë¦¬ë¥¼ ì…ë ¥í–ˆì„ ë•Œ, ì´ ì¿¼ë¦¬ì— ëŒ€í•œ ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
   - **ì¶œë ¥**: ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë­í‚¹ëœ ì•„ì´í…œ ëª©ë¡. ì˜ˆë¥¼ ë“¤ì–´, "ì½”ë¯¸ë”” ì˜í™”"ë¼ëŠ” ì¿¼ë¦¬ì— ëŒ€í•´ "ìŠˆë ‰", "ë‚´ ë‚¨ìì¹œêµ¬ì˜ ê²°í˜¼ì‹", "21 ì í”„ ìŠ¤íŠ¸ë¦¬íŠ¸"ì™€ ê°™ì€ ì˜í™”ë“¤ì´ ì¶œë ¥ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### êµ¬ì²´ì ì¸ ì‘ì—…

- **ì‘ì—… 1**: í›„ë³´ ìƒì„±
  - ì—¬ëŸ¬ ì¸ë±ìŠ¤ì—ì„œ í›„ë³´ ì•„ì´í…œì„ ìƒì„±í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, "ì½”ë¯¸ë”” ì˜í™”"ë¼ëŠ” ì¿¼ë¦¬ì— ëŒ€í•´, Lexical Matching, Semantic Search, Item-to-Item Similarity ë“± ë‹¤ì–‘í•œ ë°©ë²•ì„ í†µí•´ í›„ë³´ ì•„ì´í…œì„ ìƒì„±í•©ë‹ˆë‹¤.

- **ì‘ì—… 2**: í•„í„°ë§
  - ì‚¬ìš©ìê°€ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ì•„ì´í…œì¸ì§€ í™•ì¸í•˜ì—¬ í•„í„°ë§í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ìê°€ êµ¬ë…í•˜ì§€ ì•Šì€ ì˜í™”ëŠ” ê²°ê³¼ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.

- **ì‘ì—… 3**: ì¬ë­í‚¹
  - ë‘ ê°œì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ì¬ë­í‚¹í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ëª¨ë¸ì€ ì¿¼ë¦¬ì™€ ì•„ì´í…œ IDë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë­í‚¹ì„ ìƒì„±í•˜ê³ , ë‘ ë²ˆì§¸ ëª¨ë¸ì€ ì‚¬ìš©ì ê²€ìƒ‰ ì´ë ¥ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸í™”ëœ ë­í‚¹ì„ ìƒì„±í•©ë‹ˆë‹¤.

ì´ëŸ¬í•œ ê³¼ì •ì„ í†µí•´, ì‚¬ìš©ìëŠ” ë³´ë‹¤ ê´€ë ¨ì„± ë†’ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìœ¼ë©°, ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì€ A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ í‰ê°€ë©ë‹ˆë‹¤.

---




This paper proposes a learning-based ranking model for Xfinity's instant search system. The system provides results from various sources for user-input queries, rendering new results on the screen for each keystroke. The main goal of this system is to integrate search results from multiple indices and present them in a personalized manner.

#### Training Data and Test Data

1. **Training Data**:
   - **Input**: User search queries and click data corresponding to those queries. For example, when a user inputs the query "movie," the list of results clicked for that query is collected. This data is structured as (query, item ID) pairs, with weights assigned based on the number of clicks for each pair.
   - **Output**: A ranked list of items for each query. For instance, for the query "movie," the output might include ranked movies like "Avengers," "Titanic," and "Inception."

2. **Test Data**:
   - **Input**: New user search queries. For example, when a user inputs the query "comedy movie," this query is used to predict results.
   - **Output**: A ranked list of items predicted by the model. For example, for the query "comedy movie," the output might include movies like "Shrek," "My Best Friend's Wedding," and "21 Jump Street."

#### Specific Tasks

- **Task 1**: Candidate Generation
  - Generate candidate items from multiple indices. For example, for the query "comedy movie," candidates are generated using various methods such as Lexical Matching, Semantic Search, and Item-to-Item Similarity.

- **Task 2**: Filtering
  - Filter candidates based on whether the user has access to the items. For instance, movies that the user is not subscribed to are excluded from the results.

- **Task 3**: Reranking
  - Use two deep learning models to rerank the final results. The first model takes the query and item ID as input to generate rankings, while the second model generates personalized rankings based on user search history and metadata.

Through these processes, users can obtain more relevant search results, and the system's performance is evaluated through A/B testing.

<br/>
# ìš”ì•½



ì´ ë…¼ë¬¸ì—ì„œëŠ” Xfinityì˜ ì¦‰ê° ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ìœ„í•œ ë‹¤ì¤‘ ì¸ë±ìŠ¤ë¥¼ í™œìš©í•œ ê²°ê³¼ ìˆœìœ„ í•™ìŠµ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë‘ ê°œì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í›„ë³´ ëª©ë¡ì„ ê²°í•©í•˜ê³  ê°œì¸í™”ëœ ê²°ê³¼ë¥¼ ìƒì„±í•˜ë©°, A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ê²€ìƒ‰ ì„±ê³µë¥ ê³¼ í´ë¦­ ìˆ˜ì—ì„œ ìœ ì˜ë¯¸í•œ ê°œì„ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê°œì¸í™” ëª¨ë¸ì€ ì§§ì€ ì¿¼ë¦¬ì—ì„œ í‰ê·  í‚¤ ì…ë ¥ ìˆ˜ì™€ ì„±ê³µ ì‹œê°„ì—ì„œ 10-20%ì˜ ê°œì„ ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

---

This paper proposes a learning-to-rank method for instant search results using multiple indices in Xfinity's instant search system. Two deep learning models are employed to combine candidate lists and generate personalized results, showing significant improvements in search success rates and click counts through A/B testing. For instance, the personalization model achieved a 10-20% improvement in average keystrokes and time to success for short queries.



<br/>
# ê¸°íƒ€
ë…¼ë¬¸ "Learning to Rank Instant Search Results with Multiple Indices: A Case Study in Search Aggregation for Entertainment"ì—ì„œ ë‹¤ë£¨ì–´ì§„ ë‹¤ì´ì–´ê·¸ë¨, í”¼ê·œì–´, í…Œì´ë¸”, ì–´íœë”•ìŠ¤ì˜ ì£¼ìš” ê²°ê³¼ì™€ ì¸ì‚¬ì´íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

### 1. ë‹¤ì´ì–´ê·¸ë¨ ë° í”¼ê·œì–´
- **Figure 1**: ê²€ìƒ‰ íë¦„ ë‹¤ì´ì–´ê·¸ë¨
  - ì´ ë‹¤ì´ì–´ê·¸ë¨ì€ ì‚¬ìš©ìê°€ "Park"ë¼ëŠ” ì¿¼ë¦¬ë¥¼ ì…ë ¥í–ˆì„ ë•Œì˜ ê²€ìƒ‰ íë¦„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¤ì–‘í•œ í›„ë³´ ê²°ê³¼(lexical match, synonyms, semantic search ë“±)ê°€ ìƒì„±ë˜ê³ , í•„í„°ë§ ë° ì¬ìˆœìœ„í™” ê³¼ì •ì„ í†µí•´ ìµœì¢… ê²°ê³¼ê°€ ë„ì¶œë©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ì‚¬ìš©ìê°€ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì½˜í…ì¸ (ì˜í™”, TV í”„ë¡œê·¸ë¨ ë“±)ë¥¼ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.

- **Figure 3**: ì¬ìˆœìœ„í™” ëª¨ë¸ ì•„í‚¤í…ì²˜
  - ë‘ ê°œì˜ íƒ€ì›Œë¡œ êµ¬ì„±ëœ ëª¨ë¸ì´ ì¿¼ë¦¬ì™€ ì•„ì´í…œ IDë¥¼ ì„ë² ë”©í•˜ì—¬ ê²°í•©í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì¿¼ë¦¬ì™€ ì•„ì´í…œ ê°„ì˜ ê´€ê³„ë¥¼ í•™ìŠµí•˜ì—¬ ìµœì¢… ìˆœìœ„ë¥¼ ë§¤ê¸°ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŠ” ë‹¤ì–‘í•œ í›„ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ í†µí•©í•˜ì—¬ ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.

- **Figure 4**: ê°œì¸í™” ëª¨ë¸ ì•„í‚¤í…ì²˜
  - ì´ ëª¨ë¸ì€ LSTMì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ì™€ ì•„ì´í…œ ì œëª© ê°„ì˜ ìœ ì‚¬ì„±ì„ íŒŒì•…í•©ë‹ˆë‹¤. ì‚¬ìš©ì ê²€ìƒ‰ í´ë¦­ ì´ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ìˆœìœ„ë¥¼ ê³„ì‚°í•˜ëŠ” ê³¼ì •ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ì ë§ì¶¤í˜• ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì œê³µí•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.

### 2. í…Œì´ë¸”
- **Table of Results**: A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼
  - A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì¬ìˆœìœ„í™” ë‹¨ê³„ ë„ì… í›„ ì£¼ìš” ë©”íŠ¸ë¦­ì—ì„œ ê°œì„ ì´ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê²€ìƒ‰ ì„±ê³µë¥ , í´ë¦­ê¹Œì§€ì˜ ì‹œê°„, ì…ë ¥ëœ í‚¤ìŠ¤íŠ¸ë¡œí¬ ìˆ˜ì—ì„œ ê°ê° 0.5-5%, 10-20%ì˜ ê°œì„ ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì¬ìˆœìœ„í™” ëª¨ë¸ì´ ì‚¬ìš©ì ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° íš¨ê³¼ì ì„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

### 3. ì–´íœë”•ìŠ¤
- ì–´íœë”•ìŠ¤ì—ì„œëŠ” ì‹¤í—˜ì— ì‚¬ìš©ëœ ë°ì´í„° ì„¸íŠ¸, ë©”íŠ¸ë¦­ ì •ì˜, ì„¸ì…˜í™” ë¡œì§ ë“± ì¶”ê°€ì ì¸ ì„¸ë¶€ ì‚¬í•­ì´ ì œê³µë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì •ë³´ëŠ” ì—°êµ¬ ê²°ê³¼ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê³ , ë‹¤ë¥¸ ì—°êµ¬ìë“¤ì´ ìœ ì‚¬í•œ ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---




### 1. Diagrams and Figures
- **Figure 1**: Search Flow Diagram
  - This diagram illustrates the search flow when a user inputs the query "Park." It shows how various candidate results (lexical match, synonyms, semantic search, etc.) are generated, filtered, and reranked to produce the final results. This process helps users easily find different types of content (movies, TV shows, etc.).

- **Figure 3**: Reranking Model Architecture
  - This figure depicts a two-tower model that embeds the query and item ID, combining them for final ranking. This model learns the relationship between the query and items, contributing to the generation of a cohesive list of results by integrating various candidate lists.

- **Figure 4**: Personalization Model Architecture
  - This model uses LSTM to identify similarities between the query and item titles. It incorporates user search click history to compute the final ranking. This plays a crucial role in providing personalized search results.

### 2. Tables
- **Table of Results**: A/B Test Results
  - The A/B tests showed improvements in key metrics after introducing the reranking step. For instance, there were improvements of 0.5-5% in search success rate and 10-20% in time to click and number of keystrokes. This indicates that the reranking model effectively enhances user experience.

### 3. Appendix
- The appendix provides additional details such as the datasets used in experiments, metric definitions, and sessionization logic. This information enhances the reliability of the research findings and can assist other researchers in implementing similar systems.

<br/>
# refer format:


### BibTeX 
```bibtex
@inproceedings{rome2022learning,
  author = {Scott Rome and Sardar Hamidian and Richard Walsh and Kevin Foley and Ferhan Ture},
  title = {Learning to Rank Instant Search Results with Multiple Indices: A Case Study in Search Aggregation for Entertainment},
  booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22)},
  pages = {1--5},
  year = {2022},
  month = {July},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/3477495.3536334},
  isbn = {978-1-4503-8732-3}
}
```

### ì‹œì¹´ê³  ìŠ¤íƒ€ì¼
Scott Rome, Sardar Hamidian, Richard Walsh, Kevin Foley, and Ferhan Ture. 2022. "Learning to Rank Instant Search Results with Multiple Indices: A Case Study in Search Aggregation for Entertainment." In *Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22)*, 1-5. New York, NY: ACM. https://doi.org/10.1145/3477495.3536334.
