---
layout: post
title:  "[2024]“Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time"
date:   2026-02-19 21:56:20 -0000
categories: study
---

{% highlight ruby %}

한줄 요약: 본 연구에서는 Comcast의 고객 서비스 에이전트를 지원하기 위해 "Ask Me Anything" (AMA) 기능을 도입하였으며, 이는 대규모 언어 모델(LLM)을 활용하여 실시간으로 정확한 답변을 제공한다.


짧은 요약(Abstract) :

이 논문에서는 고객 서비스의 중요성과 그에 따른 비용 효율성을 강조하며, 컴캐스트가 고객 서비스 에이전트를 지원하기 위해 "Ask Me Anything" (AMA)라는 기능을 도입한 내용을 소개합니다. AMA는 에이전트가 고객과의 대화 중에 대형 언어 모델(LLM)에 질문을 할 수 있도록 하여, 실시간으로 정확한 답변을 제공함으로써 에이전트의 작업 전환을 줄여줍니다. 내부 실험 결과, AMA를 사용하는 에이전트는 전통적인 검색 경험에 비해 대화당 약 10%의 시간을 절약할 수 있었으며, 이는 연간 수백만 달러의 비용 절감으로 이어질 수 있습니다. AMA 기능을 사용한 에이전트는 약 80%의 긍정적인 피드백을 제공하여, 고객 서비스에 있어 AI 지원 기능의 유용성을 입증하였습니다.



This paper emphasizes the importance of customer service and the associated cost efficiency, introducing Comcast's implementation of a feature called "Ask Me Anything" (AMA) to assist customer service agents. AMA allows agents to ask questions to a large language model (LLM) while handling customer conversations, providing accurate responses in real-time and reducing the amount of context switching required by the agents. Internal experiments showed that agents using AMA spent approximately 10% less time per conversation compared to traditional search experiences, potentially translating to millions of dollars in annual savings. Agents utilizing the AMA feature provided positive feedback nearly 80% of the time, demonstrating the usefulness of AI-assisted features in customer care.


* Useful sentences :


{% endhighlight %}

<br/>

[Paper link]()
[~~Lecture link~~]()

<br/>

# 단어정리
*


<br/>
# Methodology



이 논문에서는 Comcast의 고객 서비스 에이전트를 지원하기 위해 "Ask Me Anything" (AMA)라는 기능을 도입한 방법론을 설명합니다. AMA는 대규모 언어 모델(LLM)을 활용하여 에이전트가 고객과의 대화 중 실시간으로 질문을 하고, 이에 대한 정확한 답변을 제공받을 수 있도록 설계되었습니다. 이 시스템은 다음과 같은 주요 구성 요소로 이루어져 있습니다.

1. **문서 전처리**: 다양한 형식의 문서를 수집하여 표준화된 텍스트로 변환하고, 이를 청크(chunk) 단위로 나누어 저장합니다. 각 청크는 고유 식별자를 부여받아 관리됩니다. 이 과정에서 Haystack 라이브러리를 사용하여 청크의 크기와 형식을 조정합니다.

2. **관련 텍스트 스니펫 검색**: AMA 시스템은 질문에 대한 답변을 찾기 위해 두 가지 검색 모델을 사용합니다. 첫 번째는 전통적인 희소 모델인 Okapi BM25이며, 두 번째는 Dense Passage Retrieval (DPR)과 같은 밀집 모델입니다. 이 모델들은 고객 서비스 에이전트가 자주 묻는 질문에 대한 답변을 찾기 위해 최적화되어 있습니다.

3. **재정렬 모델**: 검색된 결과의 품질을 향상시키기 위해 재정렬(reranking) 모델을 사용합니다. 이 모델은 GPT-4를 활용하여 생성된 합성 질문을 기반으로 검색된 문서의 순위를 조정합니다. 이를 통해 더 관련성 높은 문서가 상위에 위치하도록 합니다.

4. **답변 생성**: 검색된 스니펫을 바탕으로 LLM을 통해 최종 답변을 생성합니다. 이 과정에서 LLM은 질문에 대한 답변을 작성하고, 출처를 인용하는 기능도 포함되어 있습니다. 이를 통해 에이전트는 제공된 답변의 신뢰성을 높일 수 있습니다.

5. **시스템 평가**: AMA 시스템의 성능은 다양한 메트릭을 통해 평가됩니다. 예를 들어, 답변 품질, 인용 일치율, 검색 결과의 재현율(Recall@K) 등이 포함됩니다. 이러한 평가를 통해 시스템의 개선점을 지속적으로 파악하고 있습니다.

이러한 방법론을 통해 Comcast는 고객 서비스 에이전트의 효율성을 높이고, 고객 만족도를 향상시키는 데 기여하고 있습니다.

---



This paper describes the methodology used by Comcast to implement the "Ask Me Anything" (AMA) feature, which assists customer service agents. AMA is designed to allow agents to ask questions to a large language model (LLM) in real-time while engaging in customer conversations, providing accurate responses. The system consists of the following key components:

1. **Document Preprocessing**: Various formats of documents are collected, standardized into plain text, and then chunked into manageable pieces. Each chunk is assigned a unique identifier for management. The Haystack library is utilized to adjust the size and format of the chunks during this process.

2. **Retrieving Relevant Text Snippets**: The AMA system employs two types of retrieval models to find answers to questions. The first is a traditional sparse model, Okapi BM25, while the second is a dense model like Dense Passage Retrieval (DPR). These models are optimized to address frequently asked questions by customer service agents.

3. **Reranking Model**: To enhance the quality of the retrieved results, a reranking model is employed. This model uses synthetic questions generated by GPT-4 to adjust the ranking of the retrieved documents. This ensures that more relevant documents are prioritized in the results.

4. **Generating Answers**: Based on the retrieved snippets, the LLM generates the final answer. This process includes the LLM writing a response to the question and incorporating a citation feature, allowing agents to verify the reliability of the provided answers.

5. **System Evaluation**: The performance of the AMA system is evaluated using various metrics, including answer quality, citation match rate, and recall@K. These evaluations help in continuously identifying areas for improvement in the system.

Through this methodology, Comcast aims to enhance the efficiency of customer service agents and improve customer satisfaction.


<br/>
# Results



이 논문에서는 Comcast가 고객 서비스 에이전트를 지원하기 위해 "Ask Me Anything" (AMA)라는 기능을 도입한 내용을 다루고 있습니다. AMA는 대규모 언어 모델(LLM)을 활용하여 에이전트가 고객과의 대화 중 실시간으로 질문을 하고, 이에 대한 정확한 답변을 제공받을 수 있도록 설계되었습니다. 이 시스템은 고객 서비스의 효율성을 높이고, 에이전트의 작업 시간을 단축시키는 데 기여하고 있습니다.

#### 결과 및 비교

1. **경쟁 모델**: AMA 시스템은 기존의 검색 시스템과 비교되었습니다. 기존 시스템은 에이전트가 새로운 도구를 열고 검색을 수행해야 했습니다. AMA는 이러한 과정을 간소화하여 에이전트가 대화 중에 직접 질문을 할 수 있도록 하였습니다.

2. **테스트 데이터**: AMA의 성능은 내부 실험을 통해 평가되었습니다. 에이전트가 AMA를 사용할 때와 전통적인 검색 옵션을 사용할 때의 대화 처리 시간을 비교하였습니다. 

3. **메트릭**: 
   - **대화 처리 시간**: AMA를 사용한 에이전트는 전통적인 검색 옵션을 사용할 때보다 약 10% 더 적은 시간을 소요했습니다. 이는 연간 수백만 달러의 비용 절감으로 이어졌습니다.
   - **긍정적인 피드백 비율**: 에이전트의 약 80%가 AMA 기능에 대해 긍정적인 피드백을 제공하였습니다. 이는 AMA가 고객 서비스에 유용한 AI 지원 기능임을 나타냅니다.

4. **비교**: AMA는 기존의 검색 시스템에 비해 에이전트의 작업 효율성을 크게 향상시켰습니다. A/B 테스트 결과, AMA를 사용한 에이전트는 "답변 없음 비율"이 11.9% 감소하고, "긍정적인 피드백 비율"이 8.9% 증가하는 성과를 보였습니다. 이러한 결과는 AMA가 더 많은 질문을 처리할 수 있도록 도와주며, 에이전트의 긍정적인 경험을 증가시켰음을 보여줍니다.

이러한 결과들은 AMA가 고객 서비스의 질을 높이고, 에이전트의 작업 효율성을 개선하는 데 기여하고 있음을 입증합니다.

---




This paper discusses how Comcast has implemented a feature called "Ask Me Anything" (AMA) to assist customer service agents. AMA is designed to leverage large language models (LLMs) to allow agents to ask questions in real-time while engaging with customers, providing accurate responses and enhancing efficiency in customer service.

#### Results and Comparisons

1. **Competing Models**: The AMA system was compared to traditional search systems. In the traditional system, agents had to open a new tool and perform a search, while AMA streamlined this process by allowing agents to ask questions directly during conversations.

2. **Test Data**: The performance of AMA was evaluated through internal experiments. The conversation handling time was compared between agents using AMA and those using the traditional search option.

3. **Metrics**:
   - **Conversation Handling Time**: Agents using AMA spent approximately 10% less time per conversation compared to those using the traditional search option, translating to millions of dollars in annual savings.
   - **Positive Feedback Rate**: About 80% of agents provided positive feedback on the AMA feature, indicating its usefulness as an AI-assisted tool for customer care.

4. **Comparison**: AMA significantly improved agent efficiency compared to the traditional search system. A/B testing results showed that agents using AMA experienced an 11.9% reduction in the "No Answer Rate" and an 8.9% increase in the "Positive Feedback Rate." These results demonstrate that AMA enables agents to handle more questions effectively while enhancing their positive experiences.

These findings validate that AMA contributes to improving the quality of customer service and enhancing agent efficiency.


<br/>
# 예제



이 논문에서는 Comcast의 고객 서비스 에이전트를 지원하기 위해 "Ask Me Anything" (AMA)이라는 기능을 도입한 방법을 설명합니다. AMA는 대규모 언어 모델(LLM)을 활용하여 에이전트가 고객과의 대화 중에 실시간으로 질문을 하고 답변을 받을 수 있도록 합니다. 이 시스템의 훈련 데이터와 테스트 데이터는 다음과 같은 방식으로 구성됩니다.

1. **훈련 데이터 준비**:
   - **문서 수집**: 다양한 내부 클라이언트로부터 고객 서비스 관련 문서들을 수집합니다. 이 문서들은 고객의 질문에 대한 답변을 포함하고 있습니다.
   - **전처리**: 수집된 문서들은 텍스트 형식으로 변환되고, 각 문서는 의미 있는 조각으로 나누어집니다. 이 조각들은 LLM이 이해할 수 있도록 임베딩됩니다.
   - **질문-답변 쌍 생성**: 내부 지식 기반에서 고객이 자주 묻는 질문을 바탕으로 질문-답변 쌍을 생성합니다. 예를 들어, "내 청구서의 잔액은 얼마인가요?"라는 질문에 대해 "현재 잔액은 50,000원입니다."라는 답변을 생성합니다.

2. **테스트 데이터 준비**:
   - **파일럿 실험**: 실제 고객 서비스 에이전트가 사용하는 질문을 수집하여 테스트 데이터로 사용합니다. 이 질문들은 고객이 자주 묻는 질문들로 구성됩니다.
   - **정답 생성**: 각 질문에 대해 인간 주석자가 내부 지식 기반을 사용하여 정답을 작성합니다. 예를 들어, "인터넷 서비스의 속도는 어떻게 확인하나요?"라는 질문에 대해 "Xfinity 앱에서 서비스 속도를 확인할 수 있습니다."라는 정답을 작성합니다.

3. **모델 평가**:
   - **응답 품질 평가**: AMA 시스템이 생성한 답변과 인간 주석자가 작성한 정답을 비교하여 "답변 품질"을 평가합니다. 이 과정에서 GPT-4와 같은 LLM을 사용하여 시스템의 답변이 얼마나 정확한지를 평가합니다.
   - **인용 일치율 평가**: AMA 시스템이 제공한 인용이 인간 주석자가 제공한 인용과 얼마나 일치하는지를 평가하여 "인용 일치율"을 계산합니다.

이러한 과정을 통해 AMA 시스템은 고객 서비스 에이전트가 고객의 질문에 신속하고 정확하게 답변할 수 있도록 지원합니다.




This paper describes how Comcast introduced a feature called "Ask Me Anything" (AMA) to assist customer service agents. AMA leverages large language models (LLMs) to allow agents to ask questions and receive answers in real-time while interacting with customers. The training and testing data for this system are structured as follows:

1. **Training Data Preparation**:
   - **Document Collection**: Various customer service-related documents are collected from internal clients. These documents contain answers to common customer inquiries.
   - **Preprocessing**: The collected documents are converted into text format and chunked into meaningful pieces. These chunks are then embedded for understanding by the LLM.
   - **Question-Answer Pair Generation**: Question-answer pairs are generated based on frequently asked questions from the internal knowledge base. For example, a question like "What is my bill balance?" might have the answer "Your current balance is $50."

2. **Testing Data Preparation**:
   - **Pilot Experiment**: Questions used by actual customer service agents are collected to form the testing data. These questions consist of common inquiries from customers.
   - **Answer Generation**: For each question, human annotators write correct answers using the internal knowledge base. For instance, for the question "How can I check my internet service speed?", the answer might be "You can check the service speed in the Xfinity app."

3. **Model Evaluation**:
   - **Response Quality Evaluation**: The answers generated by the AMA system are compared to the correct answers written by human annotators to assess "answer quality." This process involves using LLMs like GPT-4 to evaluate how accurate the system's responses are.
   - **Citation Match Rate Evaluation**: The system's citations are compared to those provided by human annotators to calculate the "citation match rate."

Through these processes, the AMA system supports customer service agents in providing quick and accurate responses to customer inquiries.

<br/>
# 요약

본 연구에서는 Comcast의 고객 서비스 에이전트를 지원하기 위해 "Ask Me Anything" (AMA) 기능을 도입하였으며, 이는 대규모 언어 모델(LLM)을 활용하여 실시간으로 정확한 답변을 제공한다. 실험 결과, AMA를 사용한 에이전트는 전통적인 검색 방식에 비해 대화당 약 10%의 시간을 절약하였고, 긍정적인 피드백 비율이 80%에 달했다. 이 시스템은 고객 서비스의 효율성을 크게 향상시키는 데 기여하였다.


This study introduced the "Ask Me Anything" (AMA) feature to assist Comcast customer service agents, leveraging large language models (LLMs) to provide accurate real-time responses. Experimental results showed that agents using AMA saved approximately 10% of the time per conversation compared to traditional search methods, with a positive feedback rate of 80%. The system significantly contributed to enhancing the efficiency of customer service.

<br/>
# 기타



1. **테이블 1: Chunking Parameters and Evaluation**
   - 이 테이블은 다양한 chunking 파라미터 설정에 따른 평가 점수를 보여줍니다. 특히, `max_chars_check` 값을 높게 설정했을 때 답변 품질이 크게 향상되었음을 나타냅니다. 이는 LLM에 제공되는 텍스트 조각의 크기가 답변의 질에 중요한 영향을 미친다는 것을 시사합니다.

2. **테이블 2: Results of Various Retrievers on Our Pilot Evaluation Set**
   - 이 테이블은 다양한 검색 모델의 성능을 비교합니다. BM25 모델이 다른 밀집 검색 모델보다 우수한 성능을 보였으며, OpenAI의 ada-002 임베딩 모델이 가장 높은 MRR을 기록했습니다. 이는 특정 도메인에 맞는 검색 모델의 선택이 중요하다는 것을 강조합니다.

3. **테이블 4: ADA vs. Reranker Search Results using Production Questions**
   - ADA 모델과 reranker 모델의 성능 비교를 보여줍니다. reranker 모델이 Recall@3과 MRR에서 유의미한 개선을 보였으며, 이는 reranker가 검색 결과의 품질을 높이는 데 기여했음을 나타냅니다.

4. **테이블 5: Response Quality**
   - ADA와 reranker 모델의 응답 품질을 비교한 결과, reranker 모델이 답변 품질과 인용 일치율에서 개선을 보였습니다. 이는 reranker가 더 정확한 정보를 제공하는 데 기여했음을 시사합니다.

5. **테이블 6: A/B Test Results**
   - A/B 테스트 결과, reranker 모델이 "No Answer Rate"를 11.9% 감소시키고, 긍정적인 피드백 비율을 8.9% 증가시켰습니다. 이는 reranker가 더 많은 질문에 대한 답변을 제공하고, 사용자 만족도를 높이는 데 기여했음을 나타냅니다.




1. **Table 1: Chunking Parameters and Evaluation**
   - This table shows the evaluation scores based on different chunking parameter settings. Notably, increasing the `max_chars_check` value significantly improved answer quality, indicating that the size of text chunks provided to the LLM has a critical impact on the quality of responses.

2. **Table 2: Results of Various Retrievers on Our Pilot Evaluation Set**
   - This table compares the performance of various retrieval models. The BM25 model outperformed other dense retrieval models, while OpenAI's ada-002 embedding model achieved the highest MRR. This emphasizes the importance of selecting retrieval models tailored to specific domains.

3. **Table 4: ADA vs. Reranker Search Results using Production Questions**
   - This table compares the performance of the ADA model and the reranker model. The reranker model showed significant improvements in Recall@3 and MRR, indicating that it contributed to enhancing the quality of search results.

4. **Table 5: Response Quality**
   - The comparison of response quality between the ADA and reranker models revealed that the reranker model improved answer quality and citation match rate. This suggests that the reranker provided more accurate information.

5. **Table 6: A/B Test Results**
   - The A/B test results indicated that the reranker model reduced the "No Answer Rate" by 11.9% and increased the positive feedback rate by 8.9%. This demonstrates that the reranker was able to provide answers to more questions and enhance user satisfaction.

<br/>
# refer format:
### BibTeX 


```bibtex
@inproceedings{rome2024ask,
  author = {Scott Rome and Tianwen Chen and Raphael Tang and Luwei Zhou and Ferhan Ture},
  title = {“Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time},
  booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '24)},
  year = {2024},
  month = {July},
  publisher = {ACM},
  doi = {10.1145/3626772.3661345},
  isbn = {979-8-4007-0431-4}
}
```

### 시카고 스타일

Scott Rome, Tianwen Chen, Raphael Tang, Luwei Zhou, and Ferhan Ture. 2024. “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time. In *Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '24)*, 1–5. New York, NY: ACM. https://doi.org/10.1145/3626772.3661345.
