---
layout: post
title:  "[2022]Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"  
date:   2022-06-03 15:11:40 -0400
categories: study
---

{% highlight ruby %}


í•œì¤„ ìš”ì•½: 



ì§§ì€ ìš”ì•½(Abstract) :    


ì´ ë…¼ë¬¸ì€ **Few-shot In-Context Learning (ICL)**ê³¼ íŒŒë¼ë¯¸í„° íš¨ìœ¨ì ì¸ íŒŒì¸íŠœë‹(PEFT) ê¸°ë²•ì„ ë¹„êµí•©ë‹ˆë‹¤. ICLì€ ì‚¬ì „í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì— ì†Œìˆ˜ì˜ ì˜ˆì‹œë¥¼ ì…ë ¥ì— í¬í•¨ì‹œì¼œ ìƒˆë¡œìš´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê²Œ í•˜ì§€ë§Œ, ë§¤ë²ˆ ì˜ˆì‹œë¥¼ ì²˜ë¦¬í•´ì•¼ í•˜ë¯€ë¡œ ê³„ì‚°ëŸ‰ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë§¤ìš° í½ë‹ˆë‹¤. ë°˜ë©´, PEFTëŠ” ëª¨ë¸ì˜ ê·¹íˆ ì¼ë¶€ íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµì‹œì¼œ ìƒˆë¡œìš´ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•˜ë©°, í›¨ì”¬ ì €ë ´í•˜ê³  íš¨ìœ¨ì ì…ë‹ˆë‹¤.

ë…¼ë¬¸ì—ì„œëŠ” ìƒˆë¡œìš´ PEFT ë°©ë²•ì¸ (IA)Â³ë¥¼ ì œì•ˆí•˜ëŠ”ë°, ì´ëŠ” í•™ìŠµëœ ë²¡í„°ë¥¼ í†µí•´ ëª¨ë¸ì˜ í™œì„±ê°’ì„ ì¡°ì ˆí•©ë‹ˆë‹¤. (IA)Â³ëŠ” ì ì€ ìˆ˜ì˜ íŒŒë¼ë¯¸í„°ë§Œìœ¼ë¡œë„ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ìƒˆë¡œìš´ ì‘ì—…ì— ëŒ€í•œ ì •í™•ë„ê°€ ICLë³´ë‹¤ ë†’ê³  ê³„ì‚° ë¹„ìš©ë„ ì ìŠµë‹ˆë‹¤.

ë˜í•œ, ì €ìë“¤ì€ T-Fewë¼ëŠ” ë ˆì‹œí”¼ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ T0 ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ ì–´ë–¤ ì‘ì—…ì—ë„ íŠ¹ë³„í•œ ì¡°ì • ì—†ì´ ì ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ì‹¤ì œ RAFT ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì¸ê°„ ì„±ëŠ¥ì„ ë›°ì–´ë„˜ëŠ” ê²°ê³¼ë¥¼ ìµœì´ˆë¡œ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ì— ì‚¬ìš©ëœ ì½”ë“œëŠ” ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.


Few-shot in-context learning (ICL) enables pre-trained language models to perform a previously-unseen task without any gradient-based training by feeding a small number of training examples as part of the input. ICL incurs substantial computational, memory, and storage costs because it involves processing all of the training examples every time a prediction is made. Parameter-efficient fine-tuning (PEFT) (e.g. adapter modules, prompt tuning, sparse update methods, etc.) offers an alternative paradigm where a small set of parameters are trained to enable a model to perform the new task. In this paper, we rigorously compare few-shot ICL and PEFT and demonstrate that the latter offers better accuracy as well as dramatically lower computational costs. Along the way, we introduce a new PEFT method called (IA)Â³ that scales activations by learned vectors, attaining stronger performance while only introducing a relatively tiny amount of new parameters. We also propose a simple recipe based on the T0 model called T-Few that can be applied to new tasks without task-specific tuning or modifications. We validate the effectiveness of T-Few on completely unseen tasks by applying it to the RAFT benchmark, attaining super-human performance for the first time and outperforming the state-of-the-art by 6% absolute. All of the code used in our experiments is publicly available.


* Useful sentences :  


{% endhighlight %}  

<br/>

[Paper link]()  
[~~Lecture link~~]()   

<br/>

# ë‹¨ì–´ì •ë¦¬  
*  







 
<br/>
# Methodology    


---

### 1. ëª¨ë¸ ë° ë°ì´í„°ì…‹

#### ğŸ‡°ğŸ‡· ì„¤ëª…:

T-FewëŠ” T5 ê¸°ë°˜ì˜ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì¸ T0-3Bë¥¼ ì‚¬ìš©í•˜ë©°, í•™ìŠµì— ì‚¬ìš©ë˜ì§€ ì•Šì•˜ë˜ íƒœìŠ¤í¬ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
RAFTì™€ ê°™ì€ ì‹¤ì œ íƒœìŠ¤í¬ë„ í¬í•¨ë˜ì–´ ìˆì–´ í˜„ì‹¤ì ì¸ few-shot ìƒí™©ì„ ë°˜ì˜í•©ë‹ˆë‹¤.

#### ğŸ‡ºğŸ‡¸ Explanation:

T-Few builds on the T5-based model T0-3B. It evaluates generalization performance on unseen tasks such as ANLI, COPA, and real-world datasets like RAFT.

---

### 2. ì†ì‹¤ í•¨ìˆ˜ (Loss Functions)

#### ğŸ‡°ğŸ‡· ì„¤ëª…:

ê¸°ì¡´ ì–¸ì–´ ëª¨ë¸ ì†ì‹¤ ì™¸ì— ë‘ ê°€ì§€ ì¶”ê°€ ì†ì‹¤ì„ ë„ì…í•©ë‹ˆë‹¤:
(1) Unlikelihood LossëŠ” í‹€ë¦° ì •ë‹µì— ë†’ì€ í™•ë¥ ì´ í• ë‹¹ë˜ì§€ ì•Šë„ë¡ ì–µì œí•˜ë©°,
(2) Length-Normalized LossëŠ” ì§§ì€ ë‹µë³€ì— ê³¼ë„í•˜ê²Œ ìœ ë¦¬í•œ ê¸°ì¡´ ì–¸ì–´ ëª¨ë¸ì˜ ê²½í–¥ì„ ë³´ì •í•©ë‹ˆë‹¤.

#### ğŸ‡ºğŸ‡¸ Explanation:

Two new loss terms are added to the standard LM loss:
(1) **Unlikelihood Loss** discourages high probabilities for incorrect candidates,
(2) **Length-Normalized Loss** corrects the modelâ€™s bias toward shorter answers.

---

#### ìˆ˜ì‹ (Formulas)

* ê¸°ë³¸ LM ì†ì‹¤ (Language Modeling Loss):

```latex
$$
\mathcal{L}_{\text{LM}} = -\frac{1}{T} \sum_{t} \log p(y_t \mid x, y_{<t})
$$
```

* ì˜ëª»ëœ í›„ë³´ ì–µì œ (Unlikelihood Loss):

```latex
$$
\mathcal{L}_{\text{UL}} = - \sum_{n=1}^{N} \sum_{t=1}^{T^{(n)}} \log \left( 1 - p\left(\hat{y}^{(n)}_t \mid x, \hat{y}^{(n)}_{<t} \right) \right)
$$
```

* ì •ë‹µ ê¸¸ì´ ë³´ì • (Length-Normalized Loss):

```latex
$$
\beta(x, y) = \frac{1}{T} \sum_{t} \log p(y_t \mid x, y_{<t})
$$

$$
\mathcal{L}_{\text{LN}} = - \log \left( \frac{\exp(\beta(x, y))}{\exp(\beta(x, y)) + \sum_{n=1}^{N} \exp(\beta(x, \hat{y}^{(n)}))} \right)
$$
```

* ìµœì¢… ì†ì‹¤ ê²°í•© (Final Loss):

```latex
$$
\mathcal{L} = \mathcal{L}_{\text{LM}} + \mathcal{L}_{\text{UL}} + \mathcal{L}_{\text{LN}}
$$
```

---

### 3. (IA)Â³: ìƒˆë¡œìš´ PEFT ê¸°ë²•

#### ğŸ‡°ğŸ‡· ì„¤ëª…:

(IA)Â³ëŠ” íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  íŠœë‹ ë°©ë²•ìœ¼ë¡œ, ê° ë ˆì´ì–´ì˜ attentionê³¼ feed-forward ì¤‘ê°„ê°’ì— ëŒ€í•´ ì‘ì€ ìŠ¤ì¼€ì¼ ë²¡í„°ë¥¼ ê³±í•˜ì—¬ ì¡°ì ˆí•©ë‹ˆë‹¤.
ì´ ë°©ì‹ì€ ê¸°ì¡´ íŒŒë¼ë¯¸í„°ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ì„œë„ ê° íƒœìŠ¤í¬ì— ë§ëŠ” ì¡°ì ˆì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

#### ğŸ‡ºğŸ‡¸ Explanation:

(IA)Â³ is a Parameter-Efficient Fine-Tuning method. It applies small learned vectors to rescale intermediate values in self-attention and feed-forward layers.
This allows task-specific adaptation with minimal new parameters.

---

#### ìˆ˜ì‹ (Formulas)

* Self-Attention ìˆ˜ì •:

```latex
$$
\text{Attention} = \text{softmax}\left( \frac{Q (l_k \odot K^\top)}{\sqrt{d_k}} \right) (l_v \odot V)
$$
```

* Feed-forward ìˆ˜ì •:

```latex
$$
(l_{ff} \odot \gamma(W_1 x)) W_2
$$
```

* ì„¤ëª…: \$\odot\$ëŠ” element-wise ê³±, \$l\_k\$, \$l\_v\$, \$l\_{ff}\$ëŠ” ê° ìœ„ì¹˜ì— ëŒ€í•œ í•™ìŠµ ê°€ëŠ¥í•œ ë²¡í„°ì…ë‹ˆë‹¤.

---

### 4. (IA)Â³ ì‚¬ì „í•™ìŠµ ì „ëµ

#### ğŸ‡°ğŸ‡· ì„¤ëª…:

(IA)Â³ ë²¡í„°ëŠ” T0ê°€ í•™ìŠµëœ ë©€í‹°íƒœìŠ¤í¬ mixtureë¥¼ ì‚¬ìš©í•´ ë¯¸ë¦¬ ì‚¬ì „í•™ìŠµë©ë‹ˆë‹¤.
ì´í›„ì— few-shot fine-tuning ì‹œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ ì„±ëŠ¥ì´ ë¹ ë¥´ê²Œ í–¥ìƒë©ë‹ˆë‹¤.

#### ğŸ‡ºğŸ‡¸ Explanation:

The (IA)Â³ vectors are pretrained on the same multi-task mixture used to train T0.
This enables efficient reuse during fine-tuning and boosts few-shot performance.

---

### 5. ì „ì²´ T-Few ë ˆì‹œí”¼ ìš”ì•½

#### ğŸ‡°ğŸ‡· ì„¤ëª…:

T-FewëŠ” T0 ë°±ë³¸ ëª¨ë¸ ìœ„ì— (IA)Â³ë¥¼ ì¶”ê°€í•˜ê³ , ìƒˆë¡œìš´ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ë„ì…í•´ ì ì€ ìƒ˜í”Œë¡œë„ ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆê²Œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

#### ğŸ‡ºğŸ‡¸ Explanation:

T-Few adds (IA)Â³ and new losses to the T0 backbone, enabling strong few-shot adaptation with minimal data and compute.

---

####  í•™ìŠµ ì„¤ì • (Training Setup)

| í•­ëª©                  | ì„¤ì •ê°’                  |
| ------------------- | -------------------- |
| í•™ìŠµ ìŠ¤í… (Steps)       | 1,000                |
| ë°°ì¹˜ í¬ê¸° (Batch Size)  | 8                    |
| ì˜µí‹°ë§ˆì´ì € (Optimizer)   | Adafactor            |
| í•™ìŠµë¥  (Learning Rate) | \$3 \times 10^{-3}\$ |

---





##  T-Few Method Summary (with Explanations â€“ Markdown + LaTeX)

---

### 1. Model and Dataset

**Model**: T0-3B (based on T5, fine-tuned on multi-task prompted data)
**Evaluation Datasets**: 9 tasks held out from T0 training (e.g., ANLI, COPA, WiC) and the RAFT benchmark

** Explanation**:
T-Few leverages T0-3B, a large-scale model built on T5, and evaluates its ability to generalize to unseen tasks. RAFT tasks are also included, making the evaluation reflect realistic few-shot scenarios.

---

### 2. Loss Functions

#### Components:

* **Language Modeling Loss**: Standard token-level loss used during autoregressive generation
* **Unlikelihood Loss**: Penalizes high probabilities assigned to incorrect candidates
* **Length-Normalized Loss**: Reduces bias toward short answers, which usually receive higher log-probs

---

####  Formulas

* **Language Modeling Loss**:

```latex
$$
\mathcal{L}_{\text{LM}} = -\frac{1}{T} \sum_{t} \log p(y_t \mid x, y_{<t})
$$
```

* **Unlikelihood Loss**:

```latex
$$
\mathcal{L}_{\text{UL}} = - \sum_{n=1}^{N} \sum_{t=1}^{T^{(n)}} \log \left( 1 - p\left(\hat{y}^{(n)}_t \mid x, \hat{y}^{(n)}_{<t} \right) \right)
$$
```

* **Length-Normalized Loss**:

```latex
$$
\beta(x, y) = \frac{1}{T} \sum_{t} \log p(y_t \mid x, y_{<t})
$$

$$
\mathcal{L}_{\text{LN}} = - \log \left( \frac{\exp(\beta(x, y))}{\exp(\beta(x, y)) + \sum_{n=1}^{N} \exp(\beta(x, \hat{y}^{(n)}))} \right)
$$
```

* **Final Combined Loss**:

```latex
$$
\mathcal{L} = \mathcal{L}_{\text{LM}} + \mathcal{L}_{\text{UL}} + \mathcal{L}_{\text{LN}}
$$
```

** Explanation**:
The final loss improves model robustness and answer quality by:

* Learning from correct outputs (`LM`)
* Penalizing wrong answers (`UL`)
* Adjusting for output length (`LN`)

---

### 3. (IA)Â³: New PEFT (Parameter-Efficient Fine-Tuning) Method

**What it does**:
Applies learned scaling vectors to attention and FFN intermediate values with minimal additional parameters.

---

####  Formulas

* **Modified Self-Attention**:

```latex
$$
\text{Attention} = \text{softmax}\left( \frac{Q (l_k \odot K^\top)}{\sqrt{d_k}} \right) (l_v \odot V)
$$
```

* **Modified Feed-Forward Layer**:

```latex
$$
(l_{ff} \odot \gamma(W_1 x)) W_2
$$
```

** Explanation**:
Instead of updating all weights, (IA)Â³ learns small task-specific vectorsâ€”\$l\_k\$, \$l\_v\$, and \$l\_{ff}\$â€”which scale intermediate results.
This saves memory and improves few-shot performance.

---

### 4. (IA)Â³ Pretraining

**Pretraining Setup**:
(IA)Â³ vectors are pretrained on the same multitask dataset used for T0.

** Explanation**:
These pretrained adapters make it easier to fine-tune on new tasks with few samples, as the model already has a task-general adjustment mechanism.

---

### 5. T-Few Training Recipe

####  Settings:

| Parameter      | Value                |
| -------------- | -------------------- |
| Training Steps | 1,000                |
| Batch Size     | 8                    |
| Optimizer      | Adafactor            |
| Learning Rate  | \$3 \times 10^{-3}\$ |

---

####  Summary Explanation:

T-Few combines a strong pretrained base model (T0), parameter-efficient tuning (IAÂ³), and a carefully designed loss function to adapt to new tasks quickly and efficientlyâ€”especially when data is scarce.





   
 
<br/>
# Results  



### 1.  **ë²¤ì¹˜ë§ˆí¬ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹**

* **T0 í•™ìŠµ ì œì™¸ íƒœìŠ¤í¬** (9ê°œ): ANLI, CB, RTE, WiC, WSC, Winogrande, COPA, H-SWAG, Story Cloze
* **RAFT benchmark**: ì‹¤ì œ ì‘ìš© ê¸°ë°˜ few-shot íƒœìŠ¤í¬ 11ê°œ, ê° 50ê°œ í•™ìŠµ ìƒ˜í”Œë§Œ ì¡´ì¬

---

### 2.  **ë¹„êµ ëª¨ë¸ (ê²½ìŸ ì•„í‚¤í…ì²˜ë“¤)**

| ë°©ë²•                          | íŠ¹ì§•                                                   |
| --------------------------- | ---------------------------------------------------- |
| **T-Few**                   | ì œì•ˆí•œ ë°©ë²•: T0 + (IA)Â³ + L<sub>UL</sub> + L<sub>LN</sub> |
| **T0**                      | zero-shot T5 ê¸°ë°˜                                      |
| **T5+LM**                   | few-shot in-context í•™ìŠµ                               |
| **GPT-3 6.7B / 13B / 175B** | OpenAI GPT-3, few-shot in-context ë°©ì‹                 |
| **PET, SetFit**             | RAFTì— ì‚¬ìš©ëœ ê¸°ì¡´ SOTA ë°©ë²•                                 |

---

### 3.  **í…ŒìŠ¤íŠ¸ íƒœìŠ¤í¬ ìœ í˜•**

* **ë¶„ë¥˜ / ë‹¤ì§€ì„ ë‹¤** (classification / multiple-choice)
* í‰ê°€ ë°©ì‹: **Rank Classification** (ì •ë‹µ í›„ë³´ë“¤ì˜ log-probì„ ë¹„êµí•˜ì—¬ ìµœê³  í™•ë¥  ì„ íƒ)

---

### 4.  **ì„±ëŠ¥ ë¹„êµ ê²°ê³¼**

#### (1) T0 í…ŒìŠ¤íŠ¸ì…‹ (9ê°œ held-out task)

| ëª¨ë¸               | Accuracy  | FLOPs (ì¶”ë¡ ) | íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ |
| ---------------- | --------- | ---------- | --------- |
| **T-Few (ours)** | **72.4%** | **1.1e12** | ì•½ 0.01%   |
| T0 (zero-shot)   | 66.9%     | 1.1e12     | 0         |
| T5+LM (ICL)      | 49.6%     | 4.5e13     | 0         |
| GPT-3 6.7B       | 57.2%     | 5.4e13     | 0         |
| GPT-3 13B        | 60.3%     | 1.0e14     | 0         |
| GPT-3 175B       | 66.6%     | 1.4e15     | 0         |

â†’ **T-Fewê°€ GPT-3 175Bë³´ë‹¤ 16ë°° ì‘ìœ¼ë©´ì„œë„ ì •í™•ë„ëŠ” ë” ë†’ê³  ê³„ì‚°ëŸ‰ì€ 1,000ë°° ì ìŒ**

---

#### (2) RAFT ë²¤ì¹˜ë§ˆí¬ (11ê°œ real-world task)

| ëª¨ë¸               | Accuracy    |
| ---------------- | ----------- |
| **T-Few (ours)** | **75.8%**  |
| Human baseline   | 73.5%       |
| PET              | 69.6%       |
| SetFit           | 66.9%       |
| GPT-3 175B       | 62.7%       |

â†’ **T-Fewê°€ ìµœì´ˆë¡œ ì¸ê°„ ì„±ëŠ¥ì„ ì´ˆê³¼í•¨**
â†’ ê¸°ì¡´ ìµœê³  ë°©ë²•ë³´ë‹¤ **+6%** ì •í™•ë„ ê°œì„ 

---

##  English Version: Results Summary

### 1.  **Benchmarks and Evaluation Datasets**

* **Held-out tasks from T0**: ANLI, CB, RTE, WiC, WSC, Winogrande, COPA, H-SWAG, Story Cloze
* **RAFT Benchmark**: 11 real-world few-shot tasks, 50 training examples per task

---

### 2.  **Baselines and Competitor Models**

| Method                  | Description                            |
| ----------------------- | -------------------------------------- |
| **T-Few (Ours)**        | T0 + (IA)Â³ + new loss terms            |
| **T0 (zero-shot)**      | Multitask fine-tuned T5, no tuning     |
| **T5+LM (ICL)**         | T5 used with in-context examples       |
| **GPT-3 6.7B/13B/175B** | OpenAI GPT-3 models using few-shot ICL |
| **PET / SetFit**        | Prior best methods on RAFT             |

---

### 3.  **Tasks and Metrics**

* Task Types: Classification, Multiple-choice
* **Evaluation Metric**: **Rank classification** (choose highest probability candidate)

---

### 4.  **Key Performance Results**

#### (1) Held-out Tasks from T0

| Model          | Accuracy  | Inference FLOPs | Updated Params |
| -------------- | --------- | --------------- | -------------- |
| **T-Few**      | **72.4%** | **1.1e12**      | \~0.01%        |
| T0 (zero-shot) | 66.9%     | 1.1e12          | 0              |
| T5+LM (ICL)    | 49.6%     | 4.5e13          | 0              |
| GPT-3 6.7B     | 57.2%     | 5.4e13          | 0              |
| GPT-3 13B      | 60.3%     | 1.0e14          | 0              |
| GPT-3 175B     | 66.6%     | 1.4e15          | 0              |

â†’ T-Few outperforms all, including GPT-3 175B (16Ã— larger model) with 1,000Ã— fewer FLOPs

---

#### (2) RAFT Real-world Tasks

| Model            | Accuracy    |
| ---------------- | ----------- |
| **T-Few (Ours)** | **75.8%**  |
| Human baseline   | 73.5%       |
| PET              | 69.6%       |
| SetFit           | 66.9%       |
| GPT-3 175B       | 62.7%       |

â†’ **T-Few is the first method to outperform human performance on RAFT**
â†’ Beats previous SOTA by **+6% absolute accuracy**






<br/>
# ì˜ˆì œ  




### 1.  In-Context Learning ì˜ˆì‹œ

ICLì—ì„œ ì‚¬ìš©í•˜ëŠ” ëŒ€í‘œ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ì€ **ì² ì ë°”ê¾¸ê¸°(task: cycled letter unscrambling)** ë¬¸ì œì…ë‹ˆë‹¤:

####  ì…ë ¥ ì˜ˆì‹œ (4-shot ICL):

```
Please unscramble the letters into a word, and write that word:
asinoc = casino, 
yfrogg = froggy, 
plesim = simple, 
iggestb = biggest, 
astedro =
```

####  ëª¨ë¸ì´ ìƒì„±í•´ì•¼ í•  ì •ë‹µ:

```
roasted
```

â†’ ì´ëŸ° ì‹ìœ¼ë¡œ few-shot ì˜ˆì‹œë“¤ì„ í•¨ê»˜ ë„£ê³  ë§ˆì§€ë§‰ì— ì •ë‹µì„ ìœ ë„í•˜ëŠ” ë°©ì‹ì´ ICLì…ë‹ˆë‹¤.

---

### 2.  (IA)Â³ ì ìš© ìœ„ì¹˜ ì˜ˆì‹œ

ì œì•ˆëœ PEFT ë°©ë²•ì¸ **(IA)Â³**ì—ì„œëŠ” Transformer ë¸”ë¡ ë‚´ **íŠ¹ì • ìœ„ì¹˜ì˜ í™œì„±ê°’**ì— ëŒ€í•´ í•™ìŠµëœ ë²¡í„°ë¥¼ ê³±í•©ë‹ˆë‹¤:

* Self-Attention: key (`K`)ì™€ value (`V`) ë²¡í„°ì— ê³±í•˜ê¸°

  $$
  \text{softmax}\left( \frac{Q \cdot (l_k \odot K^T)}{\sqrt{d_k}} \right) \cdot (l_v \odot V)
  $$

* Feed-forward network:

  $$
  (l_{ff} \odot \gamma(W_1 x)) W_2
  $$

â†’ ì¦‰, ì´ í•™ìŠµëœ ë²¡í„°ë“¤ $l_k, l_v, l_{ff}$ëŠ” íƒœìŠ¤í¬ë³„ë¡œ í•™ìŠµë˜ë©°, ì›ë˜ ëª¨ë¸ êµ¬ì¡°ë¥¼ ê±°ì˜ ë³€ê²½í•˜ì§€ ì•Šê³  ë¯¸ì„¸ ì¡°ì •ì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.

---

### 3.  RAFT ë²¤ì¹˜ë§ˆí¬ ì˜ˆì‹œ

**RAFT ë²¤ì¹˜ë§ˆí¬**ëŠ” ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ìœ ìš©í•œ 11ê°œì˜ í…ìŠ¤íŠ¸ ë¶„ë¥˜ íƒœìŠ¤í¬ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê·¸ ì¤‘ ì¼ë¶€ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

* **Banking77**: ê³ ê°ì˜ ì§ˆë¬¸ ë¶„ë¥˜ ("How do I reset my pin?" â†’ "Card issues")
* **TweetEval-hate**: íŠ¸ìœ—ì˜ í˜ì˜¤ ë°œì–¸ ê°ì§€ ("We don't need those people here." â†’ hate)
* **CivilComments**: ëŒ“ê¸€ì˜ ê³µê²©ì„± ë¶„ë¥˜

â†’ ê° íƒœìŠ¤í¬ëŠ” ë‹¨ **50ê°œì˜ í•™ìŠµ ìƒ˜í”Œ**ë§Œ ì œê³µë˜ê³ , ì •ë‹µì´ ì—†ëŠ” í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤.

---

##  English Version: Concrete Examples

### 1.  In-Context Learning Example

A core example for ICL is the **cycled letter unscrambling task**:

####  Input (4-shot ICL prompt):

```
Please unscramble the letters into a word, and write that word:
asinoc = casino, 
yfrogg = froggy, 
plesim = simple, 
iggestb = biggest, 
astedro =
```

####  Expected output:

```
roasted
```

â†’ This exemplifies how few-shot ICL provides a few labeled examples in the input to condition the model.

---

### 2.  (IA)Â³ Injection Example

The proposed PEFT method **(IA)Â³** modifies the model by rescaling intermediate activations. The learnable vectors are injected into the following locations:

* Self-Attention:

  $$
  \text{softmax}\left( \frac{Q \cdot (l_k \odot K^T)}{\sqrt{d_k}} \right) \cdot (l_v \odot V)
  $$

* Feed-Forward Layer:

  $$
  (l_{ff} \odot \gamma(W_1 x)) W_2
  $$

â†’ These vectors ($l_k$, $l_v$, $l_{ff}$) are task-specific but small, and allow efficient fine-tuning without modifying the entire model.

---

### 3.  RAFT Dataset Examples

**RAFT** contains 11 real-world classification tasks, each with only 50 training examples. Examples include:

* **Banking77**: Classify customer intent
  e.g., *"How do I reset my pin?"* â†’ `"Card issues"`

* **TweetEval-hate**: Hate speech detection on tweets
  e.g., *"We don't need those people here."* â†’ `"hate"`

* **CivilComments**: Toxic comment classification

â†’ No validation set is given. The test labels are hidden, making this a realistic few-shot setting.




<br/>  
# ìš”ì•½   




T-FewëŠ” T0 ëª¨ë¸ì— ìƒˆë¡œìš´ PEFT ê¸°ë²•ì¸ (IA)Â³ë¥¼ ì ìš©í•˜ê³ , ì¶”ê°€ ì†ì‹¤ í•¨ìˆ˜(LUL, LLN)ë¥¼ ê²°í•©í•´ íš¨ìœ¨ì ìœ¼ë¡œ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
ì´ ë°©ë²•ì€ GPT-3ë³´ë‹¤ í›¨ì”¬ ì ì€ ê³„ì‚°ëŸ‰ìœ¼ë¡œë„ ë” ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìœ¼ë©°, RAFT ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” ì¸ê°„ ì„±ëŠ¥ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.
ì˜ˆì‹œë¡œ, 4-shot ë¬¸ì œë‚˜ ê³ ê° ì§ˆë¬¸ ë¶„ë¥˜ì™€ ê°™ì€ ì‹¤ì œ íƒœìŠ¤í¬ì— ì†Œìˆ˜ ìƒ˜í”Œë§Œìœ¼ë¡œë„ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

---


T-Few fine-tunes the T0 model using a novel PEFT method called (IA)Â³, combined with unlikelihood and length-normalized losses for better efficiency.
It outperforms GPT-3 while requiring over 1,000Ã— fewer FLOPs, and is the first method to surpass human performance on the RAFT benchmark.
In real-world tasks like few-shot word unscrambling or intent classification, T-Few shows strong results with only a handful of training examples.


<br/>  
# ê¸°íƒ€  




###  Figure 2: ë‹¤ì–‘í•œ PEFT ë°©ë²• ë¹„êµ

* ë‚´ìš©: ì—¬ëŸ¬ PEFT ë°©ë²•ì˜ ì •í™•ë„ì™€ ì—…ë°ì´íŠ¸ëœ íŒŒë¼ë¯¸í„° ë¹„ìœ¨ ë¹„êµ
* ê²°ê³¼: (IA)Â³ëŠ” ì „ì²´ ëª¨ë¸ íŒŒì¸íŠœë‹ë³´ë‹¤ ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í•œ ìœ ì¼í•œ ë°©ë²•
* ì¸ì‚¬ì´íŠ¸: ì—…ë°ì´íŠ¸ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì ìœ¼ë©´ì„œë„ ì„±ëŠ¥ì´ ë†’ì•„ íš¨ìœ¨ì„±ì´ íƒì›”í•¨

---

###  Figure 3: ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì˜ FLOPs vs ì •í™•ë„

* ë‚´ìš©: ì¶”ë¡  ê³„ì‚°ëŸ‰(FLOPs) ëŒ€ë¹„ ì •í™•ë„ ë¹„êµ
* ê²°ê³¼: T-FewëŠ” GPT-3 175Bë³´ë‹¤ ì •í™•ë„ëŠ” ë” ë†’ê³  ê³„ì‚°ëŸ‰ì€ 1,000ë°° ì ìŒ
* ì¸ì‚¬ì´íŠ¸: íŒŒì¸íŠœë‹ ë¹„ìš©ì´ ë§¤ìš° ë‚®ìœ¼ë©´ì„œë„ ì„±ëŠ¥ì€ ìµœê³  ìˆ˜ì¤€

---

###  Table 1: Held-out íƒœìŠ¤í¬ì— ëŒ€í•œ ì •í™•ë„ ë° ë¹„ìš© ìš”ì•½

| ëª¨ë¸         | ì •í™•ë„       | ì¶”ë¡  FLOPs | í•™ìŠµ FLOPs | ì €ì¥ ê³µê°„ |
| ---------- | --------- | -------- | -------- | ----- |
| T-Few      | **72.4%** | 1.1e12   | 2.7e16   | 4.2MB |
| GPT-3 175B | 66.6%     | 1.4e15   | 0        | 16KB  |

* ì¸ì‚¬ì´íŠ¸: T-FewëŠ” ì •í™•ë„ì™€ ìì› íš¨ìœ¨ì„± ëª¨ë‘ì—ì„œ ìµœê³  ì„±ëŠ¥

---

###  Table 2: RAFT ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ (ìƒìœ„ 5ê°œ ë°©ë²•)

* T-Few: 75.8% (ìµœê³  ì„±ëŠ¥, ì¸ê°„ ì„±ëŠ¥ 73.5% ì´ˆê³¼)
* ì¸ì‚¬ì´íŠ¸: ì‹¤ì œ íƒœìŠ¤í¬ì— ëŒ€í•´ ì¼ë°˜í™” ì„±ëŠ¥ì´ ë›°ì–´ë‚¨

---

###  Appendix F: Ablation ì‹¤í—˜

* Pre-training ì œê±° â†’ ì •í™•ë„ 1.6% ê°ì†Œ
* LUL ë° LLN ì œê±° â†’ ì •í™•ë„ 4.1% ê°ì†Œ
* ë‘˜ ë‹¤ ì œê±° â†’ ì •í™•ë„ 2.5% ê°ì†Œ
* ì¸ì‚¬ì´íŠ¸: ê° êµ¬ì„±ìš”ì†Œê°€ ëª¨ë‘ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•¨

---


###  Figure 2: Comparison of PEFT Methods

* Content: Accuracy vs % of parameters updated
* Finding: **(IA)Â³ is the only method to outperform full-model fine-tuning**
* Insight: Very few parameters can be updated for excellent performance â€” high efficiency

---

###  Figure 3: Accuracy vs Inference FLOPs

* Content: Performance vs computational cost
* Finding: **T-Few outperforms GPT-3 175B with 1,000Ã— fewer FLOPs**
* Insight: High performance with very low computational overhead

---

###  Table 1: Held-out Task Performance & Cost Summary

| Model      | Accuracy  | Inference FLOPs | Training FLOPs | Disk Storage |
| ---------- | --------- | --------------- | -------------- | ------------ |
| **T-Few**  | **72.4%** | 1.1e12          | 2.7e16         | 4.2MB        |
| GPT-3 175B | 66.6%     | 1.4e15          | 0              | 16KB         |

* Insight: T-Few dominates both in accuracy and cost-effectiveness

---

###  Table 2: RAFT Benchmark (Top 5 Results)

* **T-Few**: 75.8% (First to outperform human baseline at 73.5%)
* Insight: Outstanding real-world generalization in few-shot settings

---

###  Appendix F: Ablation Study

* Removing pre-training â†’ â€“1.6% accuracy
* Removing LUL + LLN losses â†’ â€“4.1%
* Removing both â†’ â€“2.5%
* Insight: All components (losses, pretraining) contribute meaningfully to performance




<br/>
# refer format:     



@inproceedings{liu2022fewshot,
  title     = {Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning},
  author    = {Haokun Liu and Derek Tam and Mohammed Muqeeth and Jay Mohta and Tenghao Huang and Mohit Bansal and Colin Raffel},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2022},
  url       = {https://github.com/r-three/t-few}
}




Liu, Haokun, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and Colin Raffel. â€œFew-Shot Parameter-Efficient Fine-Tuning Is Better and Cheaper than In-Context Learning.â€ Advances in Neural Information Processing Systems (NeurIPS), 2022.  



