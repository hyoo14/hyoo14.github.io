---
layout: post
title:  "[2025]Self-supervised representation learning on gene expression data"
date:   2025-11-29 01:43:51 -0000
categories: study
---

{% highlight ruby %}

한줄 요약: 이 연구에서는 유전자 발현 데이터에서의 표현 학습을 위해 세 가지 자가 감독 학습 방법(SCARF, VIME, BYOL)을 평가하였다.


짧은 요약(Abstract) :



이 연구는 유전자 발현 데이터에서 표현 학습을 위한 자기 지도 학습(self-supervised learning) 방법의 적용을 조사합니다. 유전자 발현 데이터로부터 표현을 학습하는 것은 질병 메커니즘, 약물 반응 및 개인 맞춤형 의학에 대한 통찰력을 제공하는 중요한 작업입니다. 전통적인 기계 학습 및 심층 학습 방법은 대량의 주석이 달린 데이터에 의존하는데, 이는 유전자 발현 데이터의 경우 비용이 많이 들고 시간이 소요됩니다. 자기 지도 학습은 주석이 없는 데이터의 구조에서 직접 정보를 추출하여 이러한 한계를 극복할 수 있는 유망한 접근 방식으로 부상했습니다. 본 연구에서는 여러 공개 유전자 발현 데이터 세트를 사용하여 선택한 세 가지 자기 지도 학습 방법이 복잡한 정보를 효과적으로 포착하고 표현을 생성하여 표현 예측 정확도를 향상시킬 수 있음을 보여줍니다. 결과적으로 자기 지도 학습 방법이 전통적인 감독 모델보다 더 나은 성능을 발휘할 수 있으며, 주석 데이터에 대한 의존성을 줄이는 데 중요한 이점을 제공함을 입증합니다. 각 방법의 성능에 대한 포괄적인 분석을 제공하고, 연구 사례에 따라 이러한 방법을 사용할 수 있는 권장 사항을 제시합니다. 마지막으로, 유전자 발현 데이터 분석 분야에서 자기 지도 학습의 적용을 향상시키기 위한 향후 연구 방향을 제시합니다.




This study investigates the application of self-supervised learning methods for representation learning on gene expression data. Learning representations from gene expression data is a crucial task that provides insights into disease mechanisms, drug responses, and personalized medicine. Traditional machine learning and deep learning methods rely on large amounts of labeled data, which can be costly and time-consuming to obtain in the case of gene expression data. Self-supervised learning has emerged as a promising approach to overcome these limitations by extracting information directly from the structure of unlabeled data. Using several publicly available gene expression datasets, we demonstrate how the selected self-supervised methods can effectively capture complex information and improve phenotype prediction accuracy. The results show that self-supervised learning methods can outperform traditional supervised models while offering significant advantages by reducing the dependency on annotated data. We provide a comprehensive analysis of the performance of each method and recommendations for their use depending on the case under study. Finally, we outline future research directions to enhance the application of self-supervised learning in the field of gene expression data analysis.


* Useful sentences :


{% endhighlight %}

<br/>

[Paper link]()
[~~Lecture link~~]()

<br/>

# 단어정리
*


<br/>
# Methodology



이 연구에서는 유전자 발현 데이터에서의 표현 학습을 위해 세 가지 자가 감독 학습(self-supervised learning) 방법을 적용했습니다. 이 방법들은 각각 대조적 학습(contrastive learning), 생성적 학습(generative learning), 하이브리드 학습(hybrid learning)으로 분류됩니다. 각 방법은 고유한 아키텍처와 훈련 기법을 가지고 있으며, 유전자 발현 데이터의 특성을 고려하여 설계되었습니다.

1. **SCARF (Self-supervised Contrastive Learning using Random Feature Corruption)**:
   - SCARF는 대조적 학습 방법으로, 주어진 데이터의 일부 특성을 무작위로 손상시켜서 원본 데이터와 손상된 데이터 간의 유사성을 학습합니다. 이 과정에서, 손상된 데이터는 원본 데이터의 일부 특성을 무작위로 대체하여 생성됩니다. 그런 다음, 원본 데이터와 손상된 데이터는 인코더를 통해 표현으로 변환되고, 이 표현들은 대조적 손실 함수(InfoNCE loss)를 통해 서로 가까워지도록 학습됩니다. 이 방법은 유전자 발현 데이터의 고차원성과 낮은 샘플 수를 고려하여 설계되었습니다.

2. **VIME (Variational Information Maximization Estimator)**:
   - VIME는 생성적 오토인코더 기반의 자가 감독 학습 방법으로, 두 가지 전제 작업(pretext tasks)을 사용합니다: 특성 재구성(feature reconstruction)과 마스크 재구성(mask reconstruction). 이 방법은 각 데이터 샘플에 대해 이진 마스크 벡터를 생성하여 손상된 버전을 만들고, 인코더를 통해 이 손상된 데이터를 표현으로 변환합니다. 그런 다음, 디코더는 손상된 특성을 재구성하고, 마스크된 특성을 예측합니다. 이 과정에서 손실 함수는 두 가지 재구성 손실을 결합하여 최적화됩니다.

3. **BYOL (Bootstrap Your Own Latent)**:
   - BYOL은 하이브리드 학습 방법으로, 두 개의 신경망 브랜치를 사용합니다: 온라인 브랜치와 타겟 브랜치. 온라인 브랜치는 원본 데이터 샘플을 입력으로 받아 예측을 생성하고, 타겟 브랜치는 손상된 데이터 샘플을 입력으로 받아 예측을 생성합니다. 이 두 브랜치의 출력 간의 거리(l2-distance)를 최소화하는 방식으로 학습이 진행됩니다. BYOL은 긍정적인 쌍만을 사용하여 학습하며, 이는 데이터의 다양성을 보장합니다.

이 연구에서는 TCGA와 ARCHS4 데이터셋을 사용하여 각 방법의 성능을 평가했습니다. 각 데이터셋은 사전 훈련(pre-training)과 미세 조정(fine-tuning) 단계로 나뉘며, 사전 훈련 단계에서는 레이블이 없는 데이터를 사용하고, 미세 조정 단계에서는 레이블이 있는 데이터를 사용합니다. 이러한 접근 방식은 유전자 발현 데이터의 특성을 고려하여 설계되었으며, 자가 감독 학습 방법이 전통적인 감독 학습 방법보다 더 나은 성능을 발휘할 수 있음을 보여주었습니다.




In this study, three self-supervised learning methods were applied for representation learning on gene expression data. These methods are categorized into contrastive learning, generative learning, and hybrid learning. Each method has its unique architecture and training techniques, designed to consider the characteristics of gene expression data.

1. **SCARF (Self-supervised Contrastive Learning using Random Feature Corruption)**:
   - SCARF is a contrastive learning method that learns the similarity between original and corrupted versions of the data by randomly corrupting some features of the given data. In this process, a corrupted version of the data is generated by randomly replacing some features of the original data. The original and corrupted data are then transformed into representations through an encoder, and these representations are trained to be close to each other using a contrastive loss function (InfoNCE loss). This method is designed considering the high dimensionality and low sample size of gene expression data.

2. **VIME (Variational Information Maximization Estimator)**:
   - VIME is a generative autoencoder-based self-supervised learning method that utilizes two pretext tasks: feature reconstruction and mask reconstruction. This method generates a binary mask vector for each data sample to create a corrupted version, which is then transformed into a representation through an encoder. The decoder predicts the values of the corrupted features and the masked features. The loss function combines two reconstruction losses to optimize the model.

3. **BYOL (Bootstrap Your Own Latent)**:
   - BYOL is a hybrid learning method that employs two neural network branches: an online branch and a target branch. The online branch takes the original data sample as input to generate predictions, while the target branch takes the corrupted data sample to produce predictions. The learning process minimizes the distance (l2-distance) between the outputs of these two branches. BYOL learns from positive pairs only, ensuring the diversity of the data.

The study evaluated the performance of each method using the TCGA and ARCHS4 datasets. Each dataset was divided into pre-training and fine-tuning stages, where the pre-training stage utilized unlabeled data, and the fine-tuning stage used labeled data. This approach was designed to consider the characteristics of gene expression data and demonstrated that self-supervised learning methods can outperform traditional supervised learning methods.


<br/>
# Results



이 연구에서는 세 가지 자가 지도 학습(self-supervised learning) 방법(SCARF, VIME, BYOL)을 사용하여 유전자 발현 데이터에서 표현을 학습하고, 이를 통해 표현형 예측의 성능을 평가하였다. 실험은 두 개의 RNA-Seq 데이터셋(TCGA와 ARCHS4)을 사용하여 진행되었으며, 각 데이터셋은 사전 훈련(pre-training)과 미세 조정(fine-tuning) 세트로 나누어졌다.

#### 1. 경쟁 모델
비교를 위해, 각 자가 지도 학습 방법의 성능을 비훈련 모델(baseline model)과 비교하였다. 비훈련 모델은 무작위 초기화된 가중치를 가진 모델로, 자가 지도 학습 방법을 사용하지 않고 훈련된 모델이다.

#### 2. 테스트 데이터
- **TCGA 데이터셋**: 9349개의 샘플과 56902개의 유전자로 구성되어 있으며, 7291개의 샘플을 사전 훈련 세트로, 1029개의 샘플을 미세 조정 및 테스트 세트로 사용하였다.
- **ARCHS4 데이터셋**: 53282개의 샘플과 67128개의 유전자로 구성되어 있으며, 50998개의 샘플을 사전 훈련 세트로, 1142개의 샘플을 미세 조정 및 테스트 세트로 사용하였다.

#### 3. 메트릭
모델의 성능은 정확도(accuracy)로 평가되었으며, 미세 조정 과정에서 다양한 비율의 샘플을 사용하여 성능을 비교하였다. 특히, 미세 조정 비율이 낮을 때(예: 0.02에서 1까지) 자가 지도 학습 방법이 비훈련 모델보다 더 나은 성능을 보였다.

#### 4. 비교 결과
- **TCGA 데이터셋**: SCARF, VIME, BYOL 모두 비훈련 모델보다 높은 성능을 보였으며, 특히 BYOL이 가장 우수한 성능을 기록하였다.
- **ARCHS4 데이터셋**: 세 가지 방법 모두 비훈련 모델보다 높은 성능을 보였고, VIME가 가장 높은 성능을 나타냈다.
- **ARCHS4에서 TCGA로의 전이**: BYOL이 다른 두 방법보다 우수한 성능을 보였으며, 이는 서로 다른 데이터셋 간의 전이 학습에서의 효과를 보여준다.

#### 5. 결론
자가 지도 학습 방법은 유전자 발현 데이터에서 표현형 예측 성능을 향상시키는 데 효과적이며, 특히 미세 조정 과정에서 레이어를 언프리즈(unfreeze)할 때 더 좋은 성능을 발휘하였다. SCARF는 동질적인 데이터셋에서 효과적이며, BYOL은 이질적인 데이터셋에서도 성능을 유지하는 장점을 가지고 있다. VIME는 성능이 불안정하여 주의가 필요하다.

---



In this study, three self-supervised learning methods (SCARF, VIME, BYOL) were employed to learn representations from gene expression data and evaluate their performance in phenotype prediction. The experiments were conducted using two RNA-Seq datasets (TCGA and ARCHS4), with each dataset divided into pre-training and fine-tuning sets.

#### 1. Competing Models
To compare the performance, the results of each self-supervised learning method were evaluated against a baseline model. The baseline model was trained without using any self-supervised learning techniques, initialized with random weights.

#### 2. Test Data
- **TCGA Dataset**: Comprising 9349 samples and 56902 genes, with 7291 samples used for the pre-training set and 1029 samples for the fine-tuning and test sets.
- **ARCHS4 Dataset**: Comprising 53282 samples and 67128 genes, with 50998 samples used for the pre-training set and 1142 samples for the fine-tuning and test sets.

#### 3. Metrics
The model performance was evaluated based on accuracy, comparing the performance across various proportions of samples used during the fine-tuning process. Notably, at lower fine-tuning proportions (e.g., from 0.02 to 1), the self-supervised learning methods outperformed the baseline model.

#### 4. Comparison Results
- **TCGA Dataset**: All three methods (SCARF, VIME, BYOL) achieved higher performance than the baseline model, with BYOL showing the best results.
- **ARCHS4 Dataset**: All three methods also outperformed the baseline model, with VIME achieving the highest performance.
- **Transfer from ARCHS4 to TCGA**: BYOL outperformed the other two methods, demonstrating its effectiveness in transfer learning between different datasets.

#### 5. Conclusion
Self-supervised learning methods effectively enhance phenotype prediction performance from gene expression data, particularly when fine-tuning is performed with unfrozen layers. SCARF is effective for homogeneous datasets, while BYOL maintains performance even with heterogeneous datasets. Caution is advised with VIME due to its unstable performance.


<br/>
# 예제



이 논문에서는 유전자 발현 데이터에서의 자기 지도 학습(self-supervised learning) 방법을 사용하여 표현을 학습하고, 이를 통해 표현형 예측을 수행하는 방법을 제안합니다. 연구의 주요 목표는 유전자 발현 데이터로부터 표현형을 예측하는 것입니다. 이를 위해 연구자들은 두 가지 RNA-Seq 데이터셋을 사용하여 실험을 진행했습니다: TCGA(암 유전체 지도)와 ARCHS4(다양한 조직 샘플 데이터).

#### 데이터셋 설명
1. **TCGA 데이터셋**:
   - **입력**: 9349개의 샘플과 56902개의 유전자.
   - **출력**: 19가지 암 유형에 대한 레이블.
   - **테스트 및 트레이닝 분할**: 7291개의 샘플을 사전 훈련(pre-training) 세트로 사용하고, 1029개의 샘플을 파인 튜닝(fine-tuning) 및 테스트 세트로 사용.

2. **ARCHS4 데이터셋**:
   - **입력**: 53282개의 샘플과 67128개의 유전자.
   - **출력**: 19가지 조직 유형에 대한 레이블.
   - **테스트 및 트레이닝 분할**: 50998개의 샘플을 사전 훈련 세트로 사용하고, 1142개의 샘플을 파인 튜닝 및 테스트 세트로 사용.

#### 실험 과정
1. **사전 훈련**: 
   - 각 데이터셋에서 레이블이 없는 데이터를 사용하여 자기 지도 학습 방법을 통해 모델을 사전 훈련합니다. 이 과정에서 SCARF, VIME, BYOL의 세 가지 방법을 사용합니다.
   - 예를 들어, SCARF 방법에서는 각 샘플의 일부 특성을 무작위로 변경하여 변형된 샘플을 생성하고, 원본 샘플과 변형된 샘플 간의 유사성을 학습합니다.

2. **파인 튜닝**:
   - 사전 훈련된 모델을 사용하여 레이블이 있는 데이터로 파인 튜닝을 수행합니다. 이 과정에서 모델의 성능을 평가하기 위해 다양한 비율의 샘플을 사용합니다.
   - 예를 들어, 0.02에서 1까지의 비율로 샘플을 사용하여 모델을 훈련시키고, 각 비율에 대해 모델의 정확도를 측정합니다.

3. **결과 분석**:
   - 모델의 성능을 평가하고, 사전 훈련이 모델의 성능에 미치는 영향을 분석합니다. 특히, 사전 훈련과 파인 튜닝 데이터셋이 동일할 때와 다를 때의 성능 차이를 비교합니다.

이러한 과정을 통해 연구자들은 자기 지도 학습 방법이 유전자 발현 데이터에서 표현형 예측의 성능을 향상시킬 수 있음을 입증하였습니다.

---



This paper proposes a method for learning representations using self-supervised learning on gene expression data, aiming to predict phenotypes. The main goal of the study is to predict phenotypes from gene expression data. To achieve this, the researchers conducted experiments using two RNA-Seq datasets: TCGA (The Cancer Genome Atlas) and ARCHS4 (a dataset of various tissue samples).

#### Dataset Description
1. **TCGA Dataset**:
   - **Input**: 9349 samples and 56902 genes.
   - **Output**: Labels for 19 different cancer types.
   - **Training and Testing Split**: 7291 samples are used for the pre-training set, and 1029 samples are used for both the fine-tuning and testing sets.

2. **ARCHS4 Dataset**:
   - **Input**: 53282 samples and 67128 genes.
   - **Output**: Labels for 19 different tissue types.
   - **Training and Testing Split**: 50998 samples are used for the pre-training set, and 1142 samples are used for both the fine-tuning and testing sets.

#### Experimental Process
1. **Pre-training**: 
   - The model is pre-trained using unlabeled data from each dataset through self-supervised learning methods. Three methods, SCARF, VIME, and BYOL, are employed in this process.
   - For example, in the SCARF method, a corrupted version of each sample is generated by randomly selecting a fraction of its features, and the model learns the similarity between the original and corrupted samples.

2. **Fine-tuning**:
   - The pre-trained model is fine-tuned using labeled data. Various proportions of samples are used to evaluate the model's performance.
   - For instance, the model is trained with sample proportions ranging from 0.02 to 1, and the accuracy of the model is measured for each proportion.

3. **Result Analysis**:
   - The performance of the model is evaluated, and the impact of pre-training on the model's performance is analyzed. The performance differences are compared when the pre-training and fine-tuning datasets are the same versus when they are different.

Through this process, the researchers demonstrate that self-supervised learning methods can enhance the performance of phenotype prediction from gene expression data.

<br/>
# 요약


이 연구에서는 유전자 발현 데이터에서의 표현 학습을 위해 세 가지 자가 감독 학습 방법(SCARF, VIME, BYOL)을 평가하였다. 실험 결과, 자가 감독 학습 방법이 전통적인 감독 학습 모델보다 우수한 성능을 보이며, 특히 BYOL이 데이터 세트 간 전이 학습에서 가장 효과적임을 확인하였다. 이 연구는 자가 감독 학습이 유전자 발현 데이터 분석에 있어 주석 데이터 의존성을 줄이고 예측 성능을 향상시킬 수 있음을 보여준다.



In this study, three self-supervised learning methods (SCARF, VIME, BYOL) were evaluated for representation learning on gene expression data. The results demonstrated that self-supervised learning methods outperformed traditional supervised models, with BYOL showing the most effectiveness in transfer learning between datasets. This research highlights the potential of self-supervised learning to reduce reliance on annotated data and improve predictive performance in gene expression data analysis.

<br/>
# 기타



1. **다이어그램 및 피규어**
   - **Self-supervised pipeline (Figure 1)**: 이 다이어그램은 자기 지도 학습의 두 단계인 사전 훈련(pre-training)과 미세 조정(fine-tuning)을 보여줍니다. 사전 훈련 단계에서는 레이블이 없는 데이터를 사용하여 인코더를 학습하고, 미세 조정 단계에서는 소량의 레이블이 있는 데이터를 사용하여 특정 다운스트림 작업을 수행합니다. 이 구조는 자기 지도 학습이 레이블이 없는 데이터에서 유용한 표현을 학습할 수 있음을 강조합니다.
   - **SCARF, VIME, BYOL 아키텍처 (Figure 2)**: 각 자기 지도 학습 방법의 아키텍처를 시각적으로 설명합니다. SCARF는 대조적 학습을 기반으로 하며, VIME는 생성적 오토인코더를 사용하고, BYOL은 온라인 및 타겟 네트워크를 사용하는 하이브리드 접근법입니다. 이들 각각의 구조는 데이터의 특성에 따라 다르게 설계되어 있으며, 각 방법의 장단점을 이해하는 데 도움이 됩니다.

2. **결과 테이블**
   - **성능 비교 (Table)**: 각 자기 지도 학습 방법의 성능을 비교한 결과가 포함되어 있습니다. SCARF와 BYOL은 동일한 데이터셋에서 미세 조정 시 더 나은 성능을 보였으며, VIME는 아키텍처에 따라 성능이 불안정했습니다. 이 결과는 자기 지도 학습 방법이 데이터셋의 특성과 아키텍처에 따라 다르게 작용할 수 있음을 보여줍니다.

3. **어펜딕스**
   - **보충 자료**: 보충 자료에는 실험 설정, 데이터셋 설명, 하이퍼파라미터 조정 등의 추가 정보가 포함되어 있습니다. 이 정보는 연구의 재현성을 높이고, 다른 연구자들이 유사한 방법을 적용할 수 있도록 돕습니다.



1. **Diagrams and Figures**
   - **Self-supervised pipeline (Figure 1)**: This diagram illustrates the two stages of self-supervised learning: pre-training and fine-tuning. In the pre-training stage, an encoder is learned using unlabeled data, while in the fine-tuning stage, a small amount of labeled data is used for specific downstream tasks. This structure emphasizes the utility of self-supervised learning in extracting useful representations from unlabeled data.
   - **Architectures of SCARF, VIME, BYOL (Figure 2)**: This figure visually explains the architecture of each self-supervised learning method. SCARF is based on contrastive learning, VIME utilizes a generative autoencoder, and BYOL employs a hybrid approach with online and target networks. Understanding these structures helps to grasp the strengths and weaknesses of each method based on the characteristics of the data.

2. **Results Table**
   - **Performance Comparison (Table)**: The results comparing the performance of each self-supervised learning method are included. SCARF and BYOL showed better performance during fine-tuning on the same dataset, while VIME exhibited unstable performance depending on the architecture. This result indicates that self-supervised learning methods can behave differently based on the dataset characteristics and architecture.

3. **Appendix**
   - **Supplementary Material**: The supplementary material includes additional information on experimental setups, dataset descriptions, and hyperparameter tuning. This information enhances the reproducibility of the research and assists other researchers in applying similar methods.

<br/>
# refer format:
### BibTeX   

```bibtex
@article{Dradjat2025,
  author = {Kevin Dradjat and Massinissa Hamidi and Pierre Bartet and Blaise Hanczar},
  title = {Self-supervised representation learning on gene expression data},
  journal = {Bioinformatics},
  volume = {41},
  number = {11},
  pages = {btaf533},
  year = {2025},
  publisher = {Oxford University Press},
  doi = {10.1093/bioinformatics/btaf533},
  url = {https://academic.oup.com/bioinformatics/article/41/11/btaf533/8269452}
}
```

### 시카고 스타일

Dradjat, Kevin, Massinissa Hamidi, Pierre Bartet, and Blaise Hanczar. 2025. "Self-supervised representation learning on gene expression data." *Bioinformatics* 41 (11): btaf533. https://doi.org/10.1093/bioinformatics/btaf533.
