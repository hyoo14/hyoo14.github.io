---
layout: post
title:  "[2023]BioT5: Enriching Cross-modal Integration in Biology with Chemical Knowledge and Natural Language Associations"  
date:   2024-02-22 10:02:11 -0400
categories: study
---

{% highlight ruby %}


짧은 요약(Abstract) :    

* 최근 생물학 연구의 발전은 분자, 단백질, 그리고 자연어의 통합을 활용하여 약물 발견을 강화하고 있음  
* 하지만 현재 모델들은 몇 가지 한계를 보이고 있는데, 예를 들어 유효하지 않은 분자 SMILES의 생성, 문맥 정보의 활용 미흡, 구조화된 지식과 비구조화된 지식을 동등하게 취급하는 것 등이 있음  
* 이러한 문제들을 해결하기 위해, 우리는 화학 지식과 자연어 연관성을 바탕으로 생물학에서의 교차 모달 통합을 풍부하게 하는 포괄적인 사전 훈련 프레임워크인 BioT5를 제안  
* BioT5는 100% 견고한 분자 표현을 위해 SELFIES를 활용하며, 비구조화된 생물학 문헌에서 생물 엔티티의 주변 문맥으로부터 지식을 추출  
* 더 나아가, BioT5는 구조화된 지식과 비구조화된 지식을 구분하여 정보의 보다 효과적인 활용을 이끔  
* 사전 훈련 후에, BioT5는 다양한 작업에서 우수한 성능을 보여주며, 생물 엔티티의 기본적인 관계와 특성을 포착하는 강력한 능력을 입증  

* Recently advances in biology use the mix of molecules, proteins, and natural language to make drug discovery better  
* But, current models have some problems, such as making wrong molecular SMILES, not using context info well, and treating structured and unstructured knowledge the same  
* To fix these problems, authors suggest BioT5, a big pre-training framework that makes cross-modal integration in biology richer with chemical knowledge and natural language links  
* BioT5 uses SELFIES for 100% solid molecular representations and pulls knowledge from the context around bio-entities in unstructured biology texts  
* BioT5 also separates structured and unstructured knowledge for better use of info  
* With pre-training, BioT5 does really well in many tasks, showing its strong skill in catching the basic relations and features of bio-entities  








Useful sentences :  
* 

{% endhighlight %}  

<br/>

[Paper link](https://drive.google.com/drive/folders/1Gj3s_4CSWMY_JawmpscAp187ItIGV6ZX?usp=sharing)  
[~~Lecture link~~]()  

<br/>

# 단어정리  
* modal: 모드, 방식(시각/청각)  
* SMILES: Simplified Molecular Input Line Entry System, 화학물질의 구조를 문자열로 표현한 것, H20는 "O"로, CH4는 "C"로  
* SELFIES: Self-referencing Embedded Strings, 화학 분야 분자구조 표현위한 최식 문자열 기법  
* cornerstone: 모서리돌, 가장 중요, 기본  
* pathways: 단계, 진행과정  
* fuses: 결합하다, 통합하다  
* syntactic: 구조, 문법, 형식  
* semantics: 내용, 개념, 메세지  
* colossal: 매우 큰, 거대한, 엄청난 규모  
* dibromolit: 브롬 두개 합쳐진  
* encompassing: 포함하다, 둘러싸다, 아우르다  
* scaffold: 세포나 조직 자라게 지지해주는 물질 구조  
* membrane-bound: 세포막, 세포내 막 구조에 결합된 분자나 단백잴(신호전달, 물질운반 등 역할)  
* soluble: 용해성, 다른 용매에 용해될 수 있는 분자나 단백질( 효소)  
* solubility: 용매에 용해될 수 있는 최대양  
* worthnoting: 주목할 가치가 있는, 언급될 만한  
* tailored: 맞춤형의 , 개인 맞춤의  
* intricate: 복잡하고 세밀한  
* holistic: 전체적인 입장에서  


<br/>

# 1 Introduction  

# 2 Related Works  
## 2.1 Cross-modal Models in Biology  
### Cross Text-molecule Modalities  
### Cross Text-protein Modalities   
### Cross Three or More Biology Modalities  
## 2.2 Representations of Molecule and Protein  
### Molecule Representation  
### Protein Representation  
# 3 BioT5  
## 3.1 Pre-training Corpus  
## 3.2 Separate Tokenization and Embedding   
## 3.3 Model and Training  
### Model architecture  
### Pre-training  
### Fine-tuning  

# 4 Experiments and Results  
## 4.1 Single-instance Prediction  
### 4.1.1 Molecule Property Prediction  
#### Baselines  
#### Results  
### 4.1.2 Protein Property Prediction  

#### Baselines  
#### Results  
## 4.2 Multi-instance Prediction  
### 4.2.1 Drug-targetInteractionPrediction  
#### Baselines  
#### Results  
### 4.2.2 Protein-protein Interaction Prediction  
#### Baselines  
#### Results  
## 4.3 Cross-modal Generation  
### 4.3.1 Molecule Captioning  
#### Baselines  
#### Results  
### 4.3.2 Text-Based Molecule Generation  
#### Baselines  
#### Results  
# 5 Conclusions and Future Work   
# 6 Limitations  



