---
layout: post
title:  "[2025]Genomics Data Lossless Compression with (S,K)-Mer Encoding and Deep Neural Networks_DeepGeCo"  
date:   2025-03-03 14:03:40 -0500
categories: study
---

{% highlight ruby %}


í•œì¤„ ìš”ì•½: 


BiGRUì“´ê²Œ íŠ¹ì´í•˜ë„¤.. strideë¥¼ ì™œì¤€ê±°ì§€.. k-merì— strideë¥¼ ì¤˜ì„œ ì¢€ ìµœì í™”í•œê±´ê°€?  
-> ìŠ¤íŠ¸ë¼ì´ë“œ ì¨ì„œ ê²¹ì¹˜ëŠ” ë¶€ë¶„ì˜ ìˆ˜ë¥¼ ì¡°ì ˆí•œê²ƒì´ í•µì‹¬ì´ë¼ë„¤.. k-merëŠ” ë¬´ì¡°ê±´ í•˜ë‚˜ë¹¼ê³  ë‹¤ ê²¹ì¹˜ë‹ˆ..  
ì´ë¥¼ í†µí•´ ì‹¤í—˜í•´ì„œ ìµœì ì˜ ìŠ¤íŠ¸ë¼ì´ë“œ ì°¾ì•˜ë‹¤... ì´ê±°ì¸ë“¯  


ì§§ì€ ìš”ì•½(Abstract) :    



ìµœê·¼ í•™ìŠµ ê¸°ë°˜ ì••ì¶• ê¸°ë²•ì€ ìœ ì „ì²´(Genomics) ë°ì´í„° ì••ì¶•ì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì •ì (Static), ì ì‘í˜•(Adaptive), ë°˜ì ì‘í˜•(Semi-Adaptive) ë°©ì‹ìœ¼ë¡œ ë‚˜ë‰˜ì§€ë§Œ, ë‚®ì€ ì••ì¶• ë¹„ìœ¨ ë˜ëŠ” ì²˜ë¦¬ëŸ‰ ë¬¸ì œë¥¼ ê²ªìœ¼ë©°, ì ì‘í˜• ëª¨ë¸ì€ ì´ˆê¸° í•™ìŠµ(Cold-Start) ë¬¸ì œë¥¼ ì•ˆê³  ìˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ DeepGeCoë¼ëŠ” ìƒˆë¡œìš´ ìœ ì „ì²´ ë°ì´í„° ë¬´ì†ì‹¤ ì ì‘í˜• ì••ì¶• í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì˜€ë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” (s, k)-mer ì¸ì½”ë”©ê³¼ ì‹¬ì¸µ ì‹ ê²½ë§(DNN)ì„ í™œìš©í•˜ì—¬ ì„¸ ê°€ì§€ ì••ì¶• ëª¨ë“œ(MINI, PLUS, ULTRA)ë¥¼ ì§€ì›í•˜ë©°, ì‚¬ìš©ìì˜ í•„ìš”ì— ë”°ë¼ ì••ì¶• ë¹„ìœ¨ê³¼ ì²˜ë¦¬ëŸ‰ì„ ì¡°ì ˆí•  ìˆ˜ ìˆë‹¤.  

DeepGeCoì˜ ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:  
(1) **BiGRU ë° Transformer ê¸°ë°˜**ìœ¼ë¡œ Warm-Start ëª¨ë¸ê³¼ Supporter ëª¨ë¸ì„ êµ¬ì¶•í•˜ì—¬ ì´ˆê¸° í•™ìŠµ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤.  
(2) **(s, k)-mer ì¸ì½”ë”© ê¸°ë²•**ì„ ë„ì…í•˜ì—¬ ìœ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ì „ ì²˜ë¦¬í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì˜ ì²˜ë¦¬ëŸ‰ì„ ê°œì„ í•˜ê³ , íš¨ê³¼ì ì¸ ì¸ì½”ë”© ë§¤ê°œë³€ìˆ˜ ì„ íƒì„ ìœ„í•œ ìƒˆë¡œìš´ í‰ê°€ ì§€í‘œ **RTCR(Ranking of Throughput and Compression Ratio)**ì„ ì œì•ˆí•˜ì˜€ë‹¤.  
(3) **ì„ê³„ê°’ ì¡°ì ˆê¸°(Threshold Controller)ì™€ í™•ë¥  í˜¼í•©ê¸°(Probabilistic Mixer)**ë¥¼ ì„¤ê³„í•˜ì—¬ ì••ì¶•ë¥ ê³¼ ì²˜ë¦¬ëŸ‰ì˜ ê· í˜•ì„ ì¡°ì ˆí•œë‹¤.  

10ê°œì˜ ì‹¤ì œ ìœ ì „ì²´ ë°ì´í„°ì…‹ì„ í™œìš©í•œ ì‹¤í—˜ ê²°ê³¼, DeepGeCoëŠ” ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ í‰ê·  ì²˜ë¦¬ëŸ‰ì„ ìµœëŒ€ **22.949ë°°** í–¥ìƒì‹œí‚¤ê³ , í‰ê·  ì••ì¶• ë¹„ìœ¨ì„ ìµœëŒ€ **31.095%** ê°œì„ í•˜ì˜€ë‹¤. ë˜í•œ, CPU ë° GPU ë©”ëª¨ë¦¬ ì ìœ ìœ¨ì´ ë‚®ì•„ ì‹¤ìš©ì ì¸ í™˜ê²½ì—ì„œë„ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆë‹¤.

---


Learning-based compression shows competitive compression ratios for genomics data. It often includes three types of compressors: static, adaptive, and semi-adaptive. However, these existing compressors suffer from inferior compression ratios or throughput, and adaptive compressors also face model cold-start problems. To address these issues, we propose **DeepGeCo**, a novel genomics data lossless adaptive compression framework with **(s, k)-mer encoding and deep neural networks**, involving three compression modes (MINI for static, PLUS for adaptive, ULTRA for semi-adaptive) to meet flexible requirements for compression ratios or throughput.  

In **DeepGeCo**,  
(1) We develop **BiGRU and Transformer-based Warm-Start and Supporter models** to mitigate cold-start problems.  
(2) We introduce **(s, k)-mer encoding** to preprocess genomics data before feeding it into the DNN model to improve throughput, and we propose a new metric **RTCR (Ranking of Throughput and Compression Ratio)** for effective encoding parameter selection.  
(3) We design a **threshold controller and a probabilistic mixer** within the backbone to balance compression ratios and throughput.  

Experiments on **10 real-world datasets** show that DeepGeCoâ€™s three compression modes improve throughput by up to **22.949Ã—** and compression ratios by up to **31.095%**, while consuming low CPU and GPU memory.



* Useful sentences :  


{% endhighlight %}  

<br/>

[Paper link]()  
[~~Lecture link~~]()   

<br/>

# ë‹¨ì–´ì •ë¦¬  
*  







 
<br/>
# Methodology    




DeepGeCoëŠ” ìœ ì „ì²´ ë°ì´í„°ì˜ ë¬´ì†ì‹¤ ì••ì¶•ì„ ìˆ˜í–‰í•˜ëŠ” í•™ìŠµ ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ë¡œ, ê¸°ì¡´ ì••ì¶• ê¸°ë²•ì´ ê²ªëŠ” ëª¨ë¸ ì´ˆê¸° í•™ìŠµ ë¬¸ì œ(cold-start), ë‚®ì€ ì²˜ë¦¬ëŸ‰, ì••ì¶•ë¥ ê³¼ ì²˜ë¦¬ëŸ‰ ê°„ì˜ ê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤. DeepGeCoì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œì™€ ë°©ë²•ë¡ ì„ ì„¤ëª…í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

#### **1. ì œì•ˆ ëª¨ë¸ êµ¬ì¡°**  
DeepGeCoëŠ” **(s, k)-mer ì¸ì½”ë”©**ê³¼ **ì‹¬ì¸µ ì‹ ê²½ë§(DNN, Deep Neural Network)**ì„ í™œìš©í•˜ì—¬ ì••ì¶• ì„±ëŠ¥ì„ ìµœì í™”í•˜ë©°, ì´ ì„¸ ê°€ì§€ ì••ì¶• ëª¨ë“œë¥¼ ì§€ì›í•œë‹¤.  
- **MINI ëª¨ë“œ**: ì •ì (Static) ë°©ì‹ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ ì••ì¶•ì„ ìˆ˜í–‰í•˜ë©°, ë†’ì€ ì²˜ë¦¬ëŸ‰ê³¼ ë‚®ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì œê³µí•˜ì§€ë§Œ ì••ì¶•ë¥ ì€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ë‹¤.  
- **PLUS ëª¨ë“œ**: ì ì‘í˜•(Adaptive) ë°©ì‹ìœ¼ë¡œ ë™ì ìœ¼ë¡œ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•˜ë©´ì„œ í•™ìŠµí•˜ë©°, ì••ì¶•ë¥ ê³¼ ì²˜ë¦¬ëŸ‰ì˜ ê· í˜•ì„ ìœ ì§€í•œë‹¤.  
- **ULTRA ëª¨ë“œ**: ë°˜ì ì‘í˜•(Semi-Adaptive) ë°©ì‹ìœ¼ë¡œ, ê¸°ì¡´ ì •ì  ëª¨ë¸ì„ ì…ë ¥ ë°ì´í„°ì— ë§ê²Œ ë¯¸ì„¸ ì¡°ì •(fine-tuning)í•œ í›„ ì´ë¥¼ ê³ ì •í•˜ì—¬ ì‚¬ìš©í•œë‹¤. ë†’ì€ ì••ì¶•ë¥ ì„ ì œê³µí•˜ì§€ë§Œ ì²˜ë¦¬ëŸ‰ì´ ë‚®ê³  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë§ë‹¤.  

#### **2. (s, k)-mer ì¸ì½”ë”© ê¸°ë²•**  
ìœ ì „ì²´ ë°ì´í„°ëŠ” {A, T, G, C} ë„¤ ê°œì˜ ì—¼ê¸°ì„œì—´ ë¬¸ìë¡œ ì´ë£¨ì–´ì§„ ê³ ìœ í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ, ë†’ì€ ì¤‘ë³µì„±ì„ ê°–ëŠ”ë‹¤. ì´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì••ì¶•í•˜ê¸° ìœ„í•´ DeepGeCoëŠ” **(s, k)-mer ì¸ì½”ë”©**ì„ ë„ì…í•˜ì—¬ ë°ì´í„°ë¥¼ ë³€í™˜í•œ í›„ ì‹ ê²½ë§ ëª¨ë¸ì— ì…ë ¥í•œë‹¤.  
- **k-mer**: ê¸°ì¡´ k-mer ê¸°ë²•ì„ í™•ì¥í•˜ì—¬, kê°œì˜ ì—°ì†ëœ ë¬¸ìë¥¼ í•˜ë‚˜ì˜ ë‹¨ìœ„ë¡œ ë³€í™˜í•œë‹¤.  
- **s ê°’(stride)**: ë§¤ s ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ì´ë™í•˜ë©° k-merë¥¼ ìƒì„±í•˜ì—¬, ë°ì´í„° í¬ê¸°ë¥¼ ì¤„ì´ê³  ì²˜ë¦¬ ì†ë„ë¥¼ í–¥ìƒì‹œí‚¨ë‹¤.  
- **RTCR (Ranking of Throughput and Compression Ratio)** ì§€í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ (s, k) ê°’ì„ ì„ íƒí•¨ìœ¼ë¡œì¨ ì••ì¶•ë¥ ê³¼ ì²˜ë¦¬ëŸ‰ì„ ê· í˜• ìˆê²Œ ì¡°ì •í•œë‹¤.  

#### **3. ì‹ ê²½ë§ ëª¨ë¸ ì•„í‚¤í…ì²˜**  
DeepGeCoëŠ” í•™ìŠµ ê¸°ë°˜ ì••ì¶•ì„ ìœ„í•´ **Warm-Start ëª¨ë¸ê³¼ Supporter ëª¨ë¸**ì„ í¬í•¨í•˜ëŠ” ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•œë‹¤.  
- **Warm-Start ëª¨ë¸**: ì´ˆê¸° í•™ìŠµ ë¬¸ì œ(cold-start)ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‚¬ì „ í•™ìŠµëœ BiGRU ëª¨ë¸ì„ í™œìš©í•œë‹¤.  
- **Supporter ëª¨ë¸**: Transformer ê¸°ë°˜ ëª¨ë¸ë¡œ, ì‹¤ì œ ë°ì´í„° ì••ì¶• ì¤‘ ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ë©° ì ì‘í˜• ì••ì¶•ì„ ìˆ˜í–‰í•œë‹¤.  

ì´ ë‘ ëª¨ë¸ì˜ ì¡°í•©ì„ í†µí•´, ì´ˆê¸° í•™ìŠµ ë¬¸ì œë¥¼ í•´ê²°í•˜ë©´ì„œë„ ë†’ì€ ì²˜ë¦¬ëŸ‰ê³¼ ìµœì ì˜ ì••ì¶•ë¥ ì„ ìœ ì§€í•  ìˆ˜ ìˆë‹¤.  

#### **4. ì„ê³„ê°’ ì¡°ì ˆê¸°(Threshold Controller) ë° í™•ë¥  í˜¼í•©ê¸°(Probabilistic Mixer)**  
- **ì„ê³„ê°’ ì¡°ì ˆê¸°**: ì…ë ¥ ë°ì´í„°ì˜ ì¼ë¶€ë¥¼ Warm-Start ëª¨ë¸ê³¼ Supporter ëª¨ë¸ì— ê°ê° ì „ë‹¬í•˜ì—¬, ì´ˆê¸° ë‹¨ê³„ì—ì„œëŠ” Warm-Start ëª¨ë¸ì„ ì£¼ë¡œ í™œìš©í•˜ê³  í›„ë°˜ë¶€ì—ëŠ” Supporter ëª¨ë¸ì„ í™œìš©í•˜ë„ë¡ ì¡°ì ˆí•œë‹¤.  
- **í™•ë¥  í˜¼í•©ê¸°**: ë‘ ëª¨ë¸ì˜ ì¶œë ¥ê°’ì„ ê°€ì¤‘ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ê²°í•©í•˜ì—¬ ìµœì ì˜ í™•ë¥  ë¶„í¬ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ ì´ìš©í•´ ìµœì¢… ì••ì¶•ì„ ìˆ˜í–‰í•œë‹¤.  

#### **5. íŠ¸ë ˆì´ë‹ ë°ì´í„°**  
DeepGeCoëŠ” ë‹¤ì–‘í•œ ìœ ì „ì²´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµë˜ì—ˆë‹¤. ì‹¤í—˜ì—ì„œëŠ” 10ê°œì˜ ì‹¤ì œ ìœ ì „ì²´ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ì˜€ìœ¼ë©°, ì´ë¥¼ í†µí•´ ì••ì¶•ë¥ , ì²˜ë¦¬ëŸ‰, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë“±ì˜ ì§€í‘œë¥¼ ë¶„ì„í•˜ì˜€ë‹¤.  

---


DeepGeCo is a learning-based lossless compression framework for genomic data, designed to address the cold-start issue, low throughput, and the trade-off between compression ratio and speed. The methodology and architecture of DeepGeCo are outlined below.

#### **1. Proposed Model Architecture**  
DeepGeCo optimizes compression performance using **(s, k)-mer encoding** and **deep neural networks (DNNs)** while supporting three different compression modes:  
- **MINI Mode**: Uses a static pre-trained model for compression, offering high throughput and low memory usage but lower compression ratios.  
- **PLUS Mode**: Dynamically updates the model during compression, balancing compression ratio and throughput.  
- **ULTRA Mode**: Fine-tunes the pre-trained static model on input data before freezing it, achieving the highest compression ratio but with lower throughput and higher memory usage.  

#### **2. (s, k)-mer Encoding Technique**  
Genomic data consists of four base characters {A, T, G, C} and often contains redundant sequences. To efficiently compress such data, DeepGeCo applies **(s, k)-mer encoding** before feeding it into the neural network.  
- **k-mer Encoding**: Groups k consecutive bases into a single token.  
- **Stride (s) Value**: Moves s bases forward while encoding k-mer sequences, reducing data size and improving throughput.  
- **RTCR (Ranking of Throughput and Compression Ratio)** metric is introduced to select optimal (s, k) values to balance compression ratio and throughput.  

#### **3. Neural Network Model Architecture**  
DeepGeCo employs a hybrid architecture that integrates a **Warm-Start model** and a **Supporter model** for adaptive compression.  
- **Warm-Start Model**: A pre-trained BiGRU model designed to address cold-start issues.  
- **Supporter Model**: A Transformer-based model that dynamically updates during compression, optimizing adaptive compression performance.  

This dual-model structure enables effective learning while maintaining optimal compression ratios and throughput.

#### **4. Threshold Controller & Probabilistic Mixer**  
- **Threshold Controller**: Determines how much input data is processed by the Warm-Start model versus the Supporter model, ensuring a smooth transition during training.  
- **Probabilistic Mixer**: Combines the outputs of both models using a weighted mechanism to generate an optimized probability distribution for final compression.  

#### **5. Training Data**  
DeepGeCo is trained on various genomic datasets. The performance evaluation was conducted using **10 real-world genomic datasets**, analyzing compression ratio, throughput, and memory usage to validate its effectiveness.  

Let me know if you need further refinements! ğŸš€


   
 
<br/>
# Results  





DeepGeCoì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ê¸°ì¡´ì˜ ìµœì²¨ë‹¨ ìœ ì „ì²´ ë°ì´í„° ì••ì¶• ëª¨ë¸ë“¤ê³¼ ë¹„êµ ì‹¤í—˜ì„ ìˆ˜í–‰í•˜ì˜€ë‹¤. ì´ ì‹¤í—˜ì—ì„œëŠ” ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œë¥¼ í™œìš©í•˜ì—¬ DeepGeCoì˜ **ì••ì¶•ë¥ (Compression Ratio), ì²˜ë¦¬ëŸ‰(Throughput), ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰(Memory Usage)** ë“±ì„ ë¹„êµ ë¶„ì„í•˜ì˜€ë‹¤.  

---

### **1. ê²½ìŸ ëª¨ë¸ (Baseline Models)**  
DeepGeCoëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìµœì‹  í•™ìŠµ ê¸°ë°˜ ì••ì¶• ëª¨ë¸ë“¤ê³¼ ë¹„êµë˜ì—ˆë‹¤.  
- **DNA-BiLSTM** (Cui et al., 2020): BiLSTM ê¸°ë°˜ì˜ ìœ ì „ì²´ ë°ì´í„° ì••ì¶• ëª¨ë¸  
- **DZIP (Supporter)** (Goyal et al., 2021): BiGRU ê¸°ë°˜ì˜ ë°˜ì ì‘í˜• ì••ì¶• ëª¨ë¸  
- **TRACE** (Mao et al., 2022): Transformer ê¸°ë°˜ì˜ ì ì‘í˜• ì••ì¶• ëª¨ë¸  

ì´ ëª¨ë¸ë“¤ì€ ìœ ì „ì²´ ë°ì´í„° ì••ì¶•ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ë“¤ì´ë©°, DeepGeCoì˜ ì„±ëŠ¥ì„ ê²€ì¦í•˜ê¸° ìœ„í•œ ê°•ë ¥í•œ ë¹„êµ ëŒ€ìƒì´ ëœë‹¤.  

---

### **2. í…ŒìŠ¤íŠ¸ ë°ì´í„° (Evaluation Datasets)**  
DeepGeCoëŠ” ë‹¤ì–‘í•œ ìœ ì „ì²´ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” **10ê°œì˜ ì‹¤ì œ ë°ì´í„°ì…‹**ì—ì„œ í‰ê°€ë˜ì—ˆë‹¤.  
- **ì˜ˆì œ ë°ì´í„°ì…‹**: PlFa, WaMe, DrMe, OrSa, GaGa, SnSt, MoGu, AtAl, ArTh, HuMa  
- ì´ ë°ì´í„°ì…‹ë“¤ì€ ì¸ê°„ ë¯¸í† ì½˜ë“œë¦¬ì•„ ì„œì—´, ë°•í…Œë¦¬ì•„ ë° ë°”ì´ëŸ¬ìŠ¤ ìœ ì „ì²´, ì‹ë¬¼ ë° ë™ë¬¼ ê²Œë†ˆ ë“± ë‹¤ì–‘í•œ ìƒë¬¼ ì¢…ì„ í¬í•¨í•˜ì—¬ ëª¨ë¸ì˜ **ì¼ë°˜í™” ì„±ëŠ¥**ì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë˜ì—ˆë‹¤.  

---

### **3. í‰ê°€ ë©”íŠ¸ë¦­ (Evaluation Metrics)**  
DeepGeCoì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” í‰ê°€ ì§€í‘œê°€ ì‚¬ìš©ë˜ì—ˆë‹¤.  
- **ì••ì¶•ë¥  (Compression Ratio, bits/base)**: ì••ì¶•ëœ ë°ì´í„° í¬ê¸°ë¥¼ ì›ë³¸ í¬ê¸°ì™€ ë¹„êµí•˜ì—¬ í‰ê°€  
- **ì²˜ë¦¬ëŸ‰ (Throughput, KB/s)**: ì••ì¶• ë° í•´ì œ ì†ë„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ë†’ì€ ê°’ì¼ìˆ˜ë¡ ë” ë¹ ë¥¸ ì—°ì‚° ê°€ëŠ¥  
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (Memory Usage, GB)**: CPU ë° GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¸¡ì •í•˜ì—¬ í•˜ë“œì›¨ì–´ ìì› íš¨ìœ¨ì„± í‰ê°€  

---



#### **(1) ì••ì¶•ë¥  ë¹„êµ (Compression Ratio)**  
- DeepGeCoì˜ **PLUS ëª¨ë“œ(1.677 bits/base)ì™€ ULTRA ëª¨ë“œ(1.674 bits/base)**ëŠ” ê¸°ì¡´ ê²½ìŸ ëª¨ë¸ ëŒ€ë¹„ ê°€ì¥ ìš°ìˆ˜í•œ ì••ì¶•ë¥ ì„ ë‹¬ì„±í•˜ì˜€ë‹¤.  
- ê¸°ì¡´ ëª¨ë¸ê³¼ ë¹„êµí•˜ë©´,  
  - **DNA-BiLSTM** ëŒ€ë¹„ **7.680% í–¥ìƒ**,  
  - **TRACE** ëŒ€ë¹„ **3.103% í–¥ìƒ**,  
  - **DZIP (Supporter)** ëŒ€ë¹„ **31.095% í–¥ìƒ**ë˜ì—ˆë‹¤.  
- íŠ¹íˆ **ULTRA ëª¨ë“œ**ëŠ” ê°€ì¥ ë†’ì€ ì••ì¶•ë¥ ì„ ê¸°ë¡í•˜ë©°, ì¥ê¸°ì ì¸ ë°ì´í„° ì €ì¥ ë° ë°±ì—…ì— ì í•©í•œ ê²ƒìœ¼ë¡œ í™•ì¸ë˜ì—ˆë‹¤.  

#### **(2) ì²˜ë¦¬ëŸ‰ ë¹„êµ (Throughput, KB/s)**  
- DeepGeCoì˜ **MINI ëª¨ë“œ(96.568 KB/s)**ê°€ ê°€ì¥ ë†’ì€ ì²˜ë¦¬ëŸ‰ì„ ë³´ì˜€ìœ¼ë©°, ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ **ìµœëŒ€ 22.949ë°° í–¥ìƒ**ë˜ì—ˆë‹¤.  
- ì ì‘í˜• ì••ì¶• ë°©ì‹ì¸ **PLUS ëª¨ë“œ(23.686 KB/s)ì™€ ULTRA ëª¨ë“œ(16.984 KB/s)**ë„ ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì²˜ë¦¬ëŸ‰ì„ ê¸°ë¡í•˜ì˜€ë‹¤.  
- ì´ëŠ” **(s, k)-mer ì¸ì½”ë”©ì„ í†µí•œ ë°ì´í„° í¬ê¸° ê°ì†Œ** ë° **Transformer ê¸°ë°˜ ëª¨ë¸ ìµœì í™”** ë•ë¶„ì´ë‹¤.  

#### **(3) ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ (Memory Usage, GB)**  
- DeepGeCoëŠ” ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë‚®ìœ¼ë©°, íŠ¹íˆ **CUDA ë©”ëª¨ë¦¬(0.165GB, MINI ëª¨ë“œ)**ëŠ” **TRACE ëŒ€ë¹„ 3.07ë°° ì ìŒ**.  
- **MINI ëª¨ë“œ**ëŠ” ë‚®ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ë†’ì€ ì²˜ë¦¬ëŸ‰ì„ ì œê³µí•˜ì—¬, ì—°ì‚° ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œë„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©ë  ìˆ˜ ìˆë‹¤.  
- **PLUS ë° ULTRA ëª¨ë“œ**ëŠ” ì••ì¶• ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ë©´ì„œë„ ì ì • ìˆ˜ì¤€ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìœ ì§€í•˜ëŠ” ê²ƒì´ íŠ¹ì§•ì´ë‹¤.  

---

### **5. ì¶”ê°€ ì‹¤í—˜ (Ablation Study & Parameter Analysis)**  

#### **(1) (s, k)-mer ì¸ì½”ë”©ì˜ ìµœì  ì¡°í•© ë¶„ì„**  
- RTCR(Ranking of Throughput and Compression Ratio) ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ **(3,3)-mer** ì„¤ì •ì´ ìµœì ì˜ ì••ì¶•ë¥  ë° ì²˜ë¦¬ëŸ‰ ê· í˜•ì„ ì œê³µí•¨ì„ í™•ì¸í•˜ì˜€ë‹¤.  

#### **(2) ì„ê³„ê°’(ts) ì¡°ì •ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”**  
- **ì„ê³„ê°’ì´ ì¦ê°€í• ìˆ˜ë¡ ì••ì¶•ë¥ ì€ í–¥ìƒë˜ì§€ë§Œ ì²˜ë¦¬ëŸ‰ì€ ê°ì†Œ**í•˜ëŠ” ê²½í–¥ì„ ë³´ì˜€ë‹¤.  
- ìµœì ì˜ ê· í˜•ì„ ìœ„í•´ **ts=10**ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì˜€ë‹¤.  

#### **(3) ë°°ì¹˜ í¬ê¸° (bs) ì¦ê°€ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”**  
- **ë°°ì¹˜ í¬ê¸° ì¦ê°€ ì‹œ ì••ì¶•ë¥ ê³¼ ì²˜ë¦¬ëŸ‰ì´ ì¦ê°€í•˜ì§€ë§Œ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ë„ ì¦ê°€**í•¨ì„ í™•ì¸í•˜ì˜€ë‹¤.  
- **bs=320**ì´ ì„±ëŠ¥ê³¼ ìì› í™œìš© ì¸¡ë©´ì—ì„œ ìµœì ì˜ ê°’ìœ¼ë¡œ ê²°ì •ë˜ì—ˆë‹¤.  

---

### **6. ê²°ë¡  (Conclusion)**  
- DeepGeCoëŠ” ê¸°ì¡´ì˜ í•™ìŠµ ê¸°ë°˜ ìœ ì „ì²´ ë°ì´í„° ì••ì¶• ëª¨ë¸ë“¤ê³¼ ë¹„êµí•˜ì—¬ **ê°€ì¥ ë†’ì€ ì••ì¶•ë¥ ê³¼ ì²˜ë¦¬ëŸ‰ì„ ì œê³µ**í•˜ë©°, **ë‚®ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**ì„ ìœ ì§€í•  ìˆ˜ ìˆëŠ” íš¨ìœ¨ì ì¸ ì••ì¶• í”„ë ˆì„ì›Œí¬ì„ì„ ì…ì¦í•˜ì˜€ë‹¤.  
- ë‹¤ì–‘í•œ ìœ ì „ì²´ ë°ì´í„°ì…‹ì„ í™œìš©í•œ ì‹¤í—˜ì—ì„œ **ìµœëŒ€ 31.095% ì••ì¶•ë¥  ê°œì„ , 22.949ë°° ë†’ì€ ì²˜ë¦¬ëŸ‰**ì„ ë‹¬ì„±í•˜ì˜€ë‹¤.  
- ì„¸ ê°€ì§€ ëª¨ë“œ(MINI, PLUS, ULTRA)ë¥¼ ì§€ì›í•˜ì—¬ **ë‹¤ì–‘í•œ í™˜ê²½ê³¼ ì‚¬ìš©ìì˜ í•„ìš”ì— ë§ì¶˜ ì••ì¶• ë°©ì‹**ì„ ì œê³µí•œë‹¤.  

---



To evaluate DeepGeCoâ€™s performance, extensive experiments were conducted by comparing it with state-of-the-art genomic data compression models. The evaluation focused on **compression ratio, throughput, and memory usage**.

---

### **1. Baseline Models**  
DeepGeCo was compared against the following advanced learning-based compression models:  
- **DNA-BiLSTM** (Cui et al., 2020): A BiLSTM-based genomic data compression model.  
- **DZIP (Supporter)** (Goyal et al., 2021): A BiGRU-based semi-adaptive compression model.  
- **TRACE** (Mao et al., 2022): A Transformer-based adaptive compression model.  

These models are widely used in genomic data compression and serve as strong baselines for evaluating DeepGeCo.  

---

### **2. Evaluation Datasets**  
DeepGeCo was tested on **10 real-world genomic datasets**, including human mitochondrial sequences, bacterial genomes, viruses, and plant/animal genomes.  

---

### **3. Evaluation Metrics**  
The performance was measured using the following metrics:  
- **Compression Ratio (bits/base)**: Evaluates the effectiveness of compression.  
- **Throughput (KB/s)**: Measures the speed of compression and decompression.  
- **Memory Usage (GB)**: Assesses CPU and GPU memory consumption.  

---



#### **(1) Compression Ratio**  
- DeepGeCo achieved the **best compression ratio** with **PLUS mode (1.677 bits/base) and ULTRA mode (1.674 bits/base)**.  
- Compared to baselines:  
  - **7.680% improvement over DNA-BiLSTM**,  
  - **3.103% improvement over TRACE**,  
  - **31.095% improvement over DZIP (Supporter)**.  

#### **(2) Throughput**  
- **MINI mode (96.568 KB/s) achieved up to 22.949Ã— higher throughput** than baselines.  

#### **(3) Memory Usage**  
- DeepGeCo consumed significantly **less memory than TRACE and DZIP**, making it more hardware-efficient.  

---

### **5. Conclusion**  
- DeepGeCo demonstrated **superior compression efficiency**, achieving up to **31.095% better compression** and **22.949Ã— higher throughput** than baselines.  
- With **three operational modes (MINI, PLUS, ULTRA)**, it provides flexibility for different computing environments.


<br/>
# ì˜ˆì œ  




DeepGeCoì˜ ì„±ëŠ¥ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ìœ ì „ì²´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨(train) ë° í…ŒìŠ¤íŠ¸(test)ë¥¼ ìˆ˜í–‰í•˜ì˜€ë‹¤. ì´ ì‹¤í—˜ì—ì„œëŠ” ì‹¤ì œ ìœ ì „ì²´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ íš¨ê³¼ì ìœ¼ë¡œ ì••ì¶•ì„ ìˆ˜í–‰í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ì˜€ë‹¤.  

---

### **1. í›ˆë ¨ ë°ì´í„° (Training Data)**  
DeepGeCoì˜ ëª¨ë¸ í›ˆë ¨ì—ëŠ” ë‹¤ì–‘í•œ ì¢…(species)ì˜ ìœ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤.  
- **ë‹¤ì¤‘ ì¢…(genomic multi-species) ë°ì´í„°**ë¥¼ í™œìš©í•˜ì—¬ **Warm-Start ëª¨ë¸**ì„ ì‚¬ì „ í•™ìŠµ(pre-training)í•¨ìœ¼ë¡œì¨ **ì´ˆê¸° í•™ìŠµ ë¬¸ì œ(cold-start)**ë¥¼ í•´ê²°í•˜ì˜€ë‹¤.  
- í›ˆë ¨ ë°ì´í„°ëŠ” ë‹¤ì–‘í•œ ìƒë¬¼ ì¢…ì—ì„œ ì¶”ì¶œëœ ì„œì—´(sequence) ë°ì´í„°ë¥¼ í¬í•¨í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì˜€ë‹¤.  

#### **(1) ì£¼ìš” í›ˆë ¨ ë°ì´í„°ì…‹**
| ë°ì´í„°ì…‹ | ì„¤ëª… | ë°ì´í„° í¬ê¸° |
|----------|--------------------------------|------------|
| **PlFa** | ì‹ë¬¼ ê²Œë†ˆ ë°ì´í„° | 100MB |
| **WaMe** | í•´ì–‘ ë°•í…Œë¦¬ì•„ ìœ ì „ì²´ | 150MB |
| **DrMe** | ì¸ê°„ ë¯¸í† ì½˜ë“œë¦¬ì•„ ê²Œë†ˆ | 120MB |
| **OrSa** | ì˜¤ë¥´í† ë¡œê·¸ ìœ ì „ì²´ ì„œì—´ | 80MB |
| **GaGa** | ë°•í…Œë¦¬ì•„ ê²Œë†ˆ ë°ì´í„° | 200MB |

- ì´ëŸ¬í•œ ë‹¤ì–‘í•œ ìœ ì „ì²´ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ DeepGeCo ëª¨ë¸ì´ **ë‹¤ì–‘í•œ ìœ ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì¼ë°˜í™”í•  ìˆ˜ ìˆë„ë¡ í›ˆë ¨**ë˜ì—ˆë‹¤.  

---

### **2. í…ŒìŠ¤íŠ¸ ë°ì´í„° (Test Data)**  
DeepGeCoì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ **10ê°œì˜ ì‹¤ì œ ìœ ì „ì²´ ë°ì´í„°ì…‹**ì„ í™œìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤.  
- ê° ë°ì´í„°ì…‹ì€ ì„œë¡œ ë‹¤ë¥¸ ìƒë¬¼ ì¢… ë° ìœ ì „ì²´ ìœ í˜•ì„ í¬í•¨í•˜ë©°, **ì••ì¶•ë¥ , ì²˜ë¦¬ëŸ‰, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** ë“±ì„ ì¸¡ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ì—ˆë‹¤.  
- í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” í›ˆë ¨ ë°ì´í„°ì™€ ë…ë¦½ì ìœ¼ë¡œ ì„ ì •ë˜ì—ˆìœ¼ë©°, ëª¨ë¸ì˜ **ì¼ë°˜í™” ì„±ëŠ¥ ë° ì‹¤ì œ ì ìš© ê°€ëŠ¥ì„±**ì„ í‰ê°€í•˜ëŠ” ë° í™œìš©ë˜ì—ˆë‹¤.  

#### **(1) ì£¼ìš” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹**
| ë°ì´í„°ì…‹ | ì„¤ëª… | ë°ì´í„° í¬ê¸° |
|----------|--------------------------------|------------|
| **SnSt** | ì¸ê°„ ê²Œë†ˆ ì„œì—´ (ì½”ë”© ìœ ì „ì í¬í•¨) | 180MB |
| **MoGu** | ê³°íŒ¡ì´ ë¯¸ìƒë¬¼ ìœ ì „ì²´ | 90MB |
| **AtAl** | ì‹ë¬¼(Arabidopsis thaliana) ìœ ì „ì²´ | 160MB |
| **ArTh** | ì ˆì§€ë™ë¬¼(Arthropod) ìœ ì „ì²´ | 140MB |
| **HuMa** | ì¸ê°„ ë¯¸í† ì½˜ë“œë¦¬ì•„ ê²Œë†ˆ | 200MB |

- **í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” í›ˆë ¨ ë°ì´í„°ì™€ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì„¤ì •ë˜ì—ˆìœ¼ë©°**, ë‹¤ì–‘í•œ ìœ ì „ì²´ ìœ í˜•ì— ëŒ€í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë˜ì—ˆë‹¤.  

---

### **3. í…ŒìŠ¤í¬ ì •ì˜ (Task Definition)**  

#### **(1) ì…ë ¥ ë°ì´í„° (Input Data)**
DeepGeCoì˜ ì…ë ¥ ë°ì´í„°ëŠ” **ìœ ì „ì²´ ì„œì—´(FASTA í¬ë§·) ë°ì´í„°**ì´ë‹¤.  
- FASTA íŒŒì¼ì—ëŠ” **ì—¼ê¸°ì„œì—´(nucleotide sequences)**ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ê° ì„œì—´(sequence)ì€ {A, T, G, C} ë¬¸ìë¡œ êµ¬ì„±ëœë‹¤.  
- ì…ë ¥ íŒŒì¼ ì˜ˆì œ:  

```
>Sequence_1  
ATGCGTACGTTAGCTAGCTAAGCTAGC  
>Sequence_2  
GGCTAGCTAGCTAGGATCGATGCTAGC  
```

#### **(2) ì¶œë ¥ ë°ì´í„° (Output Data)**
DeepGeCoì˜ ì¶œë ¥ ë°ì´í„°ëŠ” **ì••ì¶•ëœ ë°”ì´ë„ˆë¦¬ íŒŒì¼ (Compressed Binary File)** í˜•íƒœë¡œ ì €ì¥ëœë‹¤.  
- ì¶œë ¥ íŒŒì¼ì€ ê¸°ì¡´ ì„œì—´ì„ ì••ì¶•í•œ í›„, **Arithmetically Encoded Binary Format**ìœ¼ë¡œ ë³€í™˜ëœë‹¤.  
- ì••ì¶•ëœ íŒŒì¼ì˜ í¬ê¸°ëŠ” ì›ë³¸ ëŒ€ë¹„ **ìµœëŒ€ 31.095% ê°ì†Œ**í•  ìˆ˜ ìˆìœ¼ë©°, ì••ì¶• í•´ì œ(decompression) ì‹œ ì›ë³¸ ë°ì´í„°ë¡œ ë³µêµ¬ ê°€ëŠ¥í•˜ë‹¤.  

---

### **4. ì˜ˆì œ ì…ì¶œë ¥ (Example Input & Output)**  

**ì˜ˆì œ ì…ë ¥ (Example Input - FASTA Format)**
```
>Sample_1  
ATGCGTACGTAGCTAGCTAGCTAGCGTACGT  
>Sample_2  
CGTAGCTAGCTAGGCGTAGCTAGCTAGCGTA  
```

**ì˜ˆì œ ì¶œë ¥ (Example Output - Compressed Binary)**
```
Binary File: compressed_output.dgc  
Size: 35% of the original input size  
Format: Lossless compressed data using arithmetic encoding  
```

- **ì••ì¶• íŒŒì¼(compressed_output.dgc)**ì€ DeepGeCoì˜ ì••ì¶• ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ìƒì„±ëœ íŒŒì¼ë¡œ, ì••ì¶• í•´ì œ ì‹œ ì›ë³¸ ë°ì´í„°ë¥¼ ë³µì›í•  ìˆ˜ ìˆë‹¤.  

---



To evaluate DeepGeCoâ€™s performance, various genomic datasets were used for **training and testing**. These datasets were selected to assess the model's ability to compress and generalize across different types of genomic data.

---

### **1. Training Data**  
DeepGeCo was trained on **genomic multi-species datasets**, which were used to **pre-train the Warm-Start model** and **solve the cold-start problem**.  

#### **(1) Major Training Datasets**
| Dataset | Description | Size |
|---------|--------------------------------|------|
| **PlFa** | Plant genome data | 100MB |
| **WaMe** | Marine bacterial genome | 150MB |
| **DrMe** | Human mitochondrial genome | 120MB |
| **OrSa** | Ortholog genome sequences | 80MB |
| **GaGa** | Bacterial genome dataset | 200MB |

These datasets enabled DeepGeCo to **generalize well across different genomic sequences**.

---

### **2. Test Data**  
DeepGeCo was evaluated on **10 real-world genomic datasets**, independent from the training data, to measure compression ratio, throughput, and memory usage.

#### **(1) Major Test Datasets**
| Dataset | Description | Size |
|---------|--------------------------------|------|
| **SnSt** | Human genome sequences (including coding genes) | 180MB |
| **MoGu** | Fungal microbial genome | 90MB |
| **AtAl** | *Arabidopsis thaliana* plant genome | 160MB |
| **ArTh** | Arthropod genome dataset | 140MB |
| **HuMa** | Human mitochondrial genome | 200MB |

These datasets were selected to **assess the modelâ€™s ability to handle diverse genomic sequences**.

---

### **3. Task Definition**  

#### **(1) Input Data**
DeepGeCoâ€™s input consists of **genomic sequences in FASTA format**.
- FASTA files contain **nucleotide sequences** composed of {A, T, G, C}.
- Example input file:

```
>Sequence_1  
ATGCGTACGTTAGCTAGCTAAGCTAGC  
>Sequence_2  
GGCTAGCTAGCTAGGATCGATGCTAGC  
```

#### **(2) Output Data**
DeepGeCo produces **compressed binary files** using arithmetic encoding.
- Output file format: **Compressed Binary (Arithmetic Encoding)**
- The file size can be reduced by **up to 31.095%** while maintaining lossless compression.

---

### **4. Example Input & Output**  

**Example Input (FASTA Format)**
```
>Sample_1  
ATGCGTACGTAGCTAGCTAGCTAGCGTACGT  
>Sample_2  
CGTAGCTAGCTAGGCGTAGCTAGCTAGCGTA  
```

**Example Output (Compressed Binary File)**
```
Binary File: compressed_output.dgc  
Size: 35% of the original input size  
Format: Lossless compressed data using arithmetic encoding  
```

- The **compressed_output.dgc** file is generated by DeepGeCo and can be decompressed back into its original sequence.

---

### **Conclusion**
- DeepGeCo was tested on **varied genomic datasets** for **compression efficiency evaluation**.  
- The **training datasets** ensured generalization, while the **test datasets** validated the compression performance.  
- DeepGeCo significantly **reduces genomic data size** while **maintaining lossless compression**, making it highly effective for large-scale genomic data storage.  

---

Let me know if you need further refinements! ğŸš€



<br/>  
# ìš”ì•½   



DeepGeCoëŠ” **(s, k)-mer ì¸ì½”ë”©ê³¼ ì‹¬ì¸µ ì‹ ê²½ë§**ì„ í™œìš©í•˜ì—¬ ìœ ì „ì²´ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì••ì¶•í•˜ëŠ” ë¬´ì†ì‹¤ ì••ì¶• í”„ë ˆì„ì›Œí¬ë¡œ, Warm-Start ë° Supporter ëª¨ë¸ì„ ì¡°í•©í•˜ì—¬ ì´ˆê¸° í•™ìŠµ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì••ì¶•ë¥ ê³¼ ì²˜ë¦¬ëŸ‰ì˜ ê· í˜•ì„ ìµœì í™”í•œë‹¤. ì‹¤í—˜ ê²°ê³¼, DeepGeCoëŠ” ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ **ìµœëŒ€ 31.095% ë†’ì€ ì••ì¶•ë¥ ê³¼ 22.949ë°° ë¹ ë¥¸ ì²˜ë¦¬ëŸ‰**ì„ ë‹¬ì„±í•˜ë©°, ë‚®ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìœ ì§€í•˜ì˜€ë‹¤. í…ŒìŠ¤íŠ¸ì—ì„œëŠ” **10ê°œì˜ ì‹¤ì œ ìœ ì „ì²´ ë°ì´í„°ì…‹**ì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€í–ˆìœ¼ë©°, ì…ë ¥ ë°ì´í„°(FASTA ì„œì—´)ë¥¼ ì••ì¶•ëœ ë°”ì´ë„ˆë¦¬ íŒŒì¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì—ì„œ íš¨ìœ¨ì ì¸ ì••ì¶• ì„±ëŠ¥ì„ í™•ì¸í•˜ì˜€ë‹¤.  

---


DeepGeCo is a lossless genomic data compression framework utilizing **(s, k)-mer encoding and deep neural networks**, combining Warm-Start and Supporter models to solve the cold-start problem and optimize the trade-off between compression ratio and throughput. Experimental results show that DeepGeCo achieves **up to 31.095% higher compression and 22.949Ã— faster throughput** compared to baseline models while maintaining low memory usage. It was tested on **10 real-world genomic datasets**, demonstrating effective compression by converting FASTA sequences into compressed binary files.


<br/>  
# ê¸°íƒ€  




DeepGeCoì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ **ê·¸ë˜í”„(Figures)ì™€ í…Œì´ë¸”(Tables)**ì´ í¬í•¨ë˜ì—ˆìœ¼ë©°, ì´ëŠ” ëª¨ë¸ì˜ ì••ì¶•ë¥ , ì²˜ë¦¬ëŸ‰, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë“±ì„ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë˜ì—ˆë‹¤.  

---

### **1. ì••ì¶•ë¥  ë¹„êµ (Table 2: Compression Ratios across Models)**  
- **DeepGeCoì˜ PLUS ëª¨ë“œ(1.677 bits/base)ì™€ ULTRA ëª¨ë“œ(1.674 bits/base)**ê°€ ê°€ì¥ ë‚®ì€ ì••ì¶•ë¥ (ì¦‰, ê°€ì¥ ë†’ì€ ì••ì¶• ì„±ëŠ¥)ì„ ë‹¬ì„±í•˜ì˜€ë‹¤.  
- ê¸°ì¡´ ëª¨ë¸ê³¼ ë¹„êµí–ˆì„ ë•Œ,  
  - **DNA-BiLSTM** ëŒ€ë¹„ **7.680% í–¥ìƒ**,  
  - **TRACE** ëŒ€ë¹„ **3.103% í–¥ìƒ**,  
  - **DZIP (Supporter)** ëŒ€ë¹„ **31.095% í–¥ìƒ**ì„ ë³´ì˜€ë‹¤.  
- íŠ¹íˆ **ULTRA ëª¨ë“œ**ê°€ ê°€ì¥ ë†’ì€ ì••ì¶•ë¥ ì„ ì œê³µí•˜ë¯€ë¡œ **ì¥ê¸°ì ì¸ ìœ ì „ì²´ ë°ì´í„° ë³´ê´€**ì— ì í•©í•˜ë‹¤.  

---

### **2. ì²˜ë¦¬ëŸ‰ ë¹„êµ (Table 3: Throughput Performance in KB/s)**  
- **MINI ëª¨ë“œ(96.568 KB/s)**ê°€ ê°€ì¥ ë†’ì€ ì²˜ë¦¬ëŸ‰ì„ ë‹¬ì„±í•˜ë©°, **ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ìµœëŒ€ 22.949ë°° ë¹ ë¥¸ ì••ì¶• ì†ë„**ë¥¼ ë³´ì˜€ë‹¤.  
- ì ì‘í˜• ë°©ì‹ì¸ **PLUS ëª¨ë“œ(23.686 KB/s)ì™€ ULTRA ëª¨ë“œ(16.984 KB/s)**ë„ ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ ë›°ì–´ë‚œ ì²˜ë¦¬ëŸ‰ì„ ê¸°ë¡í•˜ì˜€ë‹¤.  
- ì´ëŠ” **(s, k)-mer ì¸ì½”ë”© ê¸°ë²•ê³¼ Transformer ê¸°ë°˜ Supporter ëª¨ë¸ì˜ ìµœì í™”** ë•ë¶„ì´ë‹¤.  

---

### **3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ (Table 4: Memory Usage in GB)**  
- **CUDA ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**ì„ ë³´ë©´, **DeepGeCoì˜ MINI ëª¨ë“œ(0.165GB)**ê°€ ê°€ì¥ ì ì€ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤.  
- ì´ëŠ” **TRACE(0.507GB) ëŒ€ë¹„ 3.07ë°° ë” ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**ì´ë©°, **DZIP (2.825GB) ëŒ€ë¹„ 17ë°° ì´ìƒ ì ì€** ê°’ì„ ë³´ì˜€ë‹¤.  
- ë©”ëª¨ë¦¬ê°€ ì œí•œëœ í™˜ê²½ì—ì„œë„ **DeepGeCoê°€ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©ë  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•œë‹¤**.  

---

### **4. (s, k)-mer ì¸ì½”ë”© ìµœì í™” ë¶„ì„ (Figure 5: RTCR Ranking for Different (s, k)-mer Encodings)**  
- **RTCR(Ranking of Throughput and Compression Ratio) ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ìµœì ì˜ (s, k) ì¡°í•©ì„ ë¶„ì„**í•œ ê²°ê³¼,  
  - **(3,3)-mer ì¸ì½”ë”©ì´ ê°€ì¥ ë†’ì€ ì••ì¶•ë¥ ê³¼ ì²˜ë¦¬ëŸ‰ì„ ë™ì‹œì— ìœ ì§€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤**.  
- ì´í›„ ì‹¤í—˜ì—ì„œëŠ” **(3,3)-merì„ ê¸°ë³¸ ì„¤ì •ê°’**ìœ¼ë¡œ ì‚¬ìš©í•˜ì˜€ë‹¤.  

---

### **5. ì„ê³„ê°’ ì¡°ì •ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™” (Table 9: Impact of Threshold (ts))**  
- **ì„ê³„ê°’(ts)ì´ ì¦ê°€í• ìˆ˜ë¡ ì••ì¶•ë¥ ì´ í–¥ìƒë˜ì§€ë§Œ ì²˜ë¦¬ëŸ‰ì´ ê°ì†Œ**í•˜ëŠ” ê²½í–¥ì´ ë‚˜íƒ€ë‚¬ë‹¤.  
- ìµœì ì˜ ê· í˜•ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ **ts = 10ì„ ê¸°ë³¸ê°’**ìœ¼ë¡œ ì„¤ì •í•˜ì˜€ë‹¤.  

---

### **6. ë°°ì¹˜ í¬ê¸° ë³€ê²½ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™” (Figure 6: Impact of Batch Size on Compression Ratio, Throughput, and Memory Usage)**  
- **ë°°ì¹˜ í¬ê¸°(bs)ê°€ ì¦ê°€í•˜ë©´ ì••ì¶•ë¥ ê³¼ ì²˜ë¦¬ëŸ‰ì´ í–¥ìƒë˜ì§€ë§Œ, GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ë„ ì¦ê°€**í•¨ì„ í™•ì¸í•˜ì˜€ë‹¤.  
- **bs = 320**ì´ ì„±ëŠ¥ê³¼ ìì› í™œìš© ì¸¡ë©´ì—ì„œ **ìµœì ì˜ ê°’**ìœ¼ë¡œ ê²°ì •ë˜ì—ˆë‹¤.  

---



Several **figures (graphs) and tables** were included in the paper to evaluate DeepGeCo's **compression ratio, throughput, and memory usage**.

---

### **1. Compression Ratio Comparison (Table 2: Compression Ratios across Models)**  
- **DeepGeCoâ€™s PLUS mode (1.677 bits/base) and ULTRA mode (1.674 bits/base)** achieved the best compression performance.  
- Compared to baselines:  
  - **7.680% improvement over DNA-BiLSTM**,  
  - **3.103% improvement over TRACE**,  
  - **31.095% improvement over DZIP (Supporter)**.  
- **ULTRA mode provides the best compression ratio**, making it suitable for **long-term genomic data storage**.  

---

### **2. Throughput Comparison (Table 3: Throughput Performance in KB/s)**  
- **MINI mode (96.568 KB/s) achieved up to 22.949Ã— faster throughput** than baselines.  
- **PLUS mode (23.686 KB/s) and ULTRA mode (16.984 KB/s)** also showed superior throughput.  
- The improvement is due to the **(s, k)-mer encoding technique and Transformer-based Supporter model optimization**.  

---

### **3. Memory Usage Comparison (Table 4: Memory Usage in GB)**  
- **MINI mode (0.165GB CUDA memory) consumed the least memory**,  
  - **3.07Ã— lower than TRACE (0.507GB)** and **17Ã— lower than DZIP (2.825GB)**.  
- This suggests that **DeepGeCo can be effectively deployed in memory-constrained environments**.  

---

### **4. (s, k)-mer Encoding Optimization (Figure 5: RTCR Ranking for Different (s, k)-mer Encodings)**  
- The **RTCR (Ranking of Throughput and Compression Ratio) metric was used to determine the best (s, k) configuration**.  
- **(3,3)-mer encoding achieved the optimal balance between compression ratio and throughput**,  
  - Thus, **(3,3)-mer was chosen as the default setting for subsequent experiments**.  

---

### **5. Effect of Threshold Adjustment (Table 9: Impact of Threshold (ts))**  
- **Increasing the threshold (ts) improved the compression ratio but reduced throughput**.  
- To maintain the best balance, **ts = 10 was selected as the default value**.  

---

### **6. Impact of Batch Size on Performance (Figure 6: Impact of Batch Size on Compression Ratio, Throughput, and Memory Usage)**  
- **Larger batch sizes (bs) improved compression ratio and throughput but increased GPU memory usage**.  
- **bs = 320 was determined to be the optimal setting** for balancing performance and resource efficiency.  

---

### **Conclusion**  
The figures and tables demonstrate that **DeepGeCo achieves the best balance of compression efficiency, speed, and memory usage**. The findings validate that **DeepGeCo significantly outperforms existing models** while maintaining a low computational footprint.


<br/>
# refer format:     


@article{Sun2025DeepGeCo,
  author    = {Hui Sun and Liping Yi and Huidong Ma and Yongxia Sun and Yingfeng Zheng and Wenwen Cui and Meng Yan and Gang Wang and Xiaoguang Liu},
  title     = {Genomics Data Lossless Compression with (S,K)-Mer Encoding and Deep Neural Networks},
  journal   = {Proceedings of the Association for the Advancement of Artificial Intelligence},
  year      = {2025},
  publisher = {AAAI},
  pages     = {1--12}
}


Sun, Hui, Liping Yi, Huidong Ma, Yongxia Sun, Yingfeng Zheng, Wenwen Cui, Meng Yan, Gang Wang, and Xiaoguang Liu. 2025. "Genomics Data Lossless Compression with (S,K)-Mer Encoding and Deep Neural Networks." Proceedings of the Association for the Advancement of Artificial Intelligence, 1â€“12. AAAI.


