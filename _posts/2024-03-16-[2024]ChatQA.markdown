---
layout: post
title:  "[2024]ChatQA: Building GPT-4 Level Conversational QA Models"  
date:   2024-03-16 22:16:29 -0400
categories: study
---

{% highlight ruby %}


한줄 요약:  

짧은 요약(Abstract) :    
* 이 논문에서 저자들은 대화형 질문 응답(QA) 모델인 ChatQA를 소개하였음  
* 저자들은 큰 언어 모델(LLM)에서 대화형 QA의 zero-shot 결과를 크게 향상시킬 수 있는 두 단계 지시어 튜닝 방법을 제안하였음  
* 대화형 QA에서 검색을 통합하기 위해, 저자들은 다단계 QA 데이터셋에서 조밀한 검색기를 미세 조정  
* 이는 최신의 질의 재작성 모델을 사용하는 것과 비교할 수 있는 결과를 제공하면서 배포 비용을 크게 줄였음  
* 특히, 저자들의 ChatQA-70B 모델은 10개의 대화형 QA 데이터셋에서 평균 점수(54.14 대 53.90)로 GPT-4를 능가  
* 이는 OpenAI GPT 모델에서 생성된 합성 데이터에 의존하지 않고 달성되었음  

Useful sentences :  


{% endhighlight %}  

<br/>

[Paper link](https://drive.google.com/drive/folders/15zm7pKvkg67pOnHOEQun1FWYZROrQ6y_?usp=sharing)  
[~~Lecture link~~]()  

<br/>

# 단어정리  
* 
<br/>

# 1. Introduction  
* 

<br/>
# 7. Conclusion  
* 이 논문에서 저자들은 7B에서 70B에 이르는 다양한 모델 크기의 ChatQA 모델들을 구축하였음  
* 10개 대화형 QA 데이터셋에 대한 포괄적인 평가를 통해, 저자들의 최고 모델인 ChatQA-70B가 GPT-3.5-turbo를 현저히 능가하고 GPT-4와 동등한 수준의 성능을 보임을 보여주었으며, 이는 ChatGPT 모델에서 생성된 합성 데이터를 사용하지 않고도 달성되었음  
* 또한, 저자들은 저자들의 수집한 대화형 QA 데이터를 사용하여 단일 턴 쿼리 검색기를 미세 조정하는 것이 상태 최신 LLM 기반 질의 재작성 모델과 비슷한 성능을 내면서도 추가적인 연산 시간과 잠재적인 API 비용을 발생시키지 않음을 보여주었음  
* 더욱이, 저자들은 "답변 불가" 샘플의 소량을 포함시키는 것이 저자들의 모델이 제공된 맥락에서 답변을 찾을 수 없을 때 이를 명시적으로 나타내는 능력을 크게 향상시킬 수 있음을 보여주었음  
* 답변 불가 평가는 저자들의 최고 모델인 ChatQA-70B가 GPT-4와 비교했을 때 약간의 격차가 있지만 매우 강력한 성능을 보임을 강조함  