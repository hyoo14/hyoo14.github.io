<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge"/>

  
  

  
  
  

  
  
  

  

  
  

  
    
      
      

  <!-- Primary Meta Tags -->
  <title>Weekly Mountain, Paper, and Work | AI CONCEPTS NOTE</title>
  <meta name="title" content="Weekly Mountain, Paper, and Work | AI CONCEPTS NOTE"/>
  <meta name="description" content="Bay is a minimal Jekyll Theme."/>

  <!-- Open Graph / Facebook -->
  <meta property="og:site_name" content="Weekly Mountain, Paper, and Work | AI CONCEPTS NOTE"/>
  <meta property="og:type" content="article"/>
  <meta property="og:url" content="http://localhost:4000/_nlp/study/2021/08/04/AI-CONCEPTS-NOTE"/>
  <meta property="og:title" content="Weekly Mountain, Paper, and Work | AI CONCEPTS NOTE"/>
  <meta property="og:description" content="Bay is a minimal Jekyll Theme."/>
  <meta property="og:image" content="http://localhost:4000/assets/img/profile-pic.jpg"/>

  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image"/>
  <meta property="twitter:url" content="http://localhost:4000/_nlp/study/2021/08/04/AI-CONCEPTS-NOTE"/>
  <meta property="twitter:title" content="Weekly Mountain, Paper, and Work | AI CONCEPTS NOTE"/>
  <meta property="twitter:description" content="Bay is a minimal Jekyll Theme."/>
  <meta property="twitter:image" content="http://localhost:4000/assets/img/profile-pic.jpg"/>
  
    <meta property="twitter:creator" content="@YourTwitterUsername"/>
    <meta property="twitter:site" content="@YourTwitterUsername"/>
  

  <link rel="stylesheet" href="http://localhost:4000/assets/css/main.css"/>
  <link rel="canonical" href="http://localhost:4000/_nlp/study/2021/08/04/AI-CONCEPTS-NOTE"/>
  <link rel="shortcut icon" href="http://localhost:4000/favicon.ico" type="image/x-icon"/>

  <!-- Google Analytics -->
  <script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', "UA-121636368-3", "auto");
    ga('send', "pageview");
  </script>
  <script async src="https://www.google-analytics.com/analytics.js"></script>


</head>


  <body>
    <header class="site-header">
  <div class="wrapper">
    <a class="site-title" href="http://localhost:4000/">
      <img src="http://localhost:4000/assets/img/title.png" alt="Weekly Mountain, Paper, and Work" />
    </a>

    <nav class="site-nav">
      <a href="#" class="menu-icon"></a>

      <div class="menu">
        
          
          
          <a class="page-link" href="http://localhost:4000/">
            Home
          </a>
        
          
          
          <a class="page-link" href="http://localhost:4000/work">
            Work
          </a>
        
          
          
          <a class="page-link" href="http://localhost:4000/mountain">
            Mountain
          </a>
        
          
          
          <a class="page-link" href="http://localhost:4000/study">
            Study
          </a>
        
      </div>
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

          <header class="post-header">

            

            <h1 class="post-title">
            
              AI CONCEPTS NOTE
            
            </h1>

            
            <p class="post-meta"><span class="post-date">August 4, 2021
            </span></p>
          </header>

          <article class="post-content">
            <p>한번 정리하고 넘어가고 싶어서 개념들 서술해봅니다.</p>

<p>-2-</p>

<p>랭기지모델 학습 - 단어 분포 모사. 마코브 어썸션 도입하여 더 낮은 엔그램으로 근사</p>

<p>좋은 모델 : 언어분포 잘 모사. 잘 정의된 테스트셋에 높은 확률 반환</p>

<p>펄플렉시티: 몇개중에 헷갈리고 있냐. 작을 수록 좋은 것</p>

<p>뉴럴랭기지 모델은 제너럴라이즈가 잘 된다는 것이 장점, 등장하지 않은 단어들도 처리 가능</p>

<p>엔트로피 불확실성 나타냄. 자주 일어나는 사건은 낮은 정보량. 드물게 발생하면 높은 정보량 가짐.<br />
불확실성은 1/등장확률 에 비례하고, 정보량에 반비례<br />
확률 낮은 것일 수록 정보량 많은 것, 불확실성 큰 것<br />
정보량은 마이너스 로그 확률. 확률 높아질수록 정보량 낮아짐. 0가까워질수록 높아짐</p>

<p>엔트로피 높을수록 플랫 디스트리뷰션, 낮을수록 샤프한 디스트리뷰션</p>

<p>크로스엔트로피는 퍼플렉시티의 로그취한 값.<br />
퍼플렉시티 작게하는 것이 목적으로 이는 크로스엔트로피 익스퍼넨셜 미니마이즈.<br />
즉, 크로스엔트로피 미니마이즈로 볼 수 있음</p>

<p>클래시피케이션이니까 크로스엔트로피 쓴다고 봐도 되고<br />
두 분포 차이 미니마이즈니까 크로스엔트로피 미니마이즈.<br />
아키르릴후드 맥시마이즈 할꺼니까 네거티브 라이클리후드 마니마이즈 하는 건데 이게 크로스엔트로피 미니마이즈와 같음.</p>

<p>크로스엔트로피 로그 취하면 퍼플렉시티.<br />
퍼플렉시티 익스퍼넨셜 취하면 크로스엔트로피임.</p>

<p>seq2seq의 many to many는 many to one 과 one to many 로 이해하는 것이 좋음</p>

<p>non-auto-regessive-현재 상태가 앞 뒤 문맥에 의해 정해짐<br />
auto-regressive- 과거상태 의존</p>

<p>티처포싱 안 하면 many2many 개수 안 맞을 수도. eos먼저 뜨면<br />
티처포싱 안 하면 이전 출력에 따라 현재 스테이트 달라짐 mle 이상해짐<br />
mle다르게 수식 적용<br />
그래서 실제 정답을 넣으줌. 그래서 학습이랑 테스트(추론) 다로 2개 짜야함<br />
티처포싱 성능 저하될 수 있으나 기본적 성능 좋아서 걍 쓰면 되지만.. 왜 저하되냐면 순서까지도 기억해주는 오버피팅이 되기때문. 그래서 보통 반반티처포싱 등 사용</p>

<p>fluent한 문장 골라내는 일이나 다음단어 뽑아내는 일은 언어모델로 사실 같음.</p>

<p>-4-<br />
seq to seq 도 auto encoder와 비슷<br />
autoencoder - 특징 추출 하는 것.(차원축소(latent space:잠재 feature의 공간?) 및 복원을 통해)</p>

<p>decoder는 conditional language model이라고 볼 수 있음-인코더로부터 문장을 압축한 context vector를 바탕으로 문장생성<br />
(conditional? 조건부 확률 느낌?)</p>

<p>classification(단어선택), discrete value 예측하는 거니까 크로스엔트로피 쓰면 됨. (소프트맥스 결과값에)<br />
MLE중이니까 negative log likelihood 미니마이즈해야히니까 크로스엔트로피.<br />
디코더가 컨디셔널랭기지 모델이니깐 퍼플렉시티 미니마이즈 해야하는 것. 그니깐 크로스엔트로피 익스포넨셜<br />
이 코르스엔트로피니깐. 크로스엔트로피 쓰면 <br />
결국 ground truth 분포와 모델 분포 삳이의 차이를 최소화하기 위함<br />
(Ground-truth는 학습하고자 하는 데이터의 원본 혹은 실제 값)</p>

<p>어텐션?<br />
키-벨류 펑션으로 미분가능함<br />
파이선의 딕셔너리= {K:v1, K2:v2} ,,, d[K] 벨류리턴 - (딕셔너리설명)<br />
기존 딕셔너리 key-value 펑션과 달리 query와 key의 “유사도”에 따라 value 반환!(weighted sum으로)<br />
-&gt;lstm hidden state한계인 부족정보를 직접 encoder에서 조회해서 예측에 필요한 정보 얻어오는 것.<br />
정보를 잘 얻어오기(이 과정이 attention) 위해 query 잘 만들어내는 과정을 학습</p>

<p>attention은 QKV.<br />
Q:현재 time-step의 decoder의 output<br />
K: 각 time-step 별 encoder의 output<br />
V: 각 time-step 별 encoder의 output<br />
q와 k의 유사도 계산(encoder output token들)<br />
유사도를 각각 encoder output toekn들에 곱해주고 더해서 현재 context vector 만들어줌.<br />
쿼리 날린 decoder 히든스테이트와 context vector를 컨캣해줘서 새로운 히든스테이트를 얻음(이것이 반영 된 것)<br />
근데 유사도 구할 때 유사도 팍팍 안 구해짐. 그래서 linear transform(linear layer 통과시킴) 후에 유사도 얻어옴.<br />
그래서 우리는 linear transform을 학습해서 유사도를 잘 받아오게 학습해야함. 이것도 잘 학습해야함</p>

<p>비유해보면 “오리역에서 가장 편하게 밥먹는 집 어디야?” -&gt; “오리역 가정식 백반집”(쿼리 바꾸는 거 학습한 것)<br />
마음속의 상태(state)를 잘 반영하면서 좋은 쿼리를 만들기 위함임.<br />
어텐션은 “쿼리를 잘 만들어내는(변환) 과정” 배우는 것이다. 여기서 batch matrix multiplication(BMM) 사용(행렬들 곱)<br />
닷프로덕트가 코싸인시뮬러리티와 비슷. 소프트맥스까지 쒸우면 유사도라고 볼 수 있음</p>

<p>pad토큰 위치에 weight가 가지 않도록 하는 안전장치 추가-&gt;이것이 마스킹</p>

<p>input feeding? 샘플링과정서 손실되는 정보 최소화, 티쳐포싱으로 인한 학습/추론 사이의 괴리 최소화<br />
인풋피딩? 아웃풋 히든스테이트를을 다음 인풋 히든스테이트에 컨캣</p>

<p>auto-regressive : 과거 자신의 상태를 참조하여 현재 자신의 상태를 업데이트. 시퀀스에서 이전 단어 보고<br />
다음 단어 예측하는 것.</p>

<p>teacher forcing 통해 auto-regressive task에 대한 sequential modeling 가능. 하지만 training mode 와 inference mode의 괴리<br />
(discrepancy) 생김</p>

<p>(dilde : ~ (물결표) )</p>

<p>pytorch ignite로 procedure 짜놓을 수 있음(lightening도 가능)</p>

<p>-5-</p>

<p>NLG - 가장 높은 확률 갖는 문장 예측. 일종의 shortest path 찾는 것으로 볼 수 있두아!</p>

<p>beam search 통해 greedy search 단점 	보완 가능(어느정도)</p>

<p>재미있어야하는 챗봇에서는 랜덤샘플링도 ㄱㅊ. 테스크에 따라 .. 번역에서는 일관성이 떨어져서 좀 그럼.</p>

<p>coverage penalty= 어텐션이 time step마다 다른 곳에 집중해야 좋은 번역일 것이라 생각(다 같은 곳만 집중시 한계니)<br />
페널티로 성능 변화는 미미하긴함</p>

<p>그래서 트레이닝 vs 인퍼런스?<br />
트레이닝은 티쳐포싱 통해서 한 스텝마다 정답이 나오게..(다음 스텝 인풋은 정답)<br />
인퍼런스는 스텝 밟아가면서,, 스텝 결과값이 다음 인풋, 또 이 결과값이 또 다음 스텝의 인풋으로 쭉쭉 가는 것.</p>

<p>인퍼런스는 다음 타임스텝에 넣어주고 학습은 티처포싱이었음..(참고)  	
이것은 오토리그레시브 속성(이전 타임스텝에 영향을 받ㄴ는 것. 쭉쭉)</p>

<p>기존에 포워드함수 하나 짜면 학습과 추론 다 되었다면, (학습 추론 같았기 때문.)<br />
하지만 NLG task(auto regressive 속성 띄기 때문) 트레이닝과 인퍼런스 함수 따로 만들어줘야.<br />
그래서 트레이닝함수 구현 했어도 서치라는 추론함수 만들어줌. 두 함수가 괴리가 일어나고<br />
그래서 강화학습이나 듀얼러닝 같은 것들 사용해서 괴리 줄여줌</p>

<p>-6-</p>

<p>test set 적격성</p>

<p>noise 포함되지 않았는가?<br />
실제 deploy 할 때와 같은 domain 인가? (이상적으로는 TRAIING 할 때와 같은 DOMAIN)</p>

<p>scoring metric. 해당 task 채점하기에 적헐한 metric 인가?</p>

<p>평가 크게 2가지<br />
정성평가(INTRINSIC) <br />
-사람이<br />
-인건비 비싸고 속도 느리고 주관개입가능(단)<br />
-절대평가/상대평가 두가지 방법이 있음</p>

<p>정량평가(EXTRINSIC)<br />
-자동으로<br />
-저렴비용, 빠른속도, 객관적 평가가능(장)<br />
-정확도가 낮을 수 있음(장)</p>

<p>-크로스엔트로피, 펠플렉시티로 평가(예)<br />
-평가방법으로 BLEU가 있음</p>

<p>실제 DEPLOY를 위해서는 INTRINSIC EVALUATION을 꼭 거쳐야함.<br />
(잦은 업데이트의 경우 EXTRINSIC EVALUATION) <br />
(배포할 때는 INTRINSIC 써서 비교통해 이전 모델과 비교 후 배포)</p>

<p>-BLEU -블루 매트릭-<br />
테스트 문장에 대해 확률을 높게 반환할수록 좋은 모델, 테스트문장에 대해 PPL이 작을수록 좋은 언어모델.<br />
PPL-몇개의 단어중에 헷갈리고 있는지. 이는 엔트로피랑 연결됨.<br />
expCE = PPL, CE = logPPL ce미니마이지는 로그피피엘 미니마이지</p>

<p>하지만 PPL(CE)는 정확한 번역의 품질을 반영 못 함. 특히 어순 변화에 취약함.</p>

<p>좋은 번역의 품질 반영을 위해 BLEU 사용.<br />
BLEU는 가중평군. (각 ngram별)</p>

<p>PPL낮을 수록 좋음. 딥러닝 모델서 CE낮아지므로 PPL떨어짐 확인. 하지만 어순 변화에 취약<br />
BLEU는 평균 precision이어서 높은 것이 좋은 것으로 어순 변화에 robust함. 사람 평가와 좋은 상관관계 보여줌<br />
BLEU 좋아지면 성능 오른 것으로 보지만 유의어/동의어 대처는 떨어지고, intrinsic 필요(서비스를 위해서는)<br />
multi-bleu.perl 사용하면 됨(범용임). 파이썬 안에서 막 찍어보려면 nltk에서 쓰는 것도 좋음(직접구현비추)</p>

<p>bleu 적용?  bpe tokenization 모두 detokenization, 한글은 mecab등으로 접사 및 특수문자 분리 후 bleu측정<br />
영어 등 라틴기반은 moses 통해 특수문자 분리 후 측정, 띄워쓰기 없는 중국어 일본어는 mecab, jieba통해<br />
seg 후 bleu측정</p>

<p>정성평가? 잘 선정된 test set으로 경쟁사로 평가<br />
-절대평가: 실제 번역 품질 단계 나눠 평가. 일관적 평가 품질 유지가 관건. (A,B,C 매기기)<br />
-상대평가: 벤치마크 대상 모아놓고 순위 매겨 평가. 객곽전 평가 품질 유지가 관건.(1,2,3등 구하면 되니 편함)<br />
전부 블라인드 테스트.</p>

<p>ppl 다음 타임스텝의 확률 분포가 얼마나 샤프한지 플랫한지를 나타냄. 샤프할수록 좋은 언어모델로 간주<br />
나는 좋아한다 학교 가는 것 / 학교 가는 것 나는 좋아한다 -&gt; 둘 다 맞지만 이런 거 평가하기에는 ppl로 부족<br />
근데 bleu는 미분이 안 되서 최적화에 사용 못 함<br />
작은 차이에서 bleu로 평가하면 좋음(정량평가)<br />
정성평가에서는 블라인드 테스트로 일관성과 객관성 유지가 중요</p>

<p>-7-</p>

<p>beam search가 많이 다뤄지진 않지만 서비스에서는 필수적인 부분<br />
데이터 확보, 모델 개선 없이도 훨씬 나은 성능 거둘 수 있음</p>

<p>NLG는 사실 search 문제<br />
(greedy search는 지금의 최선이 나중에는 나쁜 선택이될 수 있음, <br />
beam search는 top-k를 트래킹하여 그리디를 좀 더 안전하게 수행-auto regressive 단점 만회 어느정도)</p>

<p>top-k씩 계속 뽑는 것이 아니라<br />
처음 tok-k, 이후 파생된 것들 중에서 누적 중에서 top-k만 뽑음<br />
성능 제일 좋았다(seq2seq에서 transformer 쓰는 정도의 개선)<br />
패러렐하게 처리하면 속도면에서 이득을 볼 수 있음(메모리 소모되지만..)<br />
bean 크기는 5나 10정도.. 10이상은 거의 쓸 필요는 없다 개선이 거의 없어서..</p>

<p>빔서치 미니배치 패러렐라이즈 구현하면 속도와 성능 둘 다 좋을 수 있음 <br />
n샘플에 대한 빔서치 수행할 때 n x k 번의 inference가 수행<br />
따라서 n x k 개 샘플의 미니배치에 대한 inference를 수행하면 됨</p>

<p>k에서 파생된 애들을 각각 패러렐하게 계산해주고 컨캣 한 후 다시 k개 나눠서 페러렐하게 하면 되겠네</p>

<p>실제로 ppl이 번역의 성능(bleu)와 정비례하지 않음(경험적으로)</p>

<p>-8-</p>

<p>복습: <br />
어텐션은 마음의 상태(state)를 잘 반영하면서<br />
좋은 검색 결과를 이끌어내는 쿼리를 얻기 위함<br />
(예) 강남역에서 가장 회식하기 좋은 오리고기 맛있는 집은 어디야? -&gt; 강남역 오리고기 회식장소 맛집</p>

<p>만약 검색을 다양하게 할 수 있다면? =&gt; 멀티헤드 어텐션<br />
(예) 강남역 오리고기 회식장소 맛집, 오리로스 맛집, 강남역 가까운 오리고기 집, 저렴한 오리고기 등..(다양하게)</p>

<p>스케일드닷프로덕트 어텐션? -그라디언트를 좀 더 안정적으로 학습하게 상수를 나누어줌<br />
(학습이 좀 더 안정적으로 수행)</p>

<p>멀티헤드어텐션: 스케일드닷프로덕트어텐션을 여러개 들고 있음(h개만큼-#head)<br />
재미있는 것은 Q도 h개(헤드개수만큼), K, V도 h개 만큼. <br />
쿼리만 바꾸는 것이 아니라 k와 v도 정보를 빼오기 편리하게 학습하는 것. 이것이 키포인트</p>

<p>인코더에서 처음에 q,k,v가 같음(이전 블럭의 결과값)</p>

<p>디코더의 경우도 qkv 이전 블럭의 결과값<br />
인코더의 최종 출력값 q,k,v 출처가 다 달라짐. 나중에 좀 더 자세히 설명</p>

<p>예전에는 디코더가 각 타임스텝마자 시퀀셜하게 어텐션이 들어갔다면<br />
지금은 한꺼번에 q가 모든 타임스텝에 대해 k에 쿼리를 때려보는 것. 그래서 속도가 빠름. 대신에 메모리 좀 먹음<br />
배치사이즈의 샘플 별 문장 별 디코더의 각 타임스텝 별 인코더의 각 타임스텝에 대한 웨이트가 들어간 텐서<br />
(배치사이즈 샘플:미니배치의 각 문장 별)</p>

<p>멀티헤드 어텐션이란 어텐션을 여러번. 쿼리를 여러번 날림. 다양한 쿼리 날려서 더 다양한 내가 필요한 정보<br />
얻어오자.
어텐션 자체로도 인코딩과 디코딩이 가능.<br />
인코더에서 이전레이어 정보 잘 취합 때 어텐션 사용<br />
디코더에서 이전 정보 잘 취합할 때 어텐션 사용<br />
이를 통해 seq2seq 보다 더 뛰어난 구조 만들 수 있음</p>

<p>인코더는 셀프어텐션으로 구성. qkv는 이전 레이어의 출력값-즉,같은값<br />
q가 모든 타임스텝을 동시에 연산. 레지두얼 커넥션으로 깊게 쌓을 수 있게 됨.<br />
BigLM의 토대로 프리트레인 랭기지 모델의 토대가 됨</p>

<p>디코더블락-인코더와 달리 어텐션이 두개가 들어감. 하나는 인코더에서 오는 어텐션과 인코더와 같은 셀프어텐션.<br />
인코더서 온 거는 kv가 인코더에서 옴.</p>

<p>사실 패드처리를 위한 마스크가 셀프어텐션과 인코더디코더어텐션에 들어가 있어야함<br />
디코더의 셀프어텐션에 오토리그레시브한 학습을 할 때 마스킹해야함(티쳐포싱하니깐)<br />
정리하면,<br />
디코더는 인코더에서 온 어텐션(q는 이전레이어 출력값, k,v는 encoder에서 옴. 패드 마스크 들어감), <br />
셀프어텐션(마스크는 미래 보는 거 방지하는 마스크-autoregressive문제 방지용), qkv는 이전레이어출력값<br />
-패드마스크는 추론할 때 필요. 학습할 때는 꼭 필요한 것은 아님.</p>

<p>추론할 때는 셀프어텐션마스크 필요 없음(어차피 모르니..)<br />
단 모든 레이어의 t시점 이전의 모든 타임스텝의 히든스테이트가 필요함.(반영해야하니)</p>

<p>버트는 포지션인코딩 대신에 포지션임베딩레이어 사용해서 학습해서 진행<br />
rnn과 달리 순서 정보 없기 때문에 트랜스포머에서는 포지션인코딩 써줘야하고 한번만 계산해 놓으면 됨.</p>

<p>sgd에 gradient clipping으로 seq2seq 학습시켰었음 <br />
기본적으로 러닝레이트 튜닝되게 잘해줘야함. 너무 크면 발산, 너무 작으면 학습속도가 느려짐.<br />
절충안으로 러닝레이트 디케이해줌</p>

<p>아담쓰면 lr 건드릴 필요 없이 최고성능 보여줌<br />
문제는 깊은 네트워크에서, 예를들면 트랜스포머에서 쓰면 성능이 잘 안 나옴<br />
추정컨데 레지듀얼 커넥션 때문에 학습초기에 불안정한 그라디언트를 잘못된 모멘텀을 갖게 되는 듯?<br />
그래서 warm-up and linear decay(noam decay) 씀 -&gt; 처음에 러닝레이트를 작게 가져가서 불안정한 그라디언트로 인한<br />
잘못된 모멘텀이 만들어지는 것을 방지해보자(이런 것들을 러닝레이트 스케줄링이라고함)<br />
트라이얼해서 좋은 곳 찾는 나이브한 방법. warm-up step을 첫 epoch의 5%정도로<br />
warm-up step에 굉장히 민감..<br />
warm-up step 찾기 어려워서 그래서 RADM(Rectified Adam)이 나옴.<br />
얼리스테이지의 샘플 부족으로 어댑티브러닝레이트가 바랍직하지 않은 variance 갖게 됨</p>

<p>layer norm 위치를 멀티헤드어텐션 앞에 놓이니 학습이 잘 됨. LN이gradient를 평탄하게 바꾸는 효과.<br />
웜업 하던, RADAM쓰던 layer norm 해주니 성능 잘 나옴<br />
(lr decay는 여전히 필요)</p>

<p>트랜스포머는 디코딩할 때 이전 스텝의 결과물 다 들고있어야함.(메모리 많이 듦)<br />
메모리이슈땜에 rnn계열 lstm 꺼 쓰기도 함(요즘 NLG에서 디코더는, 성능이 크게 차이 안 나서..)</p>

<p>인코더가 성능 좌지우시. 그래서 인코더 트랜스포머, 디코더는 rnn쓰는 경우도 곧잘 있음<br />
pre-LN transformer에서 adam써서 최적화문제 해결</p>

<p>residual connection으로 transformer깊게 쌓을 수 있음</p>

<p>어텐션의 닷프로덕트연산은 코싸인시밀러리티와 유사.<br />
어텐션은 쿼리를 잘 만들어내서 key-value로부터 필요한 정보를 얻어내는 과정<br />
디코더의 각 타임스텝마다 인코더로부터 어텐션을 통해 정보를 얻어와서 생성 토큰의 품질을 높임-&gt;seq2seq</p>

<p>멀티헤드어텐션은 각 헤드별로 어텐션을 수행하여 다양한 정보를 얻어올 수 있음(다양한 쿼리)<br />
셀프어텐션통해 이전 레이어 정보를 인코딩/디코딩, 어텐션 통해 디코더 정보 얻어옴</p>

<p>-9-</p>

<p>멀티링구얼 기계번역?</p>

<p>인코더-디코더 구조의 모델들은 페러렐 코퍼스가 필요.</p>

<p>패러렐코퍼스 수집 비용이 매우 비쌈.<br />
한정된 패러렐 코퍼스로 학습할 경우 인코더는 컨텍스트 임베딩 성능이 떨어지고<br />
디코더는 제한된 성능의 언어모델이 될 수 밖에 없음</p>

<p>그래서 나온 해결방안이 앙상블.<br />
패러렐 부족-&gt;디코더 성능 저하.</p>

<p>그래서 모노링구얼 코퍼스로 학습한 별도 언어모델을 디코더에 앙상블로 결합</p>

<p>shallow fusion: seq2seq lm을 interpolation,</p>

<dl>
  <dt>deep fusion: 디코더와 lm의 히든 레이어 결과를 concat</dt>
  <dd>lm 상태에 따라 gate를 열고 닫아 정보의 흐름을 컨트롤</dd>
</dl>

<p>백트렌슬레이션.</p>

<p>이것도 모티브는 페러렐 코퍼스로 인한 디코더의 generation성능 떨어짐.<br />
그래서.풍부한 모노링구얼 코퍼스를 통해 추가로 디코더를 학습시켜보는 것</p>

<p>정답과 입력값을 거꾸로 해보는 것.<br />
정답 -&gt; 모델 -&gt; 입력 이런 구조</p>

<p>근데 정답 자체가 노이즈가 낀 것이어서 이게 너무 많으면 문제일 수도 있음</p>

<p>카피트렌슬레이션.<br />
그냥 y 넣고 y 나오게 해주는 것.<br />
정답 -&gt; 모델 -&gt; 정답<br />
이것도 성능이 좀 나옴.</p>

<p>노이즈드 빔백 트렌슬레이션.<br />
모델로부터 생성된 노이즈가 문제인데</p>

<p>아예 노이즈를 다양하게 섞어서 생성한 문장을 synthetic source sentece로 활용.<br />
하지만 여전히 성능의 개선의 여지가 남음</p>

<p>그래서 나온 것이 tagged back translation<br />
-신테틱 줄 때는 이거 bt라고 태그로 알려줌.<br />
이렇게 했더니 슈도코퍼스의 비율에 상관없이 학습 가능<br />
bleu 엄청 개선됨</p>

<p>-&gt;디코더의 언어모델의 성능을 향상시키는 것이 주 목적!(슈도코퍼스를 활용하여)</p>

<p>강화학습?</p>

<p>gan은 nlg 에서 feedforward는 되지만 backward가 안 되서(one-hot에서 softmax로 갈 수 없음)<br />
못 씀</p>

<p>ppl이 bleu 보다 번역의 질을 잘 반영하지 못 함.(학습때 ppl씀..)</p>

<p>–&gt; rl 통해 bleu에 대ㅐㅎ 미분 없이 학습 가능. 또한 샘플링 기반 방식이므로 티처포싱없이 학습 가능</p>

<p>rl: agent, environment, state, action, reward 로 구성</p>

<p>markov process: 이전상태 영향 받은 상태 이동. lm도 여기에 해당<br />
markov decision process: 이전상태와 행해진 액션에 영향을 받는 것.<br />
(policy, valuefunction, action-value function이 있음)<br />
value base방식과 policy base 방식이 있음</p>

<p>policy gradient의 q함수가 미분될 필요가 없음.<br />
따라서 보상함수로 미분 불가능ㅎ나 매우 족잡한(bleu) 함수를 사용할 수 있음<br />
근데 reward함수 잘 짜야함. 평균점수 대비 보상을 준다던지 등</p>

<p>nlg에서 :<br />
state: 조건으로 주어진 입력 문장 토큰들, 이전까지 생성된 토큰들<br />
action:  현재 타임스텝에서 생성할 토큰을 고르는 것<br />
reward: 완성된 생성문장과 실제 정답과의 유사도 bleu</p>

<p>nlg는 에피소드가 짧은 장점이 있음, 그래서 actor-critic 같은 고급 알고리즘을 구사할 필요성이 매우 낮음<br />
단점으로는 단어를 고르는 것이 action이므로 action space가 vocab으로 매우 크다</p>

<p>rl 장점? bleu로 optimize, (PG는 미분필요없이 bleu로 최적화 가능)<br />
티처포싱 없애도됨. nlg는 autoregressive task이므로 티처포싱으로 학습. 그래서 학습과 추론 사이 괴리감 생김<br />
근데 rl은 샘플링기반 학습이므로 학습과 추론 방법에 차이 없음</p>

<p>minimum risk training-policy gradient nlg버전<br />
리스크redefine-q함수를 y가 아닌 s서 샘플링.(subset으로 좀 더 작은 범위)<br />
몬테카를로로 구해줌<br />
마이너스 리스크 미니마이즈 플러스 리워드 맥시마이즈 결국 같은거임</p>

<p>샘플링과 라이크리후드 차이<br />
수식 잘 이해하고 코드로 옮기는 방법이 이득임</p>

<p>nllloss-negative log likelihood loss</p>

<p>-10-</p>

<p>티처포싱으로 인한 괴리.<br />
인퍼런스는 regressive한데, 티처포싱은 regressive하지 않게 정답 넣고 학습시키므로..</p>

<p>이 괴리를 없애는 다른 방법-dual learning</p>

<p>거의 모든 분야에서 듀얼러닝은 가능.</p>

<p>반대로도 학습을 하는 것. 동시에. 이것이 듀얼러닝. 이렇게 하면 더 잘될 수 있따는 아이디어<br />
근데 음성인식 경우 인식된 텍스트에서 음성으로 복구는 사실 어려움<br />
이미지 분류도 역방향은 사실 어렵<br />
그래서 기계번역에서의 듀얼러닝이 유의미함(정보손실이 거의 없으므로)</p>

<p>사이클gan이 일종의 듀얼러닝을 한 것. pair 없이 두 도메인 이미지 사이의 변환 방법을 배운 것.</p>

<p>기계번역에서도 각 언어의 문장들만 접한 상태에서 두 언어 사이의 번역 방법을 배워보는? 접근방식</p>

<p>mrt(강화학습 적용)은 샘플링 기반 방식이라서 매우 비효율적</p>

<p>mle 방식 위에서 regularization을 통해 문제를 풀 수는 없을까?<br />
이 방법이 바로 dual supervised learning</p>

<p>scale(lambda)값 줘서 정방향 역방향 다 커버하는 objective function 이용</p>

<p>시간은 오래걸림.. 메모리도 많이 사용.. 그래서 성능향상은 이뤄짐! 강화학습 샘플링 기반보다 효율적<br />
bayes theorem을 통해 유도된 매우 간단한고 직과넞ㄱ인 regularization term임.</p>

<p>pytorch autoGrad - 파이토치는 그때 그때 computation graph 생성. 필요에 따라 detach()로 back-prop 통제</p>

<p>학습시, bos, eos 모두 있어야함.</p>

<p>gan- mode collapse 문제가 있음 : 비슷한 이미지만 만들어내는 문제<br />
Wasserstein loss(와서스테인 로스) 사용해서 해결 - 분포의 다름 체크하는..<br />
cycle gan과 비슷한 dual learning.</p>

<p>back translation의 경우도 수학적으로 괜찮은 녀석임(정당성 o)</p>


          </article>

          

      </div>
      </div>
    </div>

    <footer class="site-footer">
  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <h4>CONTACT</h4>

        <div class="social-links">
          
            <div class="social-link contact-links">

              
              <img
                src="http://localhost:4000/assets/img/icons/email.png"
                alt="email"
              />
              <a href="mailto:yourmail@domain.com" id="email-link">
                
                  yourmail@domain.com
                
              </a>
            </div>

          
            <div class="social-link contact-links">

              
              <img
                src="http://localhost:4000/assets/img/icons/wechat.png"
                alt="wechat"
              />
              <a href="#" id="wechat-link">
                
                  YourWeChatUsername
                
              </a>
            </div>

          
        </div>
      </div>

      <div class="footer-col footer-col-2">
        <h4>FOLLOW</h4>

        <div class="social-links follow-links">
          
            <div class="social-link">

              
              <img
                src="http://localhost:4000/assets/img/icons/twitter.png"
                alt="twitter"
              />
              <a href="http://twitter.com/YourTwitterUsername">
                
                  Twitter
                
              </a>
            </div>

          
            <div class="social-link">

              
              <img
                src="http://localhost:4000/assets/img/icons/facebook.png"
                alt="facebook"
              />
              <a href="http://facebook.com/YourFacebookUsername">
                
                  Facebook
                
              </a>
            </div>

          
            <div class="social-link">

              
              <img
                src="http://localhost:4000/assets/img/icons/linkedin.png"
                alt="linkedin"
              />
              <a href="http://linkedin.com/in/YourLinkedInUsername">
                
                  LinkedIn
                
              </a>
            </div>

          
            <div class="social-link">

              
              <img
                src="http://localhost:4000/assets/img/icons/github.png"
                alt="github"
              />
              <a href="http://github.com/YourGitHubUsername">
                
                  GitHub
                
              </a>
            </div>

          
            <div class="social-link">

              
              <img
                src="http://localhost:4000/assets/img/icons/dribbble.png"
                alt="dribbble"
              />
              <a href="https://dribbble.com/YourDribbbleUsername">
                
                  Dribbble
                
              </a>
            </div>

          
            <div class="social-link">

              
              <img
                src="http://localhost:4000/assets/img/icons/rss.png"
                alt="rss"
              />
              <a href="/feed.xml">
                
                  RSS
                
              </a>
            </div>

          
        </div>
      </div>

      
        <div class="footer-col footer-col-3 powered-by">
          <p>
            powered by <a href="https://github.com/eliottvincent/bay">Bay</a> | 2022
          </p>
        </div>
      
    </div>
  </div>
</footer>


  

  
    
    


  <div id="wechat-widget">
    <p>
      Find me on WeChat with the ID <strong>YourWeChatUsername</strong>, or scan my QR code:
    </p>

    <img src="http://localhost:4000/assets/img/wechat-qr-code.png" alt="QR code" id="qr-code" />
  </div>




    <script type="text/javascript" src="http://localhost:4000/assets/js/vendor/cash-4.1.5.min.js"></script>
<script type="text/javascript" src="http://localhost:4000/assets/js/site.js"></script>

  </body>
</html>
